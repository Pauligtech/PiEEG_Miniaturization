{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 16:47:34.776844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-13 16:47:34.776916: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-13 16:47:34.778601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 16:47:34.786177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 16:47:35.744515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "from model_optim.model_optimizer import ModelOptimizer\n",
    "\n",
    "# Dataset\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "from custom_datasets.norm_cho import NormCho2017\n",
    "from custom_datasets.opt_game_mi import OptGameMI\n",
    "from custom_datasets.opt_std_mi import OptStdMI\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [\n",
    "    \"shallow_conv_net\",\n",
    "    \"lstm_net\",\n",
    "    \"deep_conv_net\",\n",
    "    \"eeg_net\",\n",
    "    \"lstm_cnn_net\",\n",
    "    \"lstm_cnn_net_v2\"\n",
    "]\n",
    "MODELS_HYPERPARAMS_DICT = {\n",
    "    \"shallow_conv_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"eeg_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"deep_conv_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"lstm_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net_v2\": {},\n",
    "}\n",
    "\n",
    "DATASETS_LIST = [\n",
    "    FatigueMI,\n",
    "    # NormCho2017,\n",
    "    # OptGameMI,\n",
    "    # OptStdMI,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_optim.utils import data_generator\n",
    "\n",
    "# data_generator(\n",
    "#     dataset=NormCho2017(),\n",
    "#     subjects=[1],\n",
    "#     channel_idx=[],\n",
    "#     sfreq=128,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files = glob.glob(\"./temp_v2/*/*/model/study_best_trial.npy\")\n",
    "subject_files_data = {}\n",
    "for subject_file in subject_files:\n",
    "    subject_files_data[subject_file] = np.load(subject_file, allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort subject_files_data by subject_file_data.user_attrs['trial_data']['test_accuracy']\n",
    "sorted_subject_files_data = dict(sorted(subject_files_data.items(), key=lambda item: item[1].user_attrs['trial_data']['test_accuracy'], reverse=True))\n",
    "sorted_subject_files_data_test_acc = {k: v.user_attrs['trial_data']['test_accuracy'] for k, v in sorted_subject_files_data.items()}\n",
    "rpprint(sorted_subject_files_data_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n"
     ]
    }
   ],
   "source": [
    "model_optimizer = ModelOptimizer(\n",
    "    dataset=FatigueMI(),\n",
    "    model_name=\"shallow_conv_net\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n",
      "Found previous study in ./temp/FatigueMI/[11]/07e5fc841c1c4979b04c45f7b0f990ab/model/deep_conv_net_study_best_trial.npy, removing...\n",
      "Found previous study in ./temp/FatigueMI/[11]/07e5fc841c1c4979b04c45f7b0f990ab/model/deep_conv_net_study.npy, removing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09d5401aaf4fb9af88c45208fec4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 16:50:14.051090: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_17/dropout_68/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.1105 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1105 - accuracy: 0.5441 - val_loss: 1.4251 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.5735\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6880 - accuracy: 0.5735 - val_loss: 0.8363 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8665 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.8665 - accuracy: 0.5147 - val_loss: 1.8280 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7407 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7407 - accuracy: 0.4853 - val_loss: 1.2490 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9493 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9493 - accuracy: 0.5147 - val_loss: 1.5078 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9157 - accuracy: 0.5588\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9157 - accuracy: 0.5588 - val_loss: 1.0292 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.5882\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8109 - accuracy: 0.5882 - val_loss: 1.1837 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7852 - accuracy: 0.5882\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7852 - accuracy: 0.5882 - val_loss: 0.8856 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7778 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7778 - accuracy: 0.6029 - val_loss: 0.9208 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.6176\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6964 - accuracy: 0.6176 - val_loss: 0.7532 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.5588\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7035 - accuracy: 0.5588 - val_loss: 0.8106 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.6471\n",
      "Epoch 00012: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6798 - accuracy: 0.6471 - val_loss: 0.6854 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7809 - accuracy: 0.5441\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7809 - accuracy: 0.5441 - val_loss: 0.7519 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.6912\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6013 - accuracy: 0.6912 - val_loss: 0.6804 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.6029\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6817 - accuracy: 0.6029 - val_loss: 0.6895 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.6912\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5757 - accuracy: 0.6912 - val_loss: 0.6895 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.5882\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6579 - accuracy: 0.5882 - val_loss: 0.7150 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5159 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5159 - accuracy: 0.7500 - val_loss: 0.7174 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.7059\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5053 - accuracy: 0.7059 - val_loss: 0.7320 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.6618\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6048 - accuracy: 0.6618 - val_loss: 0.7524 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.7353\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5116 - accuracy: 0.7353 - val_loss: 0.7394 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5879 - accuracy: 0.6912\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5879 - accuracy: 0.6912 - val_loss: 0.9051 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.7206\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5418 - accuracy: 0.7206 - val_loss: 0.7773 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.7647\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5272 - accuracy: 0.7647 - val_loss: 0.9776 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.7794\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4838 - accuracy: 0.7794 - val_loss: 1.0314 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00012 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.2554 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9159 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 2s 237ms/step - loss: 0.9159 - accuracy: 0.5294 - val_loss: 1.1677 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4957 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 3.5878 - accuracy: 0.4559 - val_loss: 0.8040 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8558 - accuracy: 0.6250\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8123 - accuracy: 0.6324 - val_loss: 0.7288 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7947 - accuracy: 0.6875\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9294 - accuracy: 0.6471 - val_loss: 0.8308 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4564 - accuracy: 0.5938\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1722 - accuracy: 0.6029 - val_loss: 0.8759 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7960 - accuracy: 0.5938\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4212 - accuracy: 0.4853 - val_loss: 0.6983 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7898 - accuracy: 0.5312\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6906 - accuracy: 0.5882 - val_loss: 1.4609 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.1077 - accuracy: 0.5938\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1723 - accuracy: 0.5588 - val_loss: 0.6852 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7841 - accuracy: 0.5938\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6866 - accuracy: 0.6765 - val_loss: 0.8698 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4773 - accuracy: 0.6875\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5987 - accuracy: 0.7059 - val_loss: 1.1176 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8065 - accuracy: 0.6250\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.4650 - accuracy: 0.5147 - val_loss: 0.6355 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1828 - accuracy: 0.4062\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5861 - accuracy: 0.4706 - val_loss: 0.9037 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6698 - accuracy: 0.7188\n",
      "Epoch 00013: val_accuracy improved from 0.55556 to 0.77778, storing weights.\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6885 - accuracy: 0.6912 - val_loss: 0.5758 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2047 - accuracy: 0.4688\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1709 - accuracy: 0.5294 - val_loss: 1.2430 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7343 - accuracy: 0.6250\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6429 - accuracy: 0.6324 - val_loss: 0.6577 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8991 - accuracy: 0.5312\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1154 - accuracy: 0.4706 - val_loss: 1.2123 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8962 - accuracy: 0.5625\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9238 - accuracy: 0.5588 - val_loss: 1.0572 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6563 - accuracy: 0.6562\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8621 - accuracy: 0.6176 - val_loss: 1.1736 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5288 - accuracy: 0.7188\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6060 - accuracy: 0.7059 - val_loss: 0.9609 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4543 - accuracy: 0.7500\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5050 - accuracy: 0.7500 - val_loss: 1.8928 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3407 - accuracy: 0.5000\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1571 - accuracy: 0.5735 - val_loss: 1.4676 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8960 - accuracy: 0.6562\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0498 - accuracy: 0.6176 - val_loss: 0.7439 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5804 - accuracy: 0.7500\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7576 - accuracy: 0.6618 - val_loss: 1.0849 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5208 - accuracy: 0.7188\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4514 - accuracy: 0.7794 - val_loss: 1.0269 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4758 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5081 - accuracy: 0.7353 - val_loss: 1.0249 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00013 with val_accuracy: 0.77778\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6586 - accuracy: 0.6818\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3571 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3571 - accuracy: 0.5147 - val_loss: 1.3965 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2996 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.2996 - accuracy: 0.4853 - val_loss: 2.6242 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0870 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.0870 - accuracy: 0.5147 - val_loss: 0.9875 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7369 - accuracy: 0.5735 - val_loss: 0.7188 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4330 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4330 - accuracy: 0.5147 - val_loss: 1.4471 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8225 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.8225 - accuracy: 0.4853 - val_loss: 0.7005 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2103 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2103 - accuracy: 0.5441 - val_loss: 1.0948 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4942 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4942 - accuracy: 0.4853 - val_loss: 0.7275 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3238 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3238 - accuracy: 0.5441 - val_loss: 0.8241 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9225 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9225 - accuracy: 0.5000 - val_loss: 0.7145 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9062 - accuracy: 0.5588\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9062 - accuracy: 0.5588 - val_loss: 0.7199 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.5294\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8860 - accuracy: 0.5294 - val_loss: 0.7998 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8679 - accuracy: 0.5588\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8679 - accuracy: 0.5588 - val_loss: 0.6812 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7655 - accuracy: 0.5588\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7655 - accuracy: 0.5588 - val_loss: 0.8843 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7651 - accuracy: 0.5882\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7651 - accuracy: 0.5882 - val_loss: 0.6871 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.5882\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7044 - accuracy: 0.5882 - val_loss: 0.9342 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.6324\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6415 - accuracy: 0.6324 - val_loss: 0.7488 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.6618\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6627 - accuracy: 0.6618 - val_loss: 0.9935 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6072 - accuracy: 0.6471\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6072 - accuracy: 0.6471 - val_loss: 0.7903 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.6618\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6925 - accuracy: 0.6618 - val_loss: 1.1544 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.5735\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6705 - accuracy: 0.5735 - val_loss: 0.7912 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.6324\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6909 - accuracy: 0.6324 - val_loss: 1.2671 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.6176\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7481 - accuracy: 0.6176 - val_loss: 0.7546 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7286 - accuracy: 0.5294\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7286 - accuracy: 0.5294 - val_loss: 0.8126 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.6471\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5906 - accuracy: 0.6471 - val_loss: 0.8728 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00008 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.4091 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3050 - accuracy: 0.4559\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3050 - accuracy: 0.4559 - val_loss: 1.0821 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8877 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8877 - accuracy: 0.5000 - val_loss: 0.7443 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3976 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.3976 - accuracy: 0.5147 - val_loss: 1.2954 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1029 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1029 - accuracy: 0.4853 - val_loss: 0.7725 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9295 - accuracy: 0.5588\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9295 - accuracy: 0.5588 - val_loss: 1.0737 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8161 - accuracy: 0.5441\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8161 - accuracy: 0.5441 - val_loss: 0.7558 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8009 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8009 - accuracy: 0.5441 - val_loss: 0.8315 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7545 - accuracy: 0.5735\n",
      "Epoch 00008: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7545 - accuracy: 0.5735 - val_loss: 0.6552 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7695 - accuracy: 0.5441 - val_loss: 0.7318 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8499 - accuracy: 0.5294\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8499 - accuracy: 0.5294 - val_loss: 0.6395 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.5735\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7600 - accuracy: 0.5735 - val_loss: 0.7074 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8317 - accuracy: 0.5735\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8317 - accuracy: 0.5735 - val_loss: 0.6414 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7325 - accuracy: 0.6029\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7325 - accuracy: 0.6029 - val_loss: 0.6287 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.6324\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6370 - accuracy: 0.6324 - val_loss: 0.6429 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5823 - accuracy: 0.6471\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5823 - accuracy: 0.6471 - val_loss: 0.6348 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5699 - accuracy: 0.6765\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5699 - accuracy: 0.6765 - val_loss: 0.6849 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.6912\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6231 - accuracy: 0.6912 - val_loss: 0.6530 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.6029\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6587 - accuracy: 0.6029 - val_loss: 0.7526 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.6176\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6674 - accuracy: 0.6176 - val_loss: 0.6633 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.5294\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6985 - accuracy: 0.5294 - val_loss: 0.7640 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7206\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5438 - accuracy: 0.7206 - val_loss: 0.7050 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.6912\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5747 - accuracy: 0.6912 - val_loss: 0.7832 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.6618\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6057 - accuracy: 0.6618 - val_loss: 0.7122 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.6765\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6690 - accuracy: 0.6765 - val_loss: 0.7441 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.6765\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6450 - accuracy: 0.6765 - val_loss: 0.7778 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Using epoch 00008 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.1628 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3509 - accuracy: 0.4118\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3509 - accuracy: 0.4118 - val_loss: 1.3871 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3494 - accuracy: 0.4853 - val_loss: 3.7254 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9445 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.9445 - accuracy: 0.5147 - val_loss: 1.1716 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7882 - accuracy: 0.5588\n",
      "Epoch 00004: val_accuracy improved from 0.55556 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7882 - accuracy: 0.5588 - val_loss: 0.6896 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4174 - accuracy: 0.5294\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4174 - accuracy: 0.5294 - val_loss: 1.6279 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6849 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.6849 - accuracy: 0.4853 - val_loss: 0.8169 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1878 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1878 - accuracy: 0.5441 - val_loss: 1.2957 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4047 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4047 - accuracy: 0.4853 - val_loss: 0.7178 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2293 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2293 - accuracy: 0.5441 - val_loss: 0.9584 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8519 - accuracy: 0.5441\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8519 - accuracy: 0.5441 - val_loss: 0.7040 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8730 - accuracy: 0.5441\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8730 - accuracy: 0.5441 - val_loss: 0.7424 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7360 - accuracy: 0.6176\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7360 - accuracy: 0.6176 - val_loss: 0.7422 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.5735\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7711 - accuracy: 0.5735 - val_loss: 0.6797 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.5882\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7182 - accuracy: 0.5882 - val_loss: 0.8447 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.6176\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6893 - accuracy: 0.6176 - val_loss: 0.6979 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.6324\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6951 - accuracy: 0.6324 - val_loss: 0.9577 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.6324\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6955 - accuracy: 0.6324 - val_loss: 0.7285 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.6324\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7307 - accuracy: 0.6324 - val_loss: 1.0413 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.5882\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7310 - accuracy: 0.5882 - val_loss: 0.7234 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7558 - accuracy: 0.5588\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7558 - accuracy: 0.5588 - val_loss: 1.2373 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7520 - accuracy: 0.5735\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7520 - accuracy: 0.5735 - val_loss: 0.7916 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.6765\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5575 - accuracy: 0.6765 - val_loss: 1.1031 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6618\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6217 - accuracy: 0.6618 - val_loss: 0.8195 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5993 - accuracy: 0.6471\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5993 - accuracy: 0.6471 - val_loss: 0.8820 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.7794\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5161 - accuracy: 0.7794 - val_loss: 0.9349 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Using epoch 00004 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0635 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6370 - accuracy: 0.5588\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6370 - accuracy: 0.5588 - val_loss: 1.9904 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4810 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.4810 - accuracy: 0.4853 - val_loss: 3.2595 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0290 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.0290 - accuracy: 0.5147 - val_loss: 1.3637 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3373 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3373 - accuracy: 0.4853 - val_loss: 0.9677 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2794 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2794 - accuracy: 0.5147 - val_loss: 1.6415 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4019 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4019 - accuracy: 0.4853 - val_loss: 0.6873 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8448 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8448 - accuracy: 0.5441 - val_loss: 1.4075 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2620 - accuracy: 0.5000\n",
      "Epoch 00008: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2620 - accuracy: 0.5000 - val_loss: 0.6837 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3253 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3253 - accuracy: 0.5441 - val_loss: 1.0576 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9560 - accuracy: 0.5588\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9560 - accuracy: 0.5588 - val_loss: 0.6520 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9198 - accuracy: 0.5588\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9198 - accuracy: 0.5588 - val_loss: 0.7550 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.5882\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9044 - accuracy: 0.5882 - val_loss: 0.7465 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.5588\n",
      "Epoch 00013: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9311 - accuracy: 0.5588 - val_loss: 0.6026 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8508 - accuracy: 0.6029\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8508 - accuracy: 0.6029 - val_loss: 0.9036 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8138 - accuracy: 0.5735\n",
      "Epoch 00015: val_accuracy improved from 0.66667 to 0.72222, storing weights.\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8138 - accuracy: 0.5735 - val_loss: 0.6144 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.7059\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6266 - accuracy: 0.7059 - val_loss: 1.0142 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.6471\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5767 - accuracy: 0.6471 - val_loss: 0.7716 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.7206\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5431 - accuracy: 0.7206 - val_loss: 1.2157 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.7500\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4773 - accuracy: 0.7500 - val_loss: 0.8847 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.7794\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5021 - accuracy: 0.7794 - val_loss: 1.4563 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.6029\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6981 - accuracy: 0.6029 - val_loss: 0.7833 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7116 - accuracy: 0.6765\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7116 - accuracy: 0.6765 - val_loss: 1.6982 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.6029\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6808 - accuracy: 0.6029 - val_loss: 0.8651 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6729 - accuracy: 0.6471\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6729 - accuracy: 0.6471 - val_loss: 1.0126 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.7206\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5598 - accuracy: 0.7206 - val_loss: 1.1603 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00015 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.5567 - accuracy: 0.6818\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4323 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "2/2 [==============================] - 4s 699ms/step - loss: 1.4323 - accuracy: 0.5000 - val_loss: 0.7426 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9092 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy improved from 0.38889 to 0.44444, storing weights.\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9376 - accuracy: 0.5000 - val_loss: 0.7210 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7793 - accuracy: 0.5156\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7903 - accuracy: 0.5147 - val_loss: 0.7072 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8270 - accuracy: 0.5000\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8106 - accuracy: 0.5000 - val_loss: 0.7010 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6885 - accuracy: 0.5156\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.7163 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7029 - accuracy: 0.6406\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6852 - accuracy: 0.6618 - val_loss: 0.7254 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8054 - accuracy: 0.5781\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7816 - accuracy: 0.6029 - val_loss: 0.8560 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9894 - accuracy: 0.5469\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0398 - accuracy: 0.5294 - val_loss: 0.7186 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7080 - accuracy: 0.6250\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6886 - accuracy: 0.6324 - val_loss: 0.7241 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7126 - accuracy: 0.5781\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7083 - accuracy: 0.5735 - val_loss: 0.8059 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7713 - accuracy: 0.5469\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7620 - accuracy: 0.5588 - val_loss: 0.7179 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8475 - accuracy: 0.5156\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8410 - accuracy: 0.5147 - val_loss: 0.8283 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6919 - accuracy: 0.5938\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7096 - accuracy: 0.5882 - val_loss: 0.7500 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7111 - accuracy: 0.5781\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7122 - accuracy: 0.5882 - val_loss: 0.7523 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6908 - accuracy: 0.6250\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6862 - accuracy: 0.6176 - val_loss: 0.7499 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6877 - accuracy: 0.5469\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6825 - accuracy: 0.5441 - val_loss: 0.7460 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7006 - accuracy: 0.6094\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6734 - accuracy: 0.6324 - val_loss: 0.7510 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5915 - accuracy: 0.6250\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5941 - accuracy: 0.6176 - val_loss: 0.7521 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6597 - accuracy: 0.5625\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6883 - accuracy: 0.5441 - val_loss: 0.7508 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5869 - accuracy: 0.6250\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5835 - accuracy: 0.6324 - val_loss: 0.7570 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6219 - accuracy: 0.6094\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6414 - accuracy: 0.6029 - val_loss: 0.7691 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6717 - accuracy: 0.5625\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6869 - accuracy: 0.5588 - val_loss: 0.7668 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6165 - accuracy: 0.6406\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6127 - accuracy: 0.6471 - val_loss: 0.7595 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6163 - accuracy: 0.6406\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.7510 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6515 - accuracy: 0.5781\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6599 - accuracy: 0.5588 - val_loss: 0.7520 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00003 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7611 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5007 - accuracy: 0.3529\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5007 - accuracy: 0.3529 - val_loss: 1.1791 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1304 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1304 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4383 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4383 - accuracy: 0.5147 - val_loss: 1.0739 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9597 - accuracy: 0.4412\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9597 - accuracy: 0.4412 - val_loss: 0.7756 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0556 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0556 - accuracy: 0.5147 - val_loss: 1.0420 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0462 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0462 - accuracy: 0.5147 - val_loss: 0.7482 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0680 - accuracy: 0.5147\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0680 - accuracy: 0.5147 - val_loss: 0.8963 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.4706\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9126 - accuracy: 0.4706 - val_loss: 0.7234 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8088 - accuracy: 0.5588\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8088 - accuracy: 0.5588 - val_loss: 0.7668 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7511 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7511 - accuracy: 0.5000 - val_loss: 0.6709 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8299 - accuracy: 0.5588\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8299 - accuracy: 0.5588 - val_loss: 0.7259 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.5882\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8042 - accuracy: 0.5882 - val_loss: 0.6605 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7834 - accuracy: 0.5588\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7834 - accuracy: 0.5588 - val_loss: 0.6997 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7759 - accuracy: 0.5588\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7759 - accuracy: 0.5588 - val_loss: 0.6596 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.6029\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6314 - accuracy: 0.6029 - val_loss: 0.6526 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7159 - accuracy: 0.5441\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7159 - accuracy: 0.5441 - val_loss: 0.6702 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.6618\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5998 - accuracy: 0.6618 - val_loss: 0.6477 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6523 - accuracy: 0.6324\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6523 - accuracy: 0.6324 - val_loss: 0.7572 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.6471\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6430 - accuracy: 0.6471 - val_loss: 0.6806 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.7059\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5884 - accuracy: 0.7059 - val_loss: 0.8512 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.6324\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7443 - accuracy: 0.6324 - val_loss: 0.6916 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7650 - accuracy: 0.5882\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7650 - accuracy: 0.5882 - val_loss: 0.9574 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8070 - accuracy: 0.5882\n",
      "Epoch 00023: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8070 - accuracy: 0.5882 - val_loss: 0.6889 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8681 - accuracy: 0.6029\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8681 - accuracy: 0.6029 - val_loss: 1.0399 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7611 - accuracy: 0.5882\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7611 - accuracy: 0.5882 - val_loss: 0.7231 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Using epoch 00023 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7938 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0174 - accuracy: 0.5441 - val_loss: 0.7342 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8113 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8113 - accuracy: 0.5000 - val_loss: 1.1682 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1557 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1557 - accuracy: 0.4853 - val_loss: 0.7044 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2058 - accuracy: 0.5147\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2058 - accuracy: 0.5147 - val_loss: 1.0587 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.5588\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8050 - accuracy: 0.5588 - val_loss: 0.7677 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7033 - accuracy: 0.5441\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7033 - accuracy: 0.5441 - val_loss: 0.8211 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.6765\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6595 - accuracy: 0.6765 - val_loss: 0.7362 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5996 - accuracy: 0.6765\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5996 - accuracy: 0.6765 - val_loss: 0.7391 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.6324\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6181 - accuracy: 0.6324 - val_loss: 0.7386 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.5441\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6671 - accuracy: 0.5441 - val_loss: 0.7441 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.6176\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5660 - accuracy: 0.6176 - val_loss: 0.7464 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.6324\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5756 - accuracy: 0.6324 - val_loss: 0.7528 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.6912\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5514 - accuracy: 0.6912 - val_loss: 0.7666 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.6324\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6237 - accuracy: 0.6324 - val_loss: 0.7734 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.6618\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5518 - accuracy: 0.6618 - val_loss: 0.7824 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7059\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5676 - accuracy: 0.7059 - val_loss: 0.7897 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.7059\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5391 - accuracy: 0.7059 - val_loss: 0.7989 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.6471\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5767 - accuracy: 0.6471 - val_loss: 0.8047 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.7353\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5293 - accuracy: 0.7353 - val_loss: 0.8113 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5905 - accuracy: 0.6912\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5905 - accuracy: 0.6912 - val_loss: 0.8168 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.7353\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5493 - accuracy: 0.7353 - val_loss: 0.8203 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.6471\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6228 - accuracy: 0.6471 - val_loss: 0.8227 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.6324\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5817 - accuracy: 0.6324 - val_loss: 0.8247 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.6471\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5782 - accuracy: 0.6471 - val_loss: 0.8287 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.6029\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6019 - accuracy: 0.6029 - val_loss: 0.8339 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6448 - accuracy: 0.5909\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1965 - accuracy: 0.4265\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1965 - accuracy: 0.4265 - val_loss: 1.0924 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.5294\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8705 - accuracy: 0.5294 - val_loss: 4.4897 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.8989 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.8989 - accuracy: 0.5147 - val_loss: 1.4306 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6029 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6029 - accuracy: 0.4853 - val_loss: 1.5008 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5279 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.5279 - accuracy: 0.5147 - val_loss: 1.5736 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2214 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2214 - accuracy: 0.4853 - val_loss: 0.6705 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1631 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1631 - accuracy: 0.5441 - val_loss: 1.4075 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1995 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1995 - accuracy: 0.4853 - val_loss: 0.6739 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2984 - accuracy: 0.5588\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2984 - accuracy: 0.5588 - val_loss: 1.0855 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9996 - accuracy: 0.5588\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9996 - accuracy: 0.5588 - val_loss: 0.6603 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0452 - accuracy: 0.5441\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0452 - accuracy: 0.5441 - val_loss: 0.7898 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.5882\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9041 - accuracy: 0.5882 - val_loss: 0.7165 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.6029\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7007 - accuracy: 0.6029 - val_loss: 0.6514 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.6029\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7683 - accuracy: 0.6029 - val_loss: 0.8868 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.6176\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7397 - accuracy: 0.6176 - val_loss: 0.6330 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.6324\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6836 - accuracy: 0.6324 - val_loss: 1.0184 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7529 - accuracy: 0.5735\n",
      "Epoch 00017: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7529 - accuracy: 0.5735 - val_loss: 0.6627 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.6912\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6296 - accuracy: 0.6912 - val_loss: 1.0769 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.6765\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5921 - accuracy: 0.6765 - val_loss: 0.7381 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.7206\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5160 - accuracy: 0.7206 - val_loss: 1.1411 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.6765\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5744 - accuracy: 0.6765 - val_loss: 0.7824 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5553 - accuracy: 0.6912\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5553 - accuracy: 0.6912 - val_loss: 1.2502 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.7059\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5334 - accuracy: 0.7059 - val_loss: 0.7546 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6555 - accuracy: 0.7059\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6555 - accuracy: 0.7059 - val_loss: 1.5562 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7154 - accuracy: 0.6765\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7154 - accuracy: 0.6765 - val_loss: 0.8357 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Using epoch 00017 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7649 - accuracy: 0.5909\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1119 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33333, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1119 - accuracy: 0.5147 - val_loss: 0.7365 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0424 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy improved from 0.33333 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0424 - accuracy: 0.5147 - val_loss: 1.1130 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0601 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.0601 - accuracy: 0.4853 - val_loss: 0.7977 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8174 - accuracy: 0.5588\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8174 - accuracy: 0.5588 - val_loss: 0.9026 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8471 - accuracy: 0.5147 - val_loss: 0.7156 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.5588\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7323 - accuracy: 0.5588 - val_loss: 0.7072 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.6029\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7232 - accuracy: 0.6029 - val_loss: 0.7310 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.5882\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6620 - accuracy: 0.5882 - val_loss: 0.7049 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.4853\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7028 - accuracy: 0.4853 - val_loss: 0.7096 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.6912\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6546 - accuracy: 0.6912 - val_loss: 0.7092 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.6765\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6545 - accuracy: 0.6765 - val_loss: 0.7127 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.6176\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6511 - accuracy: 0.6176 - val_loss: 0.7256 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.6618\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5938 - accuracy: 0.6618 - val_loss: 0.7198 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.5882\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6207 - accuracy: 0.5882 - val_loss: 0.7358 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.6912\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5743 - accuracy: 0.6912 - val_loss: 0.7366 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7059\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5740 - accuracy: 0.7059 - val_loss: 0.7762 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7059\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5973 - accuracy: 0.7059 - val_loss: 0.7572 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.6765\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5481 - accuracy: 0.6765 - val_loss: 0.7894 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.7647\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5337 - accuracy: 0.7647 - val_loss: 0.7959 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.7059\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5888 - accuracy: 0.7059 - val_loss: 0.8016 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.6618\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5924 - accuracy: 0.6618 - val_loss: 0.8084 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.7206\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5618 - accuracy: 0.7206 - val_loss: 0.8113 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7500\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.8147 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.6912\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5446 - accuracy: 0.6912 - val_loss: 0.8147 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4857 - accuracy: 0.7500 - val_loss: 0.8161 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00002 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.7145 - accuracy: 0.5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in [FatigueMI]:\n",
    "    for model in [\"deep_conv_net\"]:\n",
    "        model_optimizer = ModelOptimizer(\n",
    "            dataset=dataset(),\n",
    "            model_name=model\n",
    "        )\n",
    "        for subject in [11]:\n",
    "            max_epochs = MODELS_HYPERPARAMS_DICT[model][\"max_epochs\"]\n",
    "            study = model_optimizer.search_best_model(\n",
    "                subjects = [subject],\n",
    "                max_iter = 25,\n",
    "                max_epochs = max_epochs,\n",
    "                max_stag_count = 10,\n",
    "                rounds = 1,\n",
    "                replace_previous_study_for_subjects = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.168301</td>\n",
       "      <td>0.483761</td>\n",
       "      <td>0.680379</td>\n",
       "      <td>0.196618</td>\n",
       "      <td>1.255373</td>\n",
       "      <td>0.151985</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, T5, O2, ...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.575806</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>[P3, Fz, P4, Cz, T3, T5, O2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.057190</td>\n",
       "      <td>0.477276</td>\n",
       "      <td>0.602562</td>\n",
       "      <td>0.125286</td>\n",
       "      <td>2.556679</td>\n",
       "      <td>0.327611</td>\n",
       "      <td>[P3, C3, Fz, F4, Fp1, O1, F8, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>0.516096</td>\n",
       "      <td>0.679674</td>\n",
       "      <td>0.163578</td>\n",
       "      <td>1.063509</td>\n",
       "      <td>0.361561</td>\n",
       "      <td>[F3, Fz, F4, C4, T3, T5, F8, A2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>224</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>0.647678</td>\n",
       "      <td>0.059285</td>\n",
       "      <td>0.793769</td>\n",
       "      <td>0.361611</td>\n",
       "      <td>[P3, C3, Fz, F4, P4, Cz, Fp1, Fp2, T3, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.515996</td>\n",
       "      <td>0.632985</td>\n",
       "      <td>0.116990</td>\n",
       "      <td>2.764858</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>[P3, Fz, F4, Pz, Fp1, T3, T5, O2, F8, A2, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.590550</td>\n",
       "      <td>0.681202</td>\n",
       "      <td>0.090652</td>\n",
       "      <td>1.409137</td>\n",
       "      <td>0.401685</td>\n",
       "      <td>[F3, F4, P4, Pz, Fp2, T3, O1, F8, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0.543822</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>1.162843</td>\n",
       "      <td>0.401785</td>\n",
       "      <td>[P3, F3, C4, P4, Cz, Fp2, T3, O1, O2, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.179739</td>\n",
       "      <td>0.529332</td>\n",
       "      <td>0.704364</td>\n",
       "      <td>0.175032</td>\n",
       "      <td>0.644767</td>\n",
       "      <td>0.447931</td>\n",
       "      <td>[P3, Fz, F4, Fp1, Fp2, T3, O2, F7]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>0.583539</td>\n",
       "      <td>0.700953</td>\n",
       "      <td>0.117414</td>\n",
       "      <td>0.761109</td>\n",
       "      <td>0.448031</td>\n",
       "      <td>[P3, C3, Fz, P4, Cz, T5, F7, A2, T6, T4]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.485691</td>\n",
       "      <td>0.704912</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>1.714506</td>\n",
       "      <td>0.448181</td>\n",
       "      <td>[C3, F3, C4, Cz, Pz, Fp2, T5, O1, O2, F7, F8, ...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff  train_loss  val_loss  \\\n",
       "0    0.779412  0.545455  0.611111            0.168301    0.483761  0.680379   \n",
       "1    0.779412  0.681818  0.777778            0.001634    0.451416  0.575806   \n",
       "5    0.779412  0.681818  0.722222            0.057190    0.477276  0.602562   \n",
       "4    0.779412  0.545455  0.666667            0.112745    0.516096  0.679674   \n",
       "7    0.705882  0.500000  0.666667            0.039216    0.588393  0.647678   \n",
       "9    0.720588  0.590909  0.666667            0.053922    0.515996  0.632985   \n",
       "2    0.661765  0.545455  0.611111            0.050654    0.590550  0.681202   \n",
       "3    0.720588  0.500000  0.611111            0.109477    0.543822  0.628700   \n",
       "8    0.735294  0.590909  0.555556            0.179739    0.529332  0.704364   \n",
       "6    0.661765  0.500000  0.555556            0.106209    0.583539  0.700953   \n",
       "10   0.764706  0.500000  0.555556            0.209150    0.485691  0.704912   \n",
       "\n",
       "    train_val_loss_diff  test_loss    scores  \\\n",
       "0              0.196618   1.255373  0.151985   \n",
       "1              0.124390   0.658583  0.299783   \n",
       "5              0.125286   2.556679  0.327611   \n",
       "4              0.163578   1.063509  0.361561   \n",
       "7              0.059285   0.793769  0.361611   \n",
       "9              0.116990   2.764858  0.361711   \n",
       "2              0.090652   1.409137  0.401685   \n",
       "3              0.084878   1.162843  0.401785   \n",
       "8              0.175032   0.644767  0.447931   \n",
       "6              0.117414   0.761109  0.448031   \n",
       "10             0.219221   1.714506  0.448181   \n",
       "\n",
       "                                    channels_selected  sfreq  batch_size  \\\n",
       "0   [P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, T5, O2, ...  128.0         160   \n",
       "1                    [P3, Fz, P4, Cz, T3, T5, O2, T6]  256.0          32   \n",
       "5               [P3, C3, Fz, F4, Fp1, O1, F8, T6, T4]  300.0         128   \n",
       "4                [F3, Fz, F4, C4, T3, T5, F8, A2, T6]  256.0         224   \n",
       "7          [P3, C3, Fz, F4, P4, Cz, Fp1, Fp2, T3, T6]  128.0         256   \n",
       "9   [P3, Fz, F4, Pz, Fp1, T3, T5, O2, F8, A2, T6, T4]  300.0         256   \n",
       "2               [F3, F4, P4, Pz, Fp2, T3, O1, F8, A2]  256.0         160   \n",
       "3       [P3, F3, C4, P4, Cz, Fp2, T3, O1, O2, F8, T6]  128.0         192   \n",
       "8                  [P3, Fz, F4, Fp1, Fp2, T3, O2, F7]  128.0         192   \n",
       "6            [P3, C3, Fz, P4, Cz, T5, F7, A2, T6, T4]  128.0          64   \n",
       "10  [C3, F3, C4, Cz, Pz, Fp2, T5, O1, O2, F7, F8, ...  128.0          96   \n",
       "\n",
       "       model_name subjects  \n",
       "0   deep_conv_net     [11]  \n",
       "1   deep_conv_net     [11]  \n",
       "5   deep_conv_net     [11]  \n",
       "4   deep_conv_net     [11]  \n",
       "7   deep_conv_net     [11]  \n",
       "9   deep_conv_net     [11]  \n",
       "2   deep_conv_net     [11]  \n",
       "3   deep_conv_net     [11]  \n",
       "8   deep_conv_net     [11]  \n",
       "6   deep_conv_net     [11]  \n",
       "10  deep_conv_net     [11]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_optimizer.get_study_metrics(study).sort_values(by=\"scores\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[1;36m128\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m160\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test_accuracy = \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6111111044883728</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val_accuracy = \u001b[1;36m0.6111111044883728\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">channels_selected = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'P3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'C3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'C4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Cz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Pz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fp2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T5'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'O2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F8'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'A2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T6'</span>\n",
       " <span style=\"color: #008000; text-decoration-color: #008000\">'T4'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "channels_selected = \u001b[1m[\u001b[0m\u001b[32m'P3'\u001b[0m \u001b[32m'C3'\u001b[0m \u001b[32m'F3'\u001b[0m \u001b[32m'Fz'\u001b[0m \u001b[32m'F4'\u001b[0m \u001b[32m'C4'\u001b[0m \u001b[32m'Cz'\u001b[0m \u001b[32m'Pz'\u001b[0m \u001b[32m'Fp2'\u001b[0m \u001b[32m'T5'\u001b[0m \u001b[32m'O2'\u001b[0m \u001b[32m'F8'\u001b[0m \u001b[32m'A2'\u001b[0m \u001b[32m'T6'\u001b[0m\n",
       " \u001b[32m'T4'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint({ k: v for k, v in study.best_trial.params.items() if not k.startswith(\"channels\") })\n",
    "rprint(\"test_accuracy =\", study.best_trial.user_attrs[\"trial_data\"][\"test_accuracy\"])\n",
    "rprint(\"val_accuracy =\", np.max(study.best_trial.user_attrs[\"trial_data\"][\"val_accuracy\"]))\n",
    "rprint(\"channels_selected =\", study.best_trial.user_attrs[\"trial_data\"][\"channels_selected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fatigue_mi_studies = glob.glob(\"./temp/FatigueMI/**/**/model/*_study.npy\") + glob.glob(\"./temp/FatigueMI/**/**/model/shallow_conv_net_study_best_trial.npy\")\n",
    "temp_fatigue_mi_studies_dict = {}\n",
    "temp_fatigue_mi_studies_file_names_dict = {}\n",
    "\n",
    "for study_file in temp_fatigue_mi_studies:\n",
    "    study = np.load(study_file, allow_pickle=True).item()\n",
    "    subject_number = int(study_file.split(\"[\")[1].split(']')[0])\n",
    "    model_name = study_file.split(\"/\")[-1].replace(\"_study.npy\", \"\").replace(\"shallow_conv_net_study_best_trial.npy\", \"shallow_conv_net\")\n",
    "    temp_fatigue_mi_studies_dict[f\"{subject_number}_{model_name}\"] = study\n",
    "    temp_fatigue_mi_studies_file_names_dict[f\"{subject_number}_{model_name}\"] = study_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>1.209507</td>\n",
       "      <td>1.407622</td>\n",
       "      <td>0.198116</td>\n",
       "      <td>1.633958</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>1.353778</td>\n",
       "      <td>1.540807</td>\n",
       "      <td>0.187029</td>\n",
       "      <td>1.678117</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.157701</td>\n",
       "      <td>0.673368</td>\n",
       "      <td>0.198031</td>\n",
       "      <td>[P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.595995</td>\n",
       "      <td>0.62438</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.578216</td>\n",
       "      <td>0.327611</td>\n",
       "      <td>[P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200980</td>\n",
       "      <td>84.76915</td>\n",
       "      <td>82.498848</td>\n",
       "      <td>2.270302</td>\n",
       "      <td>90.271187</td>\n",
       "      <td>0.111561</td>\n",
       "      <td>[F3, Fz, F4, Fp2, T3, T5, F7, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/4f2b98dbeb684bfa8f887b396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>0.580237</td>\n",
       "      <td>0.42945</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.791186</td>\n",
       "      <td>[P3, C3, F4, C4, Pz, Fp1, O1, F8, A2, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[13]</td>\n",
       "      <td>./temp/FatigueMI/[13]/1b189965ada44ff99e73fa14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.259804</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.901306</td>\n",
       "      <td>[P3, C3, F4, C4, P4, Pz, Fp2, T3, O2]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[5]</td>\n",
       "      <td>./temp/FatigueMI/[5]/d199c9c2ac924b238693f158e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.189622</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.414381</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, T5, O2, F7, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[12]</td>\n",
       "      <td>./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.878924</td>\n",
       "      <td>[P3, C3, Fz, C4, Fp1, Fp2, T3, O1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[8]</td>\n",
       "      <td>./temp/FatigueMI/[8]/9fd82ec44ef3496da6307b57e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>[C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "      <td>./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff train_loss   val_loss  \\\n",
       "19   0.838235  0.818182  0.722222            0.116013   1.209507   1.407622   \n",
       "22   0.794118  0.818182  0.722222            0.071895   1.353778   1.540807   \n",
       "7    0.573529  0.545455  0.555556            0.017974   0.812133   0.654432   \n",
       "13   0.691176  0.863636  0.722222            0.031046   0.595995    0.62438   \n",
       "18   0.867647  0.545455  0.666667            0.200980   84.76915  82.498848   \n",
       "..        ...       ...       ...                 ...        ...        ...   \n",
       "0    1.000000  0.636364  0.833333            0.166667   0.150787   0.580237   \n",
       "0    0.926471  0.636364  0.666667            0.259804       None       None   \n",
       "0    1.000000  0.772727  0.888889            0.111111   0.189622   0.604003   \n",
       "0    1.000000  0.636364  0.722222            0.277778       None       None   \n",
       "0    1.000000  0.863636  0.888889            0.111111       None       None   \n",
       "\n",
       "   train_val_loss_diff  test_loss    scores  \\\n",
       "19            0.198116   1.633958  0.077361   \n",
       "22            0.187029   1.678117  0.077361   \n",
       "7             0.157701   0.673368  0.198031   \n",
       "13            0.028385   0.578216  0.327611   \n",
       "18            2.270302  90.271187  0.111561   \n",
       "..                 ...        ...       ...   \n",
       "0              0.42945   0.998291  0.791186   \n",
       "0                 None       None  0.901306   \n",
       "0             0.414381   0.733969  0.665729   \n",
       "0                 None       None  0.878924   \n",
       "0                 None       None  0.520520   \n",
       "\n",
       "                                    channels_selected  sfreq batch_size  \\\n",
       "19                                   [C3, Fz, T6, T4]  256.0        192   \n",
       "22                                   [C3, Fz, T6, T4]  256.0        160   \n",
       "7           [P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]  128.0        256   \n",
       "13              [P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]  128.0        192   \n",
       "18              [F3, Fz, F4, Fp2, T3, T5, F7, A2, T4]  256.0        224   \n",
       "..                                                ...    ...        ...   \n",
       "0           [P3, C3, F4, C4, Pz, Fp1, O1, F8, A2, T6]   None       None   \n",
       "0               [P3, C3, F4, C4, P4, Pz, Fp2, T3, O2]   None       None   \n",
       "0                [P3, C3, F3, C4, Cz, T5, O2, F7, T6]   None       None   \n",
       "0                  [P3, C3, Fz, C4, Fp1, Fp2, T3, O1]   None       None   \n",
       "0   [C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...   None       None   \n",
       "\n",
       "          model_name subjects  \\\n",
       "19           eeg_net      [9]   \n",
       "22           eeg_net      [9]   \n",
       "7      deep_conv_net      [9]   \n",
       "13     deep_conv_net      [9]   \n",
       "18      lstm_cnn_net      [9]   \n",
       "..               ...      ...   \n",
       "0   shallow_conv_net     [13]   \n",
       "0   shallow_conv_net      [5]   \n",
       "0   shallow_conv_net     [12]   \n",
       "0   shallow_conv_net      [8]   \n",
       "0   shallow_conv_net      [4]   \n",
       "\n",
       "                                            file_path  \n",
       "19  ./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...  \n",
       "22  ./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...  \n",
       "7   ./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...  \n",
       "13  ./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...  \n",
       "18  ./temp/FatigueMI/[9]/4f2b98dbeb684bfa8f887b396...  \n",
       "..                                                ...  \n",
       "0   ./temp/FatigueMI/[13]/1b189965ada44ff99e73fa14...  \n",
       "0   ./temp/FatigueMI/[5]/d199c9c2ac924b238693f158e...  \n",
       "0   ./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...  \n",
       "0   ./temp/FatigueMI/[8]/9fd82ec44ef3496da6307b57e...  \n",
       "0   ./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...  \n",
       "\n",
       "[85 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_study_trials_concat_df = pd.DataFrame()\n",
    "\n",
    "for subject_model in temp_fatigue_mi_studies_dict:\n",
    "    study = temp_fatigue_mi_studies_dict[subject_model]\n",
    "    study_trials_df = model_optimizer.get_study_metrics(study, **{ \n",
    "        \"default_model_name\": \"shallow_conv_net\", \n",
    "        \"subjects\": [subject_model.split(\"_\")[0]],\n",
    "        \"file_path\": temp_fatigue_mi_studies_file_names_dict[subject_model],\n",
    "    })\n",
    "    # Filter: Top 10 best scores -> Max training accuracy -> Minimum difference between training and validation accuracy -> Max test accuracy = best model\n",
    "    filtered_study_trials_df = study_trials_df.copy()\n",
    "    filtered_study_trials_df = filtered_study_trials_df.nsmallest(2, 'scores')\n",
    "    # filtered_study_trials_df = filtered_study_trials_df.nsmallest(5, 'train_val_acc_diff')\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['train_acc'] == max(filtered_study_trials_df['train_acc'])]\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['train_val_acc_diff'] == min(filtered_study_trials_df['train_val_acc_diff'])]\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['test_acc'] == max(filtered_study_trials_df['test_acc'])]\n",
    "    filtered_study_trials_concat_df = pd.concat([filtered_study_trials_concat_df, filtered_study_trials_df])\n",
    "display(filtered_study_trials_concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'9'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'11'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'12'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'4'\u001b[0m, \u001b[32m'6'\u001b[0m, \u001b[32m'9'\u001b[0m, \u001b[32m'11'\u001b[0m, \u001b[32m'12'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.575806</td>\n",
       "      <td>0.12439</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>[P3, Fz, P4, Cz, T3, T5, O2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.755424</td>\n",
       "      <td>1.030562</td>\n",
       "      <td>0.275138</td>\n",
       "      <td>1.222213</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>[P3, C3, F3, Fz, P4, Cz, T3, T5, O1, F7, F8, A...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/6772e2405e6e436faba83820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.277274</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.853020</td>\n",
       "      <td>[P3, C3, Fz, F4, C4, P4, F7, F8]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>[C3, F3, C4, Cz, Fp2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.305321</td>\n",
       "      <td>0.739283</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, Pz, Fp2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.189622</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.414381</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, T5, O2, F7, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.746527</td>\n",
       "      <td>0.32044</td>\n",
       "      <td>0.510645</td>\n",
       "      <td>0.111411</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>4</td>\n",
       "      <td>./temp/FatigueMI/[4]/52166a0614d541acb9b9ef965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.233660</td>\n",
       "      <td>0.718789</td>\n",
       "      <td>1.110411</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>1.152245</td>\n",
       "      <td>0.077561</td>\n",
       "      <td>[C3, F3, P4, Cz, Pz, T3, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>4</td>\n",
       "      <td>./temp/FatigueMI/[4]/72578c4a27b64a8e989fd9072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>[C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>4</td>\n",
       "      <td>./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.118139</td>\n",
       "      <td>0.673557</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>6</td>\n",
       "      <td>./temp/FatigueMI/[6]/0614f3b1603b4442a2cc79ade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.233660</td>\n",
       "      <td>0.831503</td>\n",
       "      <td>0.940101</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.985933</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>[P3, F3, Fz, Cz, Pz, Fp1, F7, A2, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>6</td>\n",
       "      <td>./temp/FatigueMI/[6]/969f098d0f9344e5baa14cc42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.522768</td>\n",
       "      <td>1.17613</td>\n",
       "      <td>0.653362</td>\n",
       "      <td>2.52356</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, Cz, T3, T5, O1, F8, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>6</td>\n",
       "      <td>./temp/FatigueMI/[6]/7ec6d62fc9a84597a65261efc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.595995</td>\n",
       "      <td>0.62438</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.578216</td>\n",
       "      <td>0.327611</td>\n",
       "      <td>[P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>9</td>\n",
       "      <td>./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>1.209507</td>\n",
       "      <td>1.407622</td>\n",
       "      <td>0.198116</td>\n",
       "      <td>1.633958</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>9</td>\n",
       "      <td>./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.080062</td>\n",
       "      <td>0.289237</td>\n",
       "      <td>0.209175</td>\n",
       "      <td>0.342057</td>\n",
       "      <td>0.418946</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, P4, Pz, Fp1, T5, O2, A2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>9</td>\n",
       "      <td>./temp/FatigueMI/[9]/63a8c87ffc02471893db5ac9a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff train_loss  val_loss  \\\n",
       "8    0.779412  0.681818  0.777778            0.001634   0.451416  0.575806   \n",
       "9    0.970588  0.681818  0.722222            0.248366   0.755424  1.030562   \n",
       "11   0.941176  0.727273  0.666667            0.274510   0.501189  0.778463   \n",
       "12   0.852941  0.727273  0.888889            0.035948   0.388678  0.429204   \n",
       "13   0.955882  0.818182  0.833333            0.122549   0.432221  0.737542   \n",
       "15   1.000000  0.772727  0.888889            0.111111   0.189622  0.604003   \n",
       "26   0.823529  0.818182  0.666667            0.156863   0.426087  0.746527   \n",
       "27   0.955882  0.818182  0.722222            0.233660   0.718789  1.110411   \n",
       "28   1.000000  0.863636  0.888889            0.111111       None      None   \n",
       "33   0.705882  0.681818  0.666667            0.039216   0.572419  0.690558   \n",
       "34   0.955882  0.636364  0.722222            0.233660   0.831503  0.940101   \n",
       "36   1.000000  0.727273  0.888889            0.111111   0.522768   1.17613   \n",
       "45   0.691176  0.863636  0.722222            0.031046   0.595995   0.62438   \n",
       "46   0.838235  0.818182  0.722222            0.116013   1.209507  1.407622   \n",
       "48   1.000000  0.909091  0.944444            0.055556   0.080062  0.289237   \n",
       "\n",
       "   train_val_loss_diff test_loss    scores  \\\n",
       "8              0.12439  0.658583  0.299783   \n",
       "9             0.275138  1.222213  0.077861   \n",
       "11            0.277274  0.757358  0.853020   \n",
       "12            0.040526  0.646307  0.262646   \n",
       "13            0.305321  0.739283  0.028128   \n",
       "15            0.414381  0.733969  0.665729   \n",
       "26             0.32044  0.510645  0.111411   \n",
       "27            0.391622  1.152245  0.077561   \n",
       "28                None      None  0.520520   \n",
       "33            0.118139  0.673557  0.111661   \n",
       "34            0.108597  0.985933  0.077661   \n",
       "36            0.653362   2.52356  0.012896   \n",
       "45            0.028385  0.578216  0.327611   \n",
       "46            0.198116  1.633958  0.077361   \n",
       "48            0.209175  0.342057  0.418946   \n",
       "\n",
       "                                    channels_selected  sfreq batch_size  \\\n",
       "8                    [P3, Fz, P4, Cz, T3, T5, O2, T6]  256.0         32   \n",
       "9   [P3, C3, F3, Fz, P4, Cz, T3, T5, O1, F7, F8, A...  256.0        256   \n",
       "11                   [P3, C3, Fz, F4, C4, P4, F7, F8]    NaN       None   \n",
       "12                          [C3, F3, C4, Cz, Fp2, T6]  128.0        128   \n",
       "13                      [P3, C3, F3, C4, Cz, Pz, Fp2]  128.0         32   \n",
       "15               [P3, C3, F3, C4, Cz, T5, O2, F7, T6]   None       None   \n",
       "26                           [F3, P4, Pz, F7, F8, A2]  300.0         32   \n",
       "27                   [C3, F3, P4, Cz, Pz, T3, T6, T4]  256.0        160   \n",
       "28  [C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...   None       None   \n",
       "33      [P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]  300.0         64   \n",
       "34          [P3, F3, Fz, Cz, Pz, Fp1, F7, A2, T6, T4]  256.0         32   \n",
       "36       [P3, C3, F3, Fz, F4, Cz, T3, T5, O1, F8, A2]  256.0         32   \n",
       "45              [P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]  128.0        192   \n",
       "46                                   [C3, Fz, T6, T4]  256.0        192   \n",
       "48  [P3, C3, F3, Fz, F4, C4, P4, Pz, Fp1, T5, O2, A2]    NaN       None   \n",
       "\n",
       "          model_name subjects  \\\n",
       "8      deep_conv_net       11   \n",
       "9            eeg_net       11   \n",
       "11  shallow_conv_net       11   \n",
       "12     deep_conv_net       12   \n",
       "13           eeg_net       12   \n",
       "15  shallow_conv_net       12   \n",
       "26     deep_conv_net        4   \n",
       "27           eeg_net        4   \n",
       "28  shallow_conv_net        4   \n",
       "33     deep_conv_net        6   \n",
       "34           eeg_net        6   \n",
       "36  shallow_conv_net        6   \n",
       "45     deep_conv_net        9   \n",
       "46           eeg_net        9   \n",
       "48  shallow_conv_net        9   \n",
       "\n",
       "                                            file_path  \n",
       "8   ./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...  \n",
       "9   ./temp/FatigueMI/[11]/6772e2405e6e436faba83820...  \n",
       "11  ./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...  \n",
       "12  ./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...  \n",
       "13  ./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...  \n",
       "15  ./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...  \n",
       "26  ./temp/FatigueMI/[4]/52166a0614d541acb9b9ef965...  \n",
       "27  ./temp/FatigueMI/[4]/72578c4a27b64a8e989fd9072...  \n",
       "28  ./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...  \n",
       "33  ./temp/FatigueMI/[6]/0614f3b1603b4442a2cc79ade...  \n",
       "34  ./temp/FatigueMI/[6]/969f098d0f9344e5baa14cc42...  \n",
       "36  ./temp/FatigueMI/[6]/7ec6d62fc9a84597a65261efc...  \n",
       "45  ./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...  \n",
       "46  ./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...  \n",
       "48  ./temp/FatigueMI/[9]/63a8c87ffc02471893db5ac9a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subjects_to_retain = [4, 6, 9, 11, 12]\n",
    "subjects_to_retain_str = [f'{subject}' for subject in subjects_to_retain]\n",
    "model_names_to_retain_str = [\"shallow_conv_net\", \"deep_conv_net\", \"eeg_net\"]\n",
    "\n",
    "rprint(subjects_to_retain_str)\n",
    "\n",
    "# Convert subjects written as \"['1']\" to \"[1]\"\n",
    "filtered_study_trials_concat_df['subjects'] = filtered_study_trials_concat_df['subjects'].apply(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\"))\n",
    "\n",
    "# Convert subjects to catagorical\n",
    "filtered_study_trials_concat_df['subjects'] = pd.Categorical(filtered_study_trials_concat_df['subjects'].astype(str))\n",
    "# filtered_study_trials_concat_df.query(f\"subjects in {subjects_to_retain_str} and test_acc > 0.67\")\n",
    "\n",
    "# Get the models with the highest test_acc for each type of model_name (eeg_net, deep_conv_net, etc.) and for each subject (4, 6, 9, 10, 11, 12)\n",
    "best_models_df = filtered_study_trials_concat_df.groupby(['subjects', 'model_name']).apply(lambda x: x.nlargest(1, 'test_acc')).reset_index(drop=True)\n",
    "best_models_df = best_models_df.query(f\"subjects in {subjects_to_retain_str}\")\n",
    "best_models_df = best_models_df.query(f\"model_name in {model_names_to_retain_str}\")\n",
    "display(best_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
