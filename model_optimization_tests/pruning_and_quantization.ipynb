{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 01:20:10.870197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-20 01:20:10.870247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-20 01:20:10.873859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-20 01:20:10.901380: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 01:20:12.632025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "%load_ext tensorboard\n",
    "    \n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tf\"\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"0\"\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import keras\n",
    "    \n",
    "# region Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Permute, Dropout\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    ")\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "# endregion Keras\n",
    "\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_optim.utils import channels_to_channels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "# RNG = jax.random.PRNGKey(SKLRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Helper funcs\n",
    "def shallow_conv_net_square_layer(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "def shallow_conv_net_log_layer(x):\n",
    "    return tf.math.log(tf.clip_by_value(x, 1e-7, 10000))\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    \"shallow_conv_net_square_layer\": shallow_conv_net_square_layer, \n",
    "    \"shallow_conv_net_log_layer\": shallow_conv_net_log_layer \n",
    "}\n",
    "# endregion Helper funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.575806</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>['P3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O2' 'T6']</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.755424</td>\n",
       "      <td>1.030562</td>\n",
       "      <td>0.275138</td>\n",
       "      <td>1.222213</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>['P3' 'C3' 'F3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O1' ...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/6772e2405e6e436faba83820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.277274</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.853020</td>\n",
       "      <td>['P3' 'C3' 'Fz' 'F4' 'C4' 'P4' 'F7' 'F8']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>['C3' 'F3' 'C4' 'Cz' 'Fp2' 'T6']</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.305321</td>\n",
       "      <td>0.739283</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>['P3' 'C3' 'F3' 'C4' 'Cz' 'Pz' 'Fp2']</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_number  train_acc  test_acc   val_acc  train_val_acc_diff  \\\n",
       "0             1   0.779412  0.681818  0.777778            0.001634   \n",
       "1             3   0.970588  0.681818  0.722222            0.248366   \n",
       "2             0   0.941176  0.727273  0.666667            0.274510   \n",
       "3            23   0.852941  0.727273  0.888889            0.035948   \n",
       "4            15   0.955882  0.818182  0.833333            0.122549   \n",
       "\n",
       "   train_loss  val_loss  train_val_loss_diff  test_loss    scores  \\\n",
       "0    0.451416  0.575806             0.124390   0.658583  0.299783   \n",
       "1    0.755424  1.030562             0.275138   1.222213  0.077861   \n",
       "2    0.501189  0.778463             0.277274   0.757358  0.853020   \n",
       "3    0.388678  0.429204             0.040526   0.646307  0.262646   \n",
       "4    0.432221  0.737542             0.305321   0.739283  0.028128   \n",
       "\n",
       "                                   channels_selected  sfreq  batch_size  \\\n",
       "0          ['P3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O2' 'T6']  256.0        32.0   \n",
       "1  ['P3' 'C3' 'F3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O1' ...  256.0       256.0   \n",
       "2          ['P3' 'C3' 'Fz' 'F4' 'C4' 'P4' 'F7' 'F8']    NaN         NaN   \n",
       "3                   ['C3' 'F3' 'C4' 'Cz' 'Fp2' 'T6']  128.0       128.0   \n",
       "4              ['P3' 'C3' 'F3' 'C4' 'Cz' 'Pz' 'Fp2']  128.0        32.0   \n",
       "\n",
       "         model_name  subjects  \\\n",
       "0     deep_conv_net        11   \n",
       "1           eeg_net        11   \n",
       "2  shallow_conv_net        11   \n",
       "3     deep_conv_net        12   \n",
       "4           eeg_net        12   \n",
       "\n",
       "                                           file_path  \n",
       "0  ./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...  \n",
       "1  ./temp/FatigueMI/[11]/6772e2405e6e436faba83820...  \n",
       "2  ./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...  \n",
       "3  ./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...  \n",
       "4  ./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_df = pd.read_csv(\"./final/best_models.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "best_models_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb93fd4f9a/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[11]/6772e2405e6e436faba8382021d362e4/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd4a9ff053/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e4071f15f07a/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d120893ed/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[12]/96dc576945fb4f2db582d66ae1d2c8ce/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[4]/52166a0614d541acb9b9ef965eed5de2/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[4]/72578c4a27b64a8e989fd90727f209ad/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f5297a6778/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[6]/0614f3b1603b4442a2cc79ade04a6a0d/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[6]/969f098d0f9344e5baa14cc429e2471b/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[6]/7ec6d62fc9a84597a65261efcb6e808a/model/shallow_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5df6dd6e/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520efcfee6/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[9]/63a8c87ffc02471893db5ac9a0781946/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/2e54fc7d125447c096b49ecb93fd4f9a/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/6772e2405e6e436faba8382021d362e4/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/e0643f9a780146a4adc15ddd4a9ff053/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/259f8d3cf7ce4e5283e8e4071f15f07a/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/fa0faed8a6ce4a52a2b9ca5d120893ed/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/96dc576945fb4f2db582d66ae1d2c8ce/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/52166a0614d541acb9b9ef965eed5de2/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m19\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/72578c4a27b64a8e989fd90727f209ad/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/3623cb4ba1ad4a908c9098f5297a6778/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/0614f3b1603b4442a2cc79ade04a6a0d/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/969f098d0f9344e5baa14cc429e2471b/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/7ec6d62fc9a84597a65261efcb6e808a/model/shallow_conv_net_study.npy'\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/0113b240ca004b67b81ca0fd5df6dd6e/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m13\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/fd4945e8633f4c0ab473e7520efcfee6/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m19\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/63a8c87ffc02471893db5ac9a0781946/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject_best_file_paths = best_models_df[['file_path']].to_numpy().flatten().tolist()\n",
    "subject_best_trial_numbers = best_models_df[['trial_number']].to_numpy().flatten().tolist()\n",
    "subject_best_trials = list(zip(subject_best_file_paths, subject_best_trial_numbers))\n",
    "rpprint(subject_best_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_best_trials = glob.glob('./temp_v2/**/model/shallow_conv_net_study_best_trial.npy', recursive=True)\n",
    "# subject_best_trials = sorted(subject_best_trials, key=lambda x: os.path.getmtime(x))\n",
    "# subject_best_trials = sorted(subject_best_trials, key=lambda x: int(re.compile(r\"\\[.*\\]\").search(x).group(0).strip(\"[]\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_trial_from_study(study_idx, subject_best_trials):\n",
    "    study_path = subject_best_trials[study_idx][0]\n",
    "    study = np.load(study_path, allow_pickle=True).item()\n",
    "    trial = study.trials[subject_best_trials[study_idx][1]] if hasattr(study, \"trials\") else study\n",
    "\n",
    "    model_info = {\n",
    "        \"subject\": trial.user_attrs[\"trial_data\"][\"subject\"] if hasattr(trial.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(study_path).group(0).strip(\"[]\")),\n",
    "        \"sfreq\": trial.params[\"sfreq\"] if \"sfreq\" in trial.params and not trial.params[\"sfreq\"] == None else trial.user_attrs['trial_data']['sfreq'] if \"sfreq\" in trial.user_attrs['trial_data'] else 128,\n",
    "        \"batch_size\": trial.params[\"batch_size\"] if \"batch_size\" in trial.params else 128,\n",
    "        \"channels_selected\": trial.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "        \"channels_idx_selected\": channels_to_channels_idx(trial.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "        \"model\": tf.keras.models.model_from_json(trial.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "        \"test_acc\": trial.user_attrs[\"trial_data\"][\"test_accuracy\"],\n",
    "        \"model_name\": trial.user_attrs[\"trial_data\"]['model_name'] if \"model_name\" in trial.user_attrs[\"trial_data\"] else \"shallow_conv_net\",\n",
    "    }\n",
    "    if \"weights\" in trial.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(trial.user_attrs[\"trial_data\"][\"weights\"])\n",
    "    elif \"model_weights\" in trial.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(trial.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "\n",
    "    return model_info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def load_best_trial(subject_best_trial):\n",
    "#     model = np.load(subject_best_trials[0], allow_pickle=True).item()\n",
    "#     model_info = {\n",
    "#         \"subject\": model.user_attrs[\"trial_data\"][\"subject\"] if hasattr(model.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(model.user_attrs[\"trial_data\"][\"data_path\"]).group(0).strip(\"[]\")),\n",
    "#         \"sfreq\": model.params[\"sfreq\"] if \"sfreq\" in model.params else 128,\n",
    "#         \"batch_size\": model.params[\"batch_size\"] if \"batch_size\" in model.params else 128,\n",
    "#         \"channels_selected\": model.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "#         \"channels_idx_selected\": channels_to_channels_idx(model.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "#         \"model\": tf.keras.models.model_from_json(model.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "#         \"test_acc\": model.user_attrs[\"trial_data\"][\"test_accuracy\"],\n",
    "#         \"model_name\": model.user_attrs[\"trial_data\"][\"model_name\"] if hasattr(model.user_attrs[\"trial_data\"], \"model_name\") else \"shallow_conv_net\"\n",
    "#     }\n",
    "#     if \"weights\" in model.user_attrs[\"trial_data\"]:\n",
    "#         model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "#     elif \"model_weights\" in model.user_attrs[\"trial_data\"]:\n",
    "#         model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "    \n",
    "#     return model_info\n",
    "\n",
    "def create_and_save_baseline_model(model_info, train_test_data, results_folder):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    model_info[\"model\"].compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    baseline_model_test = model_info[\"model\"].evaluate(X_test, y_test, batch_size=model_info[\"batch_size\"])\n",
    "    rpprint(baseline_model_test)\n",
    "\n",
    "    baseline_test_acc = baseline_model_test[1]\n",
    "\n",
    "    _, keras_file = None, results_folder + \"baseline_model.h5\"\n",
    "    tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n",
    "    return {\n",
    "        \"keras_file\": keras_file,\n",
    "        \"baseline_test_acc\": baseline_test_acc,\n",
    "        \"baseline_model\": model_info[\"model\"],\n",
    "    }\n",
    "\n",
    "def weight_prune_dense_layer(k_weights, b_weights, k_sparsity):\n",
    "    # Copy the kernel weights and get ranked indeces of the abs\n",
    "    kernel_weights = np.copy(k_weights)\n",
    "    kernel_weight_idx_by_magnitude = np.argsort(np.abs(kernel_weights), axis=None) # rank the individual weights in weight matrix according to their magnitude (absolute value)\n",
    "\n",
    "    kernel_weights_sparse_idx = kernel_weight_idx_by_magnitude[0:int(len(kernel_weight_idx_by_magnitude)*k_sparsity)]\n",
    "    kernel_weights[np.unravel_index(kernel_weights_sparse_idx, kernel_weights.shape) if len(kernel_weights_sparse_idx) > 0 else kernel_weights_sparse_idx] = 0\n",
    "\n",
    "    if b_weights is None:\n",
    "        return kernel_weights, None\n",
    "    \n",
    "    bias_weights = np.copy(b_weights)\n",
    "    bias_weights_idx_by_magnitude = np.argsort(np.abs(bias_weights), axis=None) # rank the individual weights in weight matrix according to their magnitude (absolute value)\n",
    "\n",
    "    bias_weights_sparse_idx = bias_weights_idx_by_magnitude[0:int(len(bias_weights_idx_by_magnitude)*k_sparsity)]\n",
    "    bias_weights[np.unravel_index(bias_weights_sparse_idx, bias_weights.shape)] = 0\n",
    "\n",
    "    return kernel_weights, bias_weights\n",
    "\n",
    "def prune_model(model_info, train_test_data, target_sparsity, results_folder):\n",
    "\n",
    "    X_train, y_train = train_test_data[\"X_train\"], train_test_data[\"y_train\"]\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    # batch_size = model_info[\"batch_size\"]\n",
    "    # epochs = 2\n",
    "    # end_step = np.ceil(len(X_train) / batch_size).astype(np.int32) * epochs\n",
    "    # # Define model for pruning.\n",
    "    # pruning_params = {\n",
    "    #     # 'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=target_sparsity, begin_step=0, frequency=1),\n",
    "    #     'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.00,\n",
    "    #                                                             final_sparsity=target_sparsity,\n",
    "    #                                                             begin_step=0,\n",
    "    #                                                             end_step=end_step,\n",
    "    #                                                             frequency=1)\n",
    "    # }\n",
    "    # keras.utils.get_custom_objects().update({\n",
    "    #     **CUSTOM_OBJECTS\n",
    "    # })\n",
    "    # baseline_model_copy = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    # model_for_pruning = prune_low_magnitude(baseline_model_copy, **pruning_params)\n",
    "    # # `prune_low_magnitude` requires a recompile.\n",
    "    # model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    keras.utils.get_custom_objects().update(CUSTOM_OBJECTS)\n",
    "    sparse_model = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    sparse_model.set_weights(model_info[\"model\"].get_weights())\n",
    "    for layer in model_info[\"model\"].layers:\n",
    "        if \"input\" in layer.name or len(layer.trainable_weights) == 0:\n",
    "            continue\n",
    "        if \"batch_normalization\" in layer.name:\n",
    "            continue\n",
    "        W = layer.get_weights()[0]\n",
    "        b = None\n",
    "        if \"batch_normalization\" not in layer.name and layer.use_bias:\n",
    "            b = layer.get_weights()[1]\n",
    "\n",
    "        if \"separable_conv2d\" in layer.name:\n",
    "            W = layer.get_weights()\n",
    "            W_0, bias_weights = weight_prune_dense_layer(W[0], b, target_sparsity)\n",
    "            W_1, _ = weight_prune_dense_layer(W[1], None, target_sparsity)\n",
    "            kernel_weights = [W_0, W_1]\n",
    "        else:\n",
    "            kernel_weights, bias_weights = weight_prune_dense_layer(W, b, target_sparsity)\n",
    "        # if pruning=='weight':\n",
    "            # rprint(layer.name, W.shape)\n",
    "        # elif pruning=='unit':\n",
    "        #     kernel_weights, bias_weights = unit_prune_dense_layer(W, b, k_sparsity)\n",
    "\n",
    "        # if \"separable_conv2d\" in layer.name:\n",
    "        #     rprint(layer.get_weights()[0].shape, layer.get_weights()[1].shape, kernel_weights.shape)\n",
    "        #     kernel_weights = kernel_weights[0]\n",
    "        \n",
    "        if \"separable_conv2d\" in layer.name:\n",
    "            sparse_model.get_layer(layer.name).set_weights(kernel_weights)\n",
    "        else:\n",
    "            sparse_model.get_layer(layer.name).set_weights([kernel_weights, bias_weights] if b is not None else [kernel_weights])\n",
    "\n",
    "    sparse_model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    model_for_pruning = sparse_model\n",
    "\n",
    "    # logdir = \"logs/pruning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # callbacks = [\n",
    "    #     tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    #     tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    # ]\n",
    "\n",
    "    # model_for_pruning.fit(X_train, y_train, batch_size=model_info[\"batch_size\"], epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "    _, model_for_pruning_accuracy = model_for_pruning.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    _, pruned_keras_file = None, results_folder + \"pruned_model.h5\"\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "\n",
    "    return {\n",
    "        \"pruned_model\": model_for_export,\n",
    "        \"pruned_model_test_acc\": model_for_pruning_accuracy,\n",
    "        \"pruned_keras_file\": pruned_keras_file\n",
    "    }\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    \n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def convert_pruned_model_to_tflite(pruned_model, sparsity, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # converter.target_spec.supported_types = [quantization]\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def convert_pruned_model_to_tflite_with_quantization(pruned_model, sparsity, quantization, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    if quantization == 'float16':\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    elif quantization == 'int8':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Quantization type {quantization} not implemented.\")\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity_{quantization}_quant.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_quant_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_quant_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def get_test_acc_non_tf_lite(model, train_test_data):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # Evaluate prediction accuracy of pruned model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=0)\n",
    "\n",
    "    # Evaluate Inference Time of pruned model\n",
    "    start_time = time.time()\n",
    "    prediction = model.predict(X_test)\n",
    "    exec_time = (time.time() - start_time)/X_test.shape[0]\n",
    "    return {\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"avg_exec_time\": exec_time\n",
    "    }\n",
    "\n",
    "def get_test_acc(model, train_test_data):\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "    def evaluate_model(interpreter):\n",
    "        input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        # signatures = interpreter.get_signature_list()\n",
    "        # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "        # Run predictions on every image in the \"test\" dataset.\n",
    "        predictions = []\n",
    "        exec_times = []\n",
    "        for i, v in enumerate(X_test):\n",
    "            v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "            # if i % 1000 == 0:\n",
    "            #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "            # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "            # # the model's input data format.\n",
    "            # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, v)\n",
    "\n",
    "            # Run inference.\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            exec_time = (time.time() - start_time)\n",
    "            exec_times.append(exec_time)\n",
    "\n",
    "            # Post-processing: remove batch dimension and find the digit with highest\n",
    "            # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "            predictions.append(class_prediction)\n",
    "\n",
    "        print('\\n')\n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        predictions = np.asarray(predictions)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "        avg_exec_time = np.mean(exec_times)\n",
    "        return accuracy, avg_exec_time\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    test_accuracy, avg_exec_time = evaluate_model(interpreter)\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"avg_exec_time\": avg_exec_time\n",
    "    }\n",
    "\n",
    "def get_model_weights_sparsity(model):\n",
    "    sparsity_levels = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "\n",
    "        for weight in weights:\n",
    "            # if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
    "            #     continue\n",
    "            weight_size = weight.numpy().size\n",
    "            zero_num = np.count_nonzero(weight == 0)\n",
    "            sparsity_levels.append((\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\",\n",
    "            ))\n",
    "    return sparsity_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Loading best trial model<span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/temp/FatigueMI/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/e0643f9a780146a4adc15ddd4a9ff053/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">shallow_conv_net_study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Loading best trial model\u001b[33m...\u001b[0m \n",
       ".\u001b[35m/temp/FatigueMI/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/e0643f9a780146a4adc15ddd4a9ff053/model/\u001b[0m\u001b[95mshallow_conv_net_study_best_trial.npy\u001b[0m \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'channels_selected'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'P3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'C3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Fz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'C4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'P4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F7'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F8'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&lt;U3'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'channels_idx_selected'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;tf_keras.src.engine.functional.Functional object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e08675050</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'shallow_conv_net'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'subject'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[1;36m256\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m96\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'channels_selected'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'P3'\u001b[0m, \u001b[32m'C3'\u001b[0m, \u001b[32m'Fz'\u001b[0m, \u001b[32m'F4'\u001b[0m, \u001b[32m'C4'\u001b[0m, \u001b[32m'P4'\u001b[0m, \u001b[32m'F7'\u001b[0m, \u001b[32m'F8'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mU3\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'channels_idx_selected'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m6\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m15\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'model'\u001b[0m\u001b[39m: <tf_keras.src.engine.functional.Functional object at \u001b[0m\u001b[1;36m0x7f0e08675050\u001b[0m\u001b[1m>\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.7272727489471436\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'shallow_conv_net'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n"
     ]
    }
   ],
   "source": [
    "# Folder structure for results: ./results/{subject}/{model}/{sparsity}/{quantization}/\n",
    "\n",
    "sparsity_levels = [0, 0.1, 0.5, 0.9]\n",
    "quantization_levels = [None, 'float16', 'int8']\n",
    "\n",
    "results_data = {\n",
    "    \"subject\": [],\n",
    "    \"model_name\": [],\n",
    "    \"sparsity\": [],\n",
    "    \"quantization\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"model_size\": [],\n",
    "    \"inf_time\": [],\n",
    "    \"weights_sparsity\": [],\n",
    "}\n",
    "\n",
    "for study_idx in [2]:\n",
    "# for study_idx in range(len(subject_best_trials)):\n",
    "\n",
    "    rprint(\"\\n\\n\\nLoading best trial model...\", subject_best_trials[study_idx][0], subject_best_trials[study_idx][1])\n",
    "\n",
    "    model_info = load_best_trial_from_study(study_idx, subject_best_trials)\n",
    "    subject = model_info[\"subject\"]\n",
    "    model_name = model_info[\"model_name\"]\n",
    "\n",
    "    rpprint(model_info)\n",
    "\n",
    "    # Make model info folder if not exists\n",
    "    os.makedirs(f\"./results/{subject}/{model_name}/\", exist_ok=True) if not os.path.exists(f\"./results/{subject}/{model_name}/\") else None\n",
    "    np.save(f\"./results/{subject}/{model_name}/model_info.npy\", { k: v for k, v in model_info.items() if k != \"model\"}, allow_pickle=True)\n",
    "\n",
    "    X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "    y_encoded = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "    train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "    for sparsity in sparsity_levels:\n",
    "        for quantization in quantization_levels:\n",
    "\n",
    "            rprint(f\"\\n\\n\\nSubject: {subject}, Model: {model_name}, Sparsity: {sparsity}, Quantization: {quantization}\\n\\n\")\n",
    "\n",
    "            results_folder = f\"./results/{subject}/{model_name}/{sparsity}/{quantization}/\"\n",
    "            os.makedirs(results_folder, exist_ok=True) if not os.path.exists(results_folder) else None # Make folder if doesn't exist\n",
    "\n",
    "            # region 1) ------------- Build & save baseline model ------------- \n",
    "            rprint(\"Building & saving baseline model...\")\n",
    "            baseline_model_info = create_and_save_baseline_model(**{\n",
    "                \"model_info\": model_info,\n",
    "                \"results_folder\": results_folder,\n",
    "                \"train_test_data\": train_test_data\n",
    "            })\n",
    "            keras_file, baseline_test_acc = baseline_model_info[\"keras_file\"], baseline_model_info[\"baseline_test_acc\"]\n",
    "            rprint('Saved baseline model to:', keras_file)\n",
    "            # endregion\n",
    "\n",
    "            # region 2) ------------- Pruning the baseline model -------------\n",
    "            rprint(\"Pruning the baseline model...\")\n",
    "            pruned_model_info = prune_model(**{\n",
    "                \"target_sparsity\": sparsity,\n",
    "                \"model_info\": model_info,\n",
    "                \"train_test_data\": train_test_data,\n",
    "                \"results_folder\": results_folder\n",
    "            })\n",
    "            \n",
    "            pruned_model = pruned_model_info[\"pruned_model\"]\n",
    "            pruned_model_test_acc, pruned_keras_file = pruned_model_info[\"pruned_model_test_acc\"], pruned_model_info[\"pruned_keras_file\"]\n",
    "            pruned_model_weights_sparsity = get_model_weights_sparsity(pruned_model)\n",
    "            model_weights_sparsity = pruned_model_weights_sparsity\n",
    "\n",
    "            rprint(f'Saved pruned Keras model with {sparsity*100}% sparsity to:', pruned_keras_file)\n",
    "            rpprint({\n",
    "                'Baseline test accuracy': baseline_test_acc,\n",
    "                'Pruned test accuracy': pruned_model_test_acc\n",
    "            })\n",
    "            # endregion\n",
    "\n",
    "            # region 3) ------------- Converting pruned model to TFLite -------------        \n",
    "            if quantization != None:\n",
    "                tflite_model_info = convert_pruned_model_to_tflite(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                pruned_tflite_model, pruned_tflite_file = tflite_model_info[\"pruned_tflite_model\"], tflite_model_info[\"pruned_tflite_file\"]\n",
    "                \n",
    "                rprint('Saved pruned TFLite model to:', pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "                rprint(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "            else:\n",
    "                pruned_tflite_model, pruned_tflite_file = None, None\n",
    "            # endregion\n",
    "\n",
    "            # region 4) ------------- Quantizing pruned TFLite model ------------- \n",
    "            if quantization != None:\n",
    "                tflite_quant_model_info = convert_pruned_model_to_tflite_with_quantization(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"quantization\": quantization,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                quantized_and_pruned_tflite_model = tflite_quant_model_info[\"pruned_quant_tflite_model\"]\n",
    "                quantized_and_pruned_tflite_file = tflite_quant_model_info[\"pruned_quant_tflite_file\"]\n",
    "\n",
    "                rprint('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "            else:\n",
    "                quantized_and_pruned_tflite_model, quantized_and_pruned_tflite_file = None, None\n",
    "            \n",
    "            # endregion\n",
    "\n",
    "            # region 5) ------------- Evaluation check -------------\n",
    "            if quantization != None:\n",
    "                tflite_quant_model_test_acc_results = get_test_acc(**{\n",
    "                    \"model\": quantized_and_pruned_tflite_model, \n",
    "                    \"train_test_data\": train_test_data\n",
    "                })\n",
    "                tflite_quant_model_test_acc = tflite_quant_model_test_acc_results[\"test_accuracy\"]\n",
    "\n",
    "                rprint('Pruned and quantized TFLite test_accuracy:', tflite_quant_model_test_acc)\n",
    "                rprint('Pruned TF test accuracy:', pruned_model_test_acc)\n",
    "            # endregion\n",
    "            \n",
    "            # region 6) ------------- Saving results -------------\n",
    "            if quantization != None:\n",
    "                model_objs = [{ \"model\": quantized_and_pruned_tflite_model, \"file\": quantized_and_pruned_tflite_file, \"tf_lite\": True, \"weights_sparsity\": model_weights_sparsity }]\n",
    "            else:\n",
    "                model_objs = [{ \"model\": pruned_model, \"file\": pruned_keras_file, \"tf_lite\": False, \"weights_sparsity\": model_weights_sparsity }]\n",
    "                \n",
    "            for model_obj in model_objs:\n",
    "                model_to_evaluate = model_obj[\"model\"]\n",
    "                model_file_to_evaluate = model_obj[\"file\"]\n",
    "                model_is_tf_lite = model_obj[\"tf_lite\"]\n",
    "                model_weights_sparsity = model_obj[\"weights_sparsity\"]\n",
    "\n",
    "                if model_to_evaluate == None or model_file_to_evaluate == None:\n",
    "                    continue\n",
    "\n",
    "                # 1) Test accuracy & inference time\n",
    "                if model_is_tf_lite:\n",
    "                    eval_res = get_test_acc(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                else:\n",
    "                    eval_res = get_test_acc_non_tf_lite(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                test_acc = eval_res[\"test_accuracy\"]\n",
    "                inf_time = eval_res[\"avg_exec_time\"]\n",
    "                # 2) Model size\n",
    "                model_size = get_gzipped_model_size(model_file_to_evaluate)\n",
    "\n",
    "                results_data[\"subject\"].append(subject)\n",
    "                results_data[\"model_name\"].append(model_name)\n",
    "                results_data[\"sparsity\"].append(sparsity)\n",
    "                results_data[\"quantization\"].append(quantization)\n",
    "                \n",
    "                results_data[\"test_acc\"].append(test_acc)\n",
    "                results_data[\"model_size\"].append(model_size)\n",
    "                results_data[\"inf_time\"].append(inf_time)\n",
    "\n",
    "                results_data[\"weights_sparsity\"].append(model_weights_sparsity)\n",
    "            # endregion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>quantization</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>model_size</th>\n",
       "      <th>inf_time</th>\n",
       "      <th>weights_sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>13109</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>[(conv2d_12/kernel:0: 0.00% sparsity , (0/560)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>7048</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>[(conv2d_12/kernel:0: 0.00% sparsity , (0/560)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>6998</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>[(conv2d_12/kernel:0: 0.00% sparsity , (0/560)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>12436</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>[(conv2d_12/kernel:0: 10.00% sparsity , (56/56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>6827</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>[(conv2d_12/kernel:0: 10.00% sparsity , (56/56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>6728</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>[(conv2d_12/kernel:0: 10.00% sparsity , (56/56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>8954</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>[(conv2d_12/kernel:0: 50.00% sparsity , (280/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>5208</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>[(conv2d_12/kernel:0: 50.00% sparsity , (280/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>5022</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>[(conv2d_12/kernel:0: 50.00% sparsity , (280/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>4643</td>\n",
       "      <td>0.014769</td>\n",
       "      <td>[(conv2d_12/kernel:0: 90.00% sparsity , (504/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>2957</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>[(conv2d_12/kernel:0: 90.00% sparsity , (504/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>2734</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>[(conv2d_12/kernel:0: 90.00% sparsity , (504/5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject        model_name  sparsity quantization  test_acc  model_size  \\\n",
       "0        11  shallow_conv_net       0.0         None  0.727273       13109   \n",
       "1        11  shallow_conv_net       0.0      float16  0.727273        7048   \n",
       "2        11  shallow_conv_net       0.0         int8  0.727273        6998   \n",
       "3        11  shallow_conv_net       0.1         None  0.727273       12436   \n",
       "4        11  shallow_conv_net       0.1      float16  0.727273        6827   \n",
       "5        11  shallow_conv_net       0.1         int8  0.727273        6728   \n",
       "6        11  shallow_conv_net       0.5         None  0.727273        8954   \n",
       "7        11  shallow_conv_net       0.5      float16  0.727273        5208   \n",
       "8        11  shallow_conv_net       0.5         int8  0.727273        5022   \n",
       "9        11  shallow_conv_net       0.9         None  0.590909        4643   \n",
       "10       11  shallow_conv_net       0.9      float16  0.590909        2957   \n",
       "11       11  shallow_conv_net       0.9         int8  0.590909        2734   \n",
       "\n",
       "    inf_time                                   weights_sparsity  \n",
       "0   0.019045  [(conv2d_12/kernel:0: 0.00% sparsity , (0/560)...  \n",
       "1   0.000376  [(conv2d_12/kernel:0: 0.00% sparsity , (0/560)...  \n",
       "2   0.000351  [(conv2d_12/kernel:0: 0.00% sparsity , (0/560)...  \n",
       "3   0.014267  [(conv2d_12/kernel:0: 10.00% sparsity , (56/56...  \n",
       "4   0.000446  [(conv2d_12/kernel:0: 10.00% sparsity , (56/56...  \n",
       "5   0.000492  [(conv2d_12/kernel:0: 10.00% sparsity , (56/56...  \n",
       "6   0.014712  [(conv2d_12/kernel:0: 50.00% sparsity , (280/5...  \n",
       "7   0.000238  [(conv2d_12/kernel:0: 50.00% sparsity , (280/5...  \n",
       "8   0.000355  [(conv2d_12/kernel:0: 50.00% sparsity , (280/5...  \n",
       "9   0.014769  [(conv2d_12/kernel:0: 90.00% sparsity , (504/5...  \n",
       "10  0.000306  [(conv2d_12/kernel:0: 90.00% sparsity , (504/5...  \n",
       "11  0.000314  [(conv2d_12/kernel:0: 90.00% sparsity , (504/5...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data_df = pd.DataFrame(results_data)\n",
    "results_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data_df.to_csv(\"./results/results_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_318353/3253146802.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  results_data_df.groupby(\"sparsity\").mean().plot.bar(y=\"test_acc\", rot=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sparsity'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_data_df.groupby(\"sparsity\").mean().plot.bar(y=\"test_acc\", rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning [0, 0.1, 0.5, 0.9]\n",
    "# 1. Load the best model\n",
    "# 2. Loop through its layers\n",
    "# 3. At each layer, set a random % of weights to zero (% sparsity)\n",
    "# 4. Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
