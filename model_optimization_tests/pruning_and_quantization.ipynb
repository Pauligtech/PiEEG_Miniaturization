{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-08 01:19:11.709881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-08 01:19:11.710032: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-08 01:19:11.714196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-08 01:19:11.736530: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 01:19:12.938460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "%load_ext tensorboard\n",
    "    \n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tf\"\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"0\"\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import keras\n",
    "    \n",
    "# region Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Permute, Dropout\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    ")\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "# endregion Keras\n",
    "\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_optim.utils import channels_to_channels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "# RNG = jax.random.PRNGKey(SKLRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Helper funcs\n",
    "def shallow_conv_net_square_layer(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "def shallow_conv_net_log_layer(x):\n",
    "    return tf.math.log(tf.clip_by_value(x, 1e-7, 10000))\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    \"shallow_conv_net_square_layer\": shallow_conv_net_square_layer, \n",
    "    \"shallow_conv_net_log_layer\": shallow_conv_net_log_layer \n",
    "}\n",
    "# endregion Helper funcs\n",
    "\n",
    "# region Models\n",
    "def shallow_conv_net(\n",
    "    nb_classes, channels, samples, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    From: https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
    "    \"\"\"\n",
    "\n",
    "    _POOL_SIZE_D2_ = kwargs.get(\"pool_size_d2\", 35)\n",
    "    _STRIDES_D2_ = kwargs.get(\"strides_d2\", 7)\n",
    "    _CONV_FILTERS_D2_ = kwargs.get(\"conv_filters_d2\", 13)\n",
    "\n",
    "    _POOL_SIZE_ = kwargs.get(\"pool_size\", (1, _POOL_SIZE_D2_))\n",
    "    _STRIDES_ = kwargs.get(\"strides\", (1, _STRIDES_D2_))\n",
    "    _CONV_FILTERS_ = kwargs.get(\"conv_filters\", (1, _CONV_FILTERS_D2_))\n",
    "\n",
    "    _CONV2D_1_UNITS_ = kwargs.get(\"conv2d_1_units\", 40)\n",
    "    _CONV2D_2_UNITS_ = kwargs.get(\"conv2d_2_units\", 40)\n",
    "    _L2_REG_1_ = kwargs.get(\"l2_reg_1\", 0.01)\n",
    "    _L2_REG_2_ = kwargs.get(\"l2_reg_2\", 0.01)\n",
    "    _L2_REG_3_ = kwargs.get(\"l2_reg_3\", 0.01)\n",
    "    _DROPOUT_RATE_ = kwargs.get(\"dropout_rate\", 0.5)\n",
    "\n",
    "    input_main = Input(shape=(channels, samples, 1))\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_1_UNITS_,\n",
    "        _CONV_FILTERS_,\n",
    "        input_shape=(channels, samples, 1),\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_1_),\n",
    "    )(input_main)\n",
    "    # block1       = Conv2D(40, (channels, 1), use_bias=False,\n",
    "    #                       kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_2_UNITS_,\n",
    "        (channels, 1),\n",
    "        use_bias=False,\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_2_),\n",
    "    )(block1)\n",
    "    block1 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1 = Activation(shallow_conv_net_square_layer)(block1)\n",
    "    block1 = AveragePooling2D(pool_size=_POOL_SIZE_, strides=_STRIDES_)(block1)\n",
    "    block1 = Activation(shallow_conv_net_log_layer)(block1)\n",
    "    block1 = Dropout(_DROPOUT_RATE_)(block1)\n",
    "    flatten = Flatten()(block1)\n",
    "    # dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    dense = Dense(\n",
    "        nb_classes,\n",
    "        kernel_constraint=max_norm(0.5),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_3_),\n",
    "    )(flatten)\n",
    "    softmax = Activation(\"softmax\")(dense)\n",
    "\n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "# endregion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_best_trials = glob.glob('./temp_v2/**/model/study_best_trial.npy', recursive=True)\n",
    "subject_best_trials = sorted(subject_best_trials, key=lambda x: os.path.getmtime(x))\n",
    "subject_best_trials = sorted(subject_best_trials, key=lambda x: int(re.compile(r\"\\[.*\\]\").search(x).group(0).strip(\"[]\")))\n",
    "\n",
    "# subject_best_trials = glob.glob('./temp/**/model/study_best_trial.npy', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[1]/292cbc92b8cf46da9986fe7d8447819f/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[2]/6405d11e654b42aca9df48458c67ecde/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[3]/9c1b753483db409a90eab7b7149b8af8/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[4]/3623cb4ba1ad4a908c9098f5297a6778/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[5]/d199c9c2ac924b238693f158eb88f675/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[6]/39d01251ff494106bf04f8a2cffcdd74/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[7]/aabe056cd1954a6f92ab47d84c86b1b8/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[8]/9fd82ec44ef3496da6307b57ecf4532f/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[9]/63a8c87ffc02471893db5ac9a0781946/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[10]/c2cc69dca74d4bfa81722cd634e6403e/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[11]/e0643f9a780146a4adc15ddd4a9ff053/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[12]/96dc576945fb4f2db582d66ae1d2c8ce/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[13]/1b189965ada44ff99e73fa145cd3901d/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[14]/a3304348c7094d02a024828ede942cda/model/study_best_trial.npy'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/292cbc92b8cf46da9986fe7d8447819f/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/6405d11e654b42aca9df48458c67ecde/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/9c1b753483db409a90eab7b7149b8af8/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/3623cb4ba1ad4a908c9098f5297a6778/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/d199c9c2ac924b238693f158eb88f675/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/39d01251ff494106bf04f8a2cffcdd74/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/aabe056cd1954a6f92ab47d84c86b1b8/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/9fd82ec44ef3496da6307b57ecf4532f/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/63a8c87ffc02471893db5ac9a0781946/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/c2cc69dca74d4bfa81722cd634e6403e/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/e0643f9a780146a4adc15ddd4a9ff053/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/96dc576945fb4f2db582d66ae1d2c8ce/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/1b189965ada44ff99e73fa145cd3901d/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/a3304348c7094d02a024828ede942cda/model/study_best_trial.npy'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint(subject_best_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_trial(subject_best_trial):\n",
    "    model = np.load(subject_best_trials[0], allow_pickle=True).item()\n",
    "    model_info = {\n",
    "        \"subject\": model.user_attrs[\"trial_data\"][\"subject\"] if hasattr(model.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(model.user_attrs[\"trial_data\"][\"data_path\"]).group(0).strip(\"[]\")),\n",
    "        \"sfreq\": model.params[\"sfreq\"] if \"sfreq\" in model.params else 128,\n",
    "        \"batch_size\": model.params[\"batch_size\"] if \"batch_size\" in model.params else 128,\n",
    "        \"channels_selected\": model.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "        \"channels_idx_selected\": channels_to_channels_idx(model.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "        \"model\": tf.keras.models.model_from_json(model.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "        \"test_acc\": model.user_attrs[\"trial_data\"][\"test_accuracy\"],\n",
    "        \"model_name\": model.user_attrs[\"trial_data\"][\"model_name\"] if hasattr(model.user_attrs[\"trial_data\"], \"model_name\") else \"shallow_conv_net\"\n",
    "    }\n",
    "    if \"weights\" in model.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "    elif \"model_weights\" in model.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "    \n",
    "    return model_info\n",
    "\n",
    "def create_and_save_baseline_model(model_info, train_test_data, results_folder):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    model_info[\"model\"].compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    baseline_model_test = model_info[\"model\"].evaluate(X_test, y_test, batch_size=model_info[\"batch_size\"])\n",
    "\n",
    "    baseline_test_acc = baseline_model_test[1]\n",
    "\n",
    "    _, keras_file = None, results_folder + \"baseline_model.h5\"\n",
    "    tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n",
    "    return {\n",
    "        \"keras_file\": keras_file,\n",
    "        \"baseline_test_acc\": baseline_test_acc,\n",
    "        \"baseline_model\": model_info[\"model\"],\n",
    "    }\n",
    "\n",
    "def weight_prune_dense_layer(k_weights, b_weights, k_sparsity):\n",
    "    # Copy the kernel weights and get ranked indeces of the abs\n",
    "    kernel_weights = np.copy(k_weights)\n",
    "    kernel_weight_idx_by_magnitude = np.argsort(np.abs(kernel_weights), axis=None) # rank the individual weights in weight matrix according to their magnitude (absolute value)\n",
    "\n",
    "    kernel_weights_sparse_idx = kernel_weight_idx_by_magnitude[0:int(len(kernel_weight_idx_by_magnitude)*k_sparsity)]\n",
    "    kernel_weights[np.unravel_index(kernel_weights_sparse_idx, kernel_weights.shape) if len(kernel_weights_sparse_idx) > 0 else kernel_weights_sparse_idx] = 0\n",
    "\n",
    "    if b_weights is None:\n",
    "        return kernel_weights, None\n",
    "    \n",
    "    bias_weights = np.copy(b_weights)\n",
    "    bias_weights_idx_by_magnitude = np.argsort(np.abs(bias_weights), axis=None) # rank the individual weights in weight matrix according to their magnitude (absolute value)\n",
    "\n",
    "    bias_weights_sparse_idx = bias_weights_idx_by_magnitude[0:int(len(bias_weights_idx_by_magnitude)*k_sparsity)]\n",
    "    bias_weights[np.unravel_index(bias_weights_sparse_idx, bias_weights.shape)] = 0\n",
    "\n",
    "    return kernel_weights, bias_weights\n",
    "\n",
    "def prune_model(model_info, train_test_data, target_sparsity, results_folder):\n",
    "\n",
    "    X_train, y_train = train_test_data[\"X_train\"], train_test_data[\"y_train\"]\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    # batch_size = model_info[\"batch_size\"]\n",
    "    # epochs = 2\n",
    "    # end_step = np.ceil(len(X_train) / batch_size).astype(np.int32) * epochs\n",
    "    # # Define model for pruning.\n",
    "    # pruning_params = {\n",
    "    #     # 'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=target_sparsity, begin_step=0, frequency=1),\n",
    "    #     'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.00,\n",
    "    #                                                             final_sparsity=target_sparsity,\n",
    "    #                                                             begin_step=0,\n",
    "    #                                                             end_step=end_step,\n",
    "    #                                                             frequency=1)\n",
    "    # }\n",
    "    # keras.utils.get_custom_objects().update({\n",
    "    #     **CUSTOM_OBJECTS\n",
    "    # })\n",
    "    # baseline_model_copy = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    # model_for_pruning = prune_low_magnitude(baseline_model_copy, **pruning_params)\n",
    "    # # `prune_low_magnitude` requires a recompile.\n",
    "    # model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    keras.utils.get_custom_objects().update(CUSTOM_OBJECTS)\n",
    "    sparse_model = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    sparse_model.set_weights(model_info[\"model\"].get_weights())\n",
    "    for layer in model_info[\"model\"].layers:\n",
    "        if \"input\" in layer.name or len(layer.trainable_weights) == 0:\n",
    "            continue\n",
    "        if \"batch_normalization\" in layer.name:\n",
    "            continue\n",
    "        W = layer.get_weights()[0]\n",
    "        b = None\n",
    "        if \"batch_normalization\" not in layer.name and layer.use_bias:\n",
    "            b = layer.get_weights()[1]\n",
    "\n",
    "        kernel_weights, bias_weights = weight_prune_dense_layer(W, b, target_sparsity)\n",
    "        # if pruning=='weight':\n",
    "            # rprint(layer.name, W.shape)\n",
    "        # elif pruning=='unit':\n",
    "        #     kernel_weights, bias_weights = unit_prune_dense_layer(W, b, k_sparsity)\n",
    "\n",
    "        sparse_model.get_layer(layer.name).set_weights([kernel_weights, bias_weights] if b is not None else [kernel_weights])\n",
    "\n",
    "    sparse_model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    model_for_pruning = sparse_model\n",
    "\n",
    "    # logdir = \"logs/pruning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # callbacks = [\n",
    "    #     tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    #     tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    # ]\n",
    "\n",
    "    # model_for_pruning.fit(X_train, y_train, batch_size=model_info[\"batch_size\"], epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "    _, model_for_pruning_accuracy = model_for_pruning.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    _, pruned_keras_file = None, results_folder + \"pruned_model.h5\"\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "\n",
    "    return {\n",
    "        \"pruned_model\": model_for_export,\n",
    "        \"pruned_model_test_acc\": model_for_pruning_accuracy,\n",
    "        \"pruned_keras_file\": pruned_keras_file\n",
    "    }\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    \n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def convert_pruned_model_to_tflite(pruned_model, sparsity, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # converter.target_spec.supported_types = [quantization]\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def convert_pruned_model_to_tflite_with_quantization(pruned_model, sparsity, quantization, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    if quantization == 'float16':\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    elif quantization == 'int8':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Quantization type {quantization} not implemented.\")\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity_{quantization}_quant.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_quant_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_quant_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def get_test_acc_non_tf_lite(model, train_test_data):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # Evaluate prediction accuracy of pruned model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=0)\n",
    "\n",
    "    # Evaluate Inference Time of pruned model\n",
    "    start_time = time.time()\n",
    "    prediction = model.predict(X_test)\n",
    "    exec_time = (time.time() - start_time)/X_test.shape[0]\n",
    "    return {\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"avg_exec_time\": exec_time\n",
    "    }\n",
    "\n",
    "def get_test_acc(model, train_test_data):\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "    def evaluate_model(interpreter):\n",
    "        input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        # signatures = interpreter.get_signature_list()\n",
    "        # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "        # Run predictions on every image in the \"test\" dataset.\n",
    "        predictions = []\n",
    "        exec_times = []\n",
    "        for i, v in enumerate(X_test):\n",
    "            v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "            # if i % 1000 == 0:\n",
    "            #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "            # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "            # # the model's input data format.\n",
    "            # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, v)\n",
    "\n",
    "            # Run inference.\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            exec_time = (time.time() - start_time)\n",
    "            exec_times.append(exec_time)\n",
    "\n",
    "            # Post-processing: remove batch dimension and find the digit with highest\n",
    "            # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "            predictions.append(class_prediction)\n",
    "\n",
    "        print('\\n')\n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        predictions = np.asarray(predictions)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "        avg_exec_time = np.mean(exec_times)\n",
    "        return accuracy, avg_exec_time\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    test_accuracy, avg_exec_time = evaluate_model(interpreter)\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"avg_exec_time\": avg_exec_time\n",
    "    }\n",
    "\n",
    "def get_model_weights_sparsity(model):\n",
    "    sparsity_levels = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "\n",
    "        for weight in weights:\n",
    "            # if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
    "            #     continue\n",
    "            weight_size = weight.numpy().size\n",
    "            zero_num = np.count_nonzero(weight == 0)\n",
    "            sparsity_levels.append((\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\",\n",
    "            ))\n",
    "    return sparsity_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Loading best trial model<span style=\"color: #808000; text-decoration-color: #808000\">...</span> .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/292cbc92b8cf46da9986fe7d8447819f/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Loading best trial model\u001b[33m...\u001b[0m .\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/292cbc92b8cf46da9986fe7d8447819f/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 01:19:19.390578: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:19.530024: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:19.530116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:19.532859: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:19.532948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:19.533039: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:21.282168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:21.282601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:21.282621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-08 01:19:21.282758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 01:19:21.282802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6593 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 300.0, returning unmodified.\n",
      "Adding metadata with 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 01:19:39.226402: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-04-08 01:19:41.331139: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-08 01:19:41.876456: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 18s 18s/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 351ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 704ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fbea41edc60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw295s1ch/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw295s1ch/assets\n",
      "2024-04-08 01:19:47.566409: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:19:47.566467: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:19:47.567271: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpw295s1ch\n",
      "2024-04-08 01:19:47.573977: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:19:47.574183: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpw295s1ch\n",
      "2024-04-08 01:19:47.578903: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-08 01:19:47.579548: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:19:47.599438: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpw295s1ch\n",
      "2024-04-08 01:19:47.611378: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 44115 microseconds.\n",
      "2024-04-08 01:19:47.633763: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model_0_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240943.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240943.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240939.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m240939.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237769.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m237769.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr5oi7q1u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr5oi7q1u/assets\n",
      "2024-04-08 01:19:48.998852: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:19:48.998912: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:19:48.999061: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpr5oi7q1u\n",
      "2024-04-08 01:19:49.000160: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:19:49.000171: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpr5oi7q1u\n",
      "2024-04-08 01:19:49.003198: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:19:49.021791: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpr5oi7q1u\n",
      "2024-04-08 01:19:49.035987: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 36924 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model_0_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240943.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240943.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119189.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m119189.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363636363636</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.8636363636363636\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fbe52761b20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fbe52761b20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 751ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkq8m21aj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkq8m21aj/assets\n",
      "2024-04-08 01:19:52.663061: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:19:52.663101: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:19:52.663235: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpkq8m21aj\n",
      "2024-04-08 01:19:52.664382: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:19:52.664392: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpkq8m21aj\n",
      "2024-04-08 01:19:52.669344: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:19:52.691309: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpkq8m21aj\n",
      "2024-04-08 01:19:52.699208: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 35974 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model_0_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240937.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240937.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240933.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m240933.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237763.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m237763.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp59xrnzly/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp59xrnzly/assets\n",
      "2024-04-08 01:19:54.213692: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:19:54.213747: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:19:54.213909: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp59xrnzly\n",
      "2024-04-08 01:19:54.215052: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:19:54.215065: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp59xrnzly\n",
      "2024-04-08 01:19:54.219571: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:19:54.247319: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp59xrnzly\n",
      "2024-04-08 01:19:54.264254: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 50345 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model_0_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240937.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240937.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66161.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m66161.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8181818181818182</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.8181818181818182\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 709ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.1/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.1/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 252ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 837ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph34e2d6c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph34e2d6c/assets\n",
      "2024-04-08 01:20:00.728148: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:00.728197: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:00.728346: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmph34e2d6c\n",
      "2024-04-08 01:20:00.729467: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:00.729481: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmph34e2d6c\n",
      "2024-04-08 01:20:00.732596: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:00.758327: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmph34e2d6c\n",
      "2024-04-08 01:20:00.773495: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 45150 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model_0.1_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240947.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240947.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224571.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m224571.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221642.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m221642.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp73i28b1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp73i28b1/assets\n",
      "2024-04-08 01:20:02.070554: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:02.070613: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:02.070877: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpp73i28b1\n",
      "2024-04-08 01:20:02.072998: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:02.073021: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpp73i28b1\n",
      "2024-04-08 01:20:02.081702: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:02.108256: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpp73i28b1\n",
      "2024-04-08 01:20:02.122063: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 51190 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model_0.1_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240947.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240947.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113859.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m113859.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363636363636</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.8636363636363636\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6q2_di_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6q2_di_2/assets\n",
      "2024-04-08 01:20:06.709060: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:06.709115: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:06.709350: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp6q2_di_2\n",
      "2024-04-08 01:20:06.711084: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:06.711139: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp6q2_di_2\n",
      "2024-04-08 01:20:06.714619: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:06.732716: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp6q2_di_2\n",
      "2024-04-08 01:20:06.741461: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 32113 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model_0.1_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240941.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240941.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224565.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m224565.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221636.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m221636.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn_981nxq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn_981nxq/assets\n",
      "2024-04-08 01:20:08.046787: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:08.046870: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:08.047059: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpn_981nxq\n",
      "2024-04-08 01:20:08.048266: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:08.048278: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpn_981nxq\n",
      "2024-04-08 01:20:08.051581: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:08.073546: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpn_981nxq\n",
      "2024-04-08 01:20:08.087040: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 39981 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model_0.1_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240941.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240941.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64358.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m64358.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363636363636</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.8636363636363636\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 779ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.5/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.5/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 273ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 922ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq96oj_za/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq96oj_za/assets\n",
      "2024-04-08 01:20:14.770445: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:14.770501: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:14.770665: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpq96oj_za\n",
      "2024-04-08 01:20:14.771992: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:14.772057: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpq96oj_za\n",
      "2024-04-08 01:20:14.775141: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:14.793562: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpq96oj_za\n",
      "2024-04-08 01:20:14.804018: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 33355 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model_0.5_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240947.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240947.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">138847.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m138847.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136426.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m136426.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgtcgcz3v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgtcgcz3v/assets\n",
      "2024-04-08 01:20:16.327196: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:16.327244: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:16.327386: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpgtcgcz3v\n",
      "2024-04-08 01:20:16.331771: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:16.331784: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpgtcgcz3v\n",
      "2024-04-08 01:20:16.342896: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:16.366551: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpgtcgcz3v\n",
      "2024-04-08 01:20:16.378437: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 51050 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model_0.5_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240947.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240947.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73966.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m73966.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636363636364</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.6363636363636364\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 755ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplck2gl0w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplck2gl0w/assets\n",
      "2024-04-08 01:20:20.699999: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:20.700109: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:20.700453: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmplck2gl0w\n",
      "2024-04-08 01:20:20.702096: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:20.702138: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmplck2gl0w\n",
      "2024-04-08 01:20:20.706186: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:20.740923: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmplck2gl0w\n",
      "2024-04-08 01:20:20.751623: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 51175 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model_0.5_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240941.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240941.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">138841.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m138841.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136420.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m136420.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7ypb0hfv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7ypb0hfv/assets\n",
      "2024-04-08 01:20:22.061275: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:22.061320: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:22.061459: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp7ypb0hfv\n",
      "2024-04-08 01:20:22.062663: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:22.062673: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp7ypb0hfv\n",
      "2024-04-08 01:20:22.065366: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:22.091389: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp7ypb0hfv\n",
      "2024-04-08 01:20:22.099027: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 37568 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model_0.5_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240941.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240941.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45911.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m45911.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636363636364</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.6363636363636364\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 773ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.9/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.9/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.40909090638160706\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 228ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 784ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.40909090638160706\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcdalbflu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcdalbflu/assets\n",
      "2024-04-08 01:20:29.115898: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:29.115940: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:29.116336: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpcdalbflu\n",
      "2024-04-08 01:20:29.118540: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:29.118610: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpcdalbflu\n",
      "2024-04-08 01:20:29.123956: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:29.143219: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpcdalbflu\n",
      "2024-04-08 01:20:29.157531: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 41202 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model_0.9_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240947.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240947.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35612.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m35612.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34171.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m34171.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2gzbal_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2gzbal_9/assets\n",
      "2024-04-08 01:20:30.575509: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:30.575580: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:30.576077: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp2gzbal_9\n",
      "2024-04-08 01:20:30.578275: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:30.578304: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp2gzbal_9\n",
      "2024-04-08 01:20:30.584017: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:30.609988: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp2gzbal_9\n",
      "2024-04-08 01:20:30.622652: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 46579 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model_0.9_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240947.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240947.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21234.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m21234.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4090909090909091</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.4090909090909091\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.40909090638160706\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/4060680392.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.40909090638160706\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphyl0dwvx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphyl0dwvx/assets\n",
      "2024-04-08 01:20:36.307722: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:36.307794: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:36.307974: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphyl0dwvx\n",
      "2024-04-08 01:20:36.309904: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:36.309946: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphyl0dwvx\n",
      "2024-04-08 01:20:36.315535: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:36.338160: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphyl0dwvx\n",
      "2024-04-08 01:20:36.348304: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 40332 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model_0.9_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240941.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240941.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35606.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m35606.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34165.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m34165.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5mhwks07/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5mhwks07/assets\n",
      "2024-04-08 01:20:37.692756: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-08 01:20:37.692848: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-08 01:20:37.693321: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp5mhwks07\n",
      "2024-04-08 01:20:37.695494: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-08 01:20:37.695605: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp5mhwks07\n",
      "2024-04-08 01:20:37.700351: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-08 01:20:37.721367: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp5mhwks07\n",
      "2024-04-08 01:20:37.728936: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 35620 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model_0.9_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240941.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240941.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15137.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m15137.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4090909090909091</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.4090909090909091\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.40909090638160706\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Folder structure for results: ./results/{subject}/{model}/{sparsity}/{quantization}/\n",
    "\n",
    "sparsity_levels = [0, 0.1, 0.5, 0.9]\n",
    "quantization_levels = [None, 'float16', 'int8']\n",
    "\n",
    "results_data = {\n",
    "    \"subject\": [],\n",
    "    \"model_name\": [],\n",
    "    \"sparsity\": [],\n",
    "    \"quantization\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"model_size\": [],\n",
    "    \"inf_time\": [],\n",
    "    \"weights_sparsity\": [],\n",
    "}\n",
    "\n",
    "for subject_best_trial in subject_best_trials[0:1]:\n",
    "\n",
    "    rprint(\"\\n\\n\\nLoading best trial model...\", subject_best_trial)\n",
    "\n",
    "    model_info = load_best_trial(subject_best_trial)\n",
    "    subject = model_info[\"subject\"]\n",
    "    model_name = model_info[\"model_name\"]\n",
    "\n",
    "    X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "    y_encoded = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "    train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "    for sparsity in sparsity_levels:\n",
    "        for quantization in quantization_levels:\n",
    "\n",
    "            rprint(f\"\\n\\n\\nSubject: {subject}, Model: {model_name}, Sparsity: {sparsity}, Quantization: {quantization}\\n\\n\")\n",
    "\n",
    "            results_folder = f\"./results/{subject}/{model_name}/{sparsity}/{quantization}/\"\n",
    "            os.makedirs(results_folder, exist_ok=True) if not os.path.exists(results_folder) else None # Make folder if doesn't exist\n",
    "\n",
    "            # region 1) ------------- Build & save baseline model ------------- \n",
    "            rprint(\"Building & saving baseline model...\")\n",
    "            baseline_model_info = create_and_save_baseline_model(**{\n",
    "                \"model_info\": model_info,\n",
    "                \"results_folder\": results_folder,\n",
    "                \"train_test_data\": train_test_data\n",
    "            })\n",
    "            keras_file, baseline_test_acc = baseline_model_info[\"keras_file\"], baseline_model_info[\"baseline_test_acc\"]\n",
    "            rprint('Saved baseline model to:', keras_file)\n",
    "            # endregion\n",
    "\n",
    "            # region 2) ------------- Pruning the baseline model -------------\n",
    "            rprint(\"Pruning the baseline model...\")\n",
    "            pruned_model_info = prune_model(**{\n",
    "                \"target_sparsity\": sparsity,\n",
    "                \"model_info\": model_info,\n",
    "                \"train_test_data\": train_test_data,\n",
    "                \"results_folder\": results_folder\n",
    "            })\n",
    "            \n",
    "            pruned_model = pruned_model_info[\"pruned_model\"]\n",
    "            pruned_model_test_acc, pruned_keras_file = pruned_model_info[\"pruned_model_test_acc\"], pruned_model_info[\"pruned_keras_file\"]\n",
    "            pruned_model_weights_sparsity = get_model_weights_sparsity(pruned_model)\n",
    "            model_weights_sparsity = pruned_model_weights_sparsity\n",
    "\n",
    "            rprint(f'Saved pruned Keras model with {sparsity*100}% sparsity to:', pruned_keras_file)\n",
    "            rpprint({\n",
    "                'Baseline test accuracy': baseline_test_acc,\n",
    "                'Pruned test accuracy': pruned_model_test_acc\n",
    "            })\n",
    "            # endregion\n",
    "\n",
    "            # region 3) ------------- Converting pruned model to TFLite -------------        \n",
    "            if quantization != None:\n",
    "                tflite_model_info = convert_pruned_model_to_tflite(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                pruned_tflite_model, pruned_tflite_file = tflite_model_info[\"pruned_tflite_model\"], tflite_model_info[\"pruned_tflite_file\"]\n",
    "                \n",
    "                rprint('Saved pruned TFLite model to:', pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "                rprint(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "            else:\n",
    "                pruned_tflite_model, pruned_tflite_file = None, None\n",
    "            # endregion\n",
    "\n",
    "            # region 4) ------------- Quantizing pruned TFLite model ------------- \n",
    "            if quantization != None:\n",
    "                tflite_quant_model_info = convert_pruned_model_to_tflite_with_quantization(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"quantization\": quantization,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                quantized_and_pruned_tflite_model = tflite_quant_model_info[\"pruned_quant_tflite_model\"]\n",
    "                quantized_and_pruned_tflite_file = tflite_quant_model_info[\"pruned_quant_tflite_file\"]\n",
    "\n",
    "                rprint('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "            else:\n",
    "                quantized_and_pruned_tflite_model, quantized_and_pruned_tflite_file = None, None\n",
    "            \n",
    "            # endregion\n",
    "\n",
    "            # region 5) ------------- Evaluation check -------------\n",
    "            if quantization != None:\n",
    "                tflite_quant_model_test_acc_results = get_test_acc(**{\n",
    "                    \"model\": quantized_and_pruned_tflite_model, \n",
    "                    \"train_test_data\": train_test_data\n",
    "                })\n",
    "                tflite_quant_model_test_acc = tflite_quant_model_test_acc_results[\"test_accuracy\"]\n",
    "\n",
    "                rprint('Pruned and quantized TFLite test_accuracy:', tflite_quant_model_test_acc)\n",
    "                rprint('Pruned TF test accuracy:', pruned_model_test_acc)\n",
    "            # endregion\n",
    "            \n",
    "            # region 6) ------------- Saving results -------------\n",
    "            if quantization != None:\n",
    "                model_objs = [{ \"model\": quantized_and_pruned_tflite_model, \"file\": quantized_and_pruned_tflite_file, \"tf_lite\": True, \"weights_sparsity\": model_weights_sparsity }]\n",
    "            else:\n",
    "                model_objs = [{ \"model\": pruned_model, \"file\": pruned_keras_file, \"tf_lite\": False, \"weights_sparsity\": model_weights_sparsity }]\n",
    "                \n",
    "            for model_obj in model_objs:\n",
    "                model_to_evaluate = model_obj[\"model\"]\n",
    "                model_file_to_evaluate = model_obj[\"file\"]\n",
    "                model_is_tf_lite = model_obj[\"tf_lite\"]\n",
    "                model_weights_sparsity = model_obj[\"weights_sparsity\"]\n",
    "\n",
    "                if model_to_evaluate == None or model_file_to_evaluate == None:\n",
    "                    continue\n",
    "\n",
    "                # 1) Test accuracy & inference time\n",
    "                if model_is_tf_lite:\n",
    "                    eval_res = get_test_acc(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                else:\n",
    "                    eval_res = get_test_acc_non_tf_lite(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                test_acc = eval_res[\"test_accuracy\"]\n",
    "                inf_time = eval_res[\"avg_exec_time\"]\n",
    "                # 2) Model size\n",
    "                model_size = get_gzipped_model_size(model_file_to_evaluate)\n",
    "\n",
    "                results_data[\"subject\"].append(subject)\n",
    "                results_data[\"model_name\"].append(model_name)\n",
    "                results_data[\"sparsity\"].append(sparsity)\n",
    "                results_data[\"quantization\"].append(quantization)\n",
    "                \n",
    "                results_data[\"test_acc\"].append(test_acc)\n",
    "                results_data[\"model_size\"].append(model_size)\n",
    "                results_data[\"inf_time\"].append(inf_time)\n",
    "\n",
    "                results_data[\"weights_sparsity\"].append(model_weights_sparsity)\n",
    "            # endregion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>quantization</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>model_size</th>\n",
       "      <th>inf_time</th>\n",
       "      <th>weights_sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>240933</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>[(conv2d_18/kernel:0: 0.00% sparsity , (0/7200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>119189</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>[(conv2d_18/kernel:0: 0.00% sparsity , (0/7200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>66161</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>[(conv2d_18/kernel:0: 0.00% sparsity , (0/7200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>224565</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>[(conv2d_18/kernel:0: 10.00% sparsity , (720/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>113859</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>[(conv2d_18/kernel:0: 10.00% sparsity , (720/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>64358</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>[(conv2d_18/kernel:0: 10.00% sparsity , (720/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>138841</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>[(conv2d_18/kernel:0: 50.00% sparsity , (3600/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>73966</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>[(conv2d_18/kernel:0: 50.00% sparsity , (3600/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>45911</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>[(conv2d_18/kernel:0: 50.00% sparsity , (3600/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>35606</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>[(conv2d_18/kernel:0: 90.00% sparsity , (6480/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>21234</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>[(conv2d_18/kernel:0: 90.00% sparsity , (6480/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>15137</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>[(conv2d_18/kernel:0: 90.00% sparsity , (6480/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject        model_name  sparsity quantization  test_acc  model_size  \\\n",
       "0         1  shallow_conv_net       0.0         None  0.863636      240933   \n",
       "1         1  shallow_conv_net       0.0      float16  0.863636      119189   \n",
       "2         1  shallow_conv_net       0.0         int8  0.818182       66161   \n",
       "3         1  shallow_conv_net       0.1         None  0.863636      224565   \n",
       "4         1  shallow_conv_net       0.1      float16  0.863636      113859   \n",
       "5         1  shallow_conv_net       0.1         int8  0.863636       64358   \n",
       "6         1  shallow_conv_net       0.5         None  0.636364      138841   \n",
       "7         1  shallow_conv_net       0.5      float16  0.636364       73966   \n",
       "8         1  shallow_conv_net       0.5         int8  0.636364       45911   \n",
       "9         1  shallow_conv_net       0.9         None  0.409091       35606   \n",
       "10        1  shallow_conv_net       0.9      float16  0.409091       21234   \n",
       "11        1  shallow_conv_net       0.9         int8  0.409091       15137   \n",
       "\n",
       "    inf_time                                   weights_sparsity  \n",
       "0   0.017883  [(conv2d_18/kernel:0: 0.00% sparsity , (0/7200...  \n",
       "1   0.004205  [(conv2d_18/kernel:0: 0.00% sparsity , (0/7200...  \n",
       "2   0.007031  [(conv2d_18/kernel:0: 0.00% sparsity , (0/7200...  \n",
       "3   0.013710  [(conv2d_18/kernel:0: 10.00% sparsity , (720/7...  \n",
       "4   0.005957  [(conv2d_18/kernel:0: 10.00% sparsity , (720/7...  \n",
       "5   0.007011  [(conv2d_18/kernel:0: 10.00% sparsity , (720/7...  \n",
       "6   0.015405  [(conv2d_18/kernel:0: 50.00% sparsity , (3600/...  \n",
       "7   0.008385  [(conv2d_18/kernel:0: 50.00% sparsity , (3600/...  \n",
       "8   0.006603  [(conv2d_18/kernel:0: 50.00% sparsity , (3600/...  \n",
       "9   0.013433  [(conv2d_18/kernel:0: 90.00% sparsity , (6480/...  \n",
       "10  0.004265  [(conv2d_18/kernel:0: 90.00% sparsity , (6480/...  \n",
       "11  0.007620  [(conv2d_18/kernel:0: 90.00% sparsity , (6480/...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data_df = pd.DataFrame(results_data)\n",
    "results_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424880/3253146802.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  results_data_df.groupby(\"sparsity\").mean().plot.bar(y=\"test_acc\", rot=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sparsity'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_data_df.groupby(\"sparsity\").mean().plot.bar(y=\"test_acc\", rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning [0, 0.1, 0.5, 0.9]\n",
    "# 1. Load the best model\n",
    "# 2. Loop through its layers\n",
    "# 3. At each layer, set a random % of weights to zero (% sparsity)\n",
    "# 4. Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
