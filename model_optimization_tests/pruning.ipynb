{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-24 15:26:06.323201: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-24 15:26:06.323270: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-24 15:26:06.324638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-24 15:26:06.331994: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 15:26:07.903551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "%load_ext tensorboard\n",
    "    \n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tf\"\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"0\"\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import keras\n",
    "    \n",
    "# region Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Permute, Dropout\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    ")\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "# endregion Keras\n",
    "\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_optim.utils import channels_to_channels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "# RNG = jax.random.PRNGKey(SKLRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/[1]/8ca44c9b9c7c4410b37ac5781bd7da1f/model/study_best_trial.npy'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'./temp/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/8ca44c9b9c7c4410b37ac5781bd7da1f/model/study_best_trial.npy'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject_best_trials = glob.glob('./temp/**/model/study_best_trial.npy', recursive=True)\n",
    "subject_best_trials = sorted(subject_best_trials, key=lambda x: os.path.getmtime(x))\n",
    "\n",
    "subject_all_trials = glob.glob('./temp/**/model/study.npy', recursive=True)\n",
    "subject_all_trials = sorted(subject_all_trials, key=lambda x: os.path.getmtime(x))\n",
    "\n",
    "rpprint(subject_best_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Helper funcs\n",
    "def shallow_conv_net_square_layer(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "def shallow_conv_net_log_layer(x):\n",
    "    return tf.math.log(tf.clip_by_value(x, 1e-7, 10000))\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    \"shallow_conv_net_square_layer\": shallow_conv_net_square_layer, \n",
    "    \"shallow_conv_net_log_layer\": shallow_conv_net_log_layer \n",
    "}\n",
    "# endregion Helper funcs\n",
    "\n",
    "# region Models\n",
    "def shallow_conv_net(\n",
    "    nb_classes, channels, samples, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    From: https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
    "    \"\"\"\n",
    "\n",
    "    _POOL_SIZE_D2_ = kwargs.get(\"pool_size_d2\", 35)\n",
    "    _STRIDES_D2_ = kwargs.get(\"strides_d2\", 7)\n",
    "    _CONV_FILTERS_D2_ = kwargs.get(\"conv_filters_d2\", 13)\n",
    "\n",
    "    _POOL_SIZE_ = kwargs.get(\"pool_size\", (1, _POOL_SIZE_D2_))\n",
    "    _STRIDES_ = kwargs.get(\"strides\", (1, _STRIDES_D2_))\n",
    "    _CONV_FILTERS_ = kwargs.get(\"conv_filters\", (1, _CONV_FILTERS_D2_))\n",
    "\n",
    "    _CONV2D_1_UNITS_ = kwargs.get(\"conv2d_1_units\", 40)\n",
    "    _CONV2D_2_UNITS_ = kwargs.get(\"conv2d_2_units\", 40)\n",
    "    _L2_REG_1_ = kwargs.get(\"l2_reg_1\", 0.01)\n",
    "    _L2_REG_2_ = kwargs.get(\"l2_reg_2\", 0.01)\n",
    "    _L2_REG_3_ = kwargs.get(\"l2_reg_3\", 0.01)\n",
    "    _DROPOUT_RATE_ = kwargs.get(\"dropout_rate\", 0.5)\n",
    "\n",
    "    input_main = Input(shape=(channels, samples, 1))\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_1_UNITS_,\n",
    "        _CONV_FILTERS_,\n",
    "        input_shape=(channels, samples, 1),\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_1_),\n",
    "    )(input_main)\n",
    "    # block1       = Conv2D(40, (channels, 1), use_bias=False,\n",
    "    #                       kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_2_UNITS_,\n",
    "        (channels, 1),\n",
    "        use_bias=False,\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_2_),\n",
    "    )(block1)\n",
    "    block1 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1 = Activation(shallow_conv_net_square_layer)(block1)\n",
    "    block1 = AveragePooling2D(pool_size=_POOL_SIZE_, strides=_STRIDES_)(block1)\n",
    "    block1 = Activation(shallow_conv_net_log_layer)(block1)\n",
    "    block1 = Dropout(_DROPOUT_RATE_)(block1)\n",
    "    flatten = Flatten()(block1)\n",
    "    # dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    dense = Dense(\n",
    "        nb_classes,\n",
    "        kernel_constraint=max_norm(0.5),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_3_),\n",
    "    )(flatten)\n",
    "    softmax = Activation(\"softmax\")(dense)\n",
    "\n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "# endregion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(study):\n",
    "        trial_metrics_dict = {\n",
    "            \"subjects\": [],\n",
    "            \"model\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"test_acc\": [],\n",
    "            \"val_acc\": [],\n",
    "            \"train_val_acc_diff\": [],\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_val_loss_diff\": [],\n",
    "            \"test_loss\": [],\n",
    "            \"scores\": [],\n",
    "            \"channels_selected\": [],\n",
    "            \"num_channels_selected\": [],\n",
    "            \"sfreq\": [],\n",
    "            \"batch_size\": [],\n",
    "            \"num_training_epochs\": [],\n",
    "            \"train_time\": [],\n",
    "            \"inf_time\": [],\n",
    "        }\n",
    "        # for res_file_name in res_files:\n",
    "        #     res = np.load(res_file_name, allow_pickle=True).item()\n",
    "        #     study = res[\"study\"]\n",
    "        for i, trial in enumerate(study.trials_dataframe().itertuples()):\n",
    "            trial_user_attrs = trial.user_attrs_trial_data\n",
    "            trial_metrics_dict[\"scores\"].append(trial.value)\n",
    "            trial_metrics_dict[\"subjects\"].append(trial_user_attrs[\"subjects\"])\n",
    "            trial_metrics_dict[\"model\"].append(trial_user_attrs[\"model_name\"]) if \"model_name\" in trial_user_attrs else None\n",
    "            trial_metrics_dict[\"train_time\"].append(trial_user_attrs[\"training_time\"]) if \"training_time\" in trial_user_attrs else None\n",
    "            trial_metrics_dict[\"inf_time\"].append(trial_user_attrs[\"inference_time\"]) if \"inference_time\" in trial_user_attrs else None\n",
    "            trial_metrics_dict[\"num_training_epochs\"].append(trial_user_attrs[\"num_training_epochs\"] if \"num_training_epochs\" in trial_user_attrs else None)\n",
    "            trial_metrics_dict[\"train_acc\"].append(\n",
    "                np.max(trial_user_attrs[\"train_accuracy\"])\n",
    "            )\n",
    "            trial_metrics_dict[\"test_acc\"].append(trial_user_attrs[\"test_accuracy\"])\n",
    "            trial_metrics_dict[\"val_acc\"].append(\n",
    "                np.max(trial_user_attrs[\"val_accuracy\"])\n",
    "            )\n",
    "            trial_metrics_dict[\"channels_selected\"].append(\n",
    "                trial_user_attrs[\"channels_selected\"]\n",
    "            )\n",
    "            trial_metrics_dict[\"num_channels_selected\"].append(\n",
    "                len(trial_user_attrs[\"channels_selected\"])\n",
    "            )\n",
    "            trial_metrics_dict[\"train_val_acc_diff\"].append(\n",
    "                abs(\n",
    "                    np.max(trial_user_attrs[\"train_accuracy\"])\n",
    "                    - np.max(trial_user_attrs[\"val_accuracy\"])\n",
    "                )\n",
    "            )\n",
    "            (\n",
    "                trial_metrics_dict[\"train_loss\"].append(\n",
    "                    np.min(trial_user_attrs[\"train_loss\"])\n",
    "                    if \"train_loss\" in trial_user_attrs\n",
    "                    else None\n",
    "                )\n",
    "            )\n",
    "            (\n",
    "                trial_metrics_dict[\"val_loss\"].append(\n",
    "                    np.min(trial_user_attrs[\"val_loss\"])\n",
    "                    if \"val_loss\" in trial_user_attrs\n",
    "                    else None\n",
    "                )\n",
    "            )\n",
    "            (\n",
    "                trial_metrics_dict[\"train_val_loss_diff\"].append(\n",
    "                    abs(\n",
    "                        np.min(trial_user_attrs[\"train_loss\"])\n",
    "                        - np.min(trial_user_attrs[\"val_loss\"])\n",
    "                    )\n",
    "                    if \"train_loss\" in trial_user_attrs\n",
    "                    and \"val_loss\" in trial_user_attrs\n",
    "                    else None\n",
    "                )\n",
    "            )\n",
    "            (\n",
    "                trial_metrics_dict[\"test_loss\"].append(\n",
    "                    np.min(trial_user_attrs[\"test_loss\"])\n",
    "                    if \"test_loss\" in trial_user_attrs\n",
    "                    else None\n",
    "                )\n",
    "            )\n",
    "            trial_metrics_dict[\"sfreq\"].append(\n",
    "                trial.params_sfreq if hasattr(trial, \"params_sfreq\") else (trial_user_attrs[\"sfreq\"] if \"sfreq\" in trial_user_attrs else None)\n",
    "            )\n",
    "            trial_metrics_dict[\"batch_size\"].append(\n",
    "                trial.params_batch_size if hasattr(trial, \"params_batch_size\") else (trial_user_attrs[\"batch_size\"] if \"batch_size\" in trial_user_attrs else None)\n",
    "            )\n",
    "        # Delete any entries in the dictionary that are empty lists\n",
    "        trial_metrics_dict = {\n",
    "            k: v\n",
    "            for k, v in trial_metrics_dict.items()\n",
    "            if len([x for x in v if x is not None]) > 0\n",
    "        }\n",
    "        \n",
    "        trial_metrics_df = pd.DataFrame(trial_metrics_dict)\n",
    "        return trial_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>num_channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1]</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.145425</td>\n",
       "      <td>10.666684</td>\n",
       "      <td>10.572948</td>\n",
       "      <td>0.093737</td>\n",
       "      <td>10.993606</td>\n",
       "      <td>0.077611</td>\n",
       "      <td>[P3, F4, P4, Pz, O1, F7, F8, A2, T6]</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1]</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.171569</td>\n",
       "      <td>13.874846</td>\n",
       "      <td>12.969428</td>\n",
       "      <td>0.905418</td>\n",
       "      <td>13.003958</td>\n",
       "      <td>0.111511</td>\n",
       "      <td>[F3, F4, C4, P4, T3, O1, F8, T4]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>10.528308</td>\n",
       "      <td>10.074472</td>\n",
       "      <td>0.453835</td>\n",
       "      <td>12.001544</td>\n",
       "      <td>0.151585</td>\n",
       "      <td>[P3, C4, P4, O2, F7, F8, A2]</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1]</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.212418</td>\n",
       "      <td>66.014801</td>\n",
       "      <td>62.986416</td>\n",
       "      <td>3.028385</td>\n",
       "      <td>63.090633</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>[P3, C3, F3, F4, C4, P4, Fp1, O2, T6, T4]</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1]</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.297386</td>\n",
       "      <td>24.199411</td>\n",
       "      <td>22.264116</td>\n",
       "      <td>1.935295</td>\n",
       "      <td>22.316408</td>\n",
       "      <td>0.197981</td>\n",
       "      <td>[F3, Cz, Pz, T3, O1, O2, F8, A2, T4]</td>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjects  train_acc  test_acc   val_acc  train_val_acc_diff  train_loss  \\\n",
       "9       [1]   0.867647  0.681818  0.722222            0.145425   10.666684   \n",
       "7       [1]   0.838235  0.545455  0.666667            0.171569   13.874846   \n",
       "15      [1]   1.000000  0.500000  0.611111            0.388889   10.528308   \n",
       "14      [1]   0.823529  0.500000  0.611111            0.212418   66.014801   \n",
       "8       [1]   0.852941  0.590909  0.555556            0.297386   24.199411   \n",
       "\n",
       "     val_loss  train_val_loss_diff  test_loss    scores  \\\n",
       "9   10.572948             0.093737  10.993606  0.077611   \n",
       "7   12.969428             0.905418  13.003958  0.111511   \n",
       "15  10.074472             0.453835  12.001544  0.151585   \n",
       "14  62.986416             3.028385  63.090633  0.151735   \n",
       "8   22.264116             1.935295  22.316408  0.197981   \n",
       "\n",
       "                            channels_selected  num_channels_selected  sfreq  \\\n",
       "9        [P3, F4, P4, Pz, O1, F7, F8, A2, T6]                      9    300   \n",
       "7            [F3, F4, C4, P4, T3, O1, F8, T4]                      8    128   \n",
       "15               [P3, C4, P4, O2, F7, F8, A2]                      7    128   \n",
       "14  [P3, C3, F3, F4, C4, P4, Fp1, O2, T6, T4]                     10    300   \n",
       "8        [F3, Cz, Pz, T3, O1, O2, F8, A2, T4]                      9    128   \n",
       "\n",
       "    batch_size  \n",
       "9          160  \n",
       "7           32  \n",
       "15          96  \n",
       "14         128  \n",
       "8          256  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_df(\n",
    "    np.load(subject_all_trials[0], allow_pickle=True).item()\n",
    ").sort_values(by=\"scores\", ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 15:26:12.093527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:12.128354: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:12.128421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:12.130920: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:12.131091: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:12.131149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:14.334268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:14.334576: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:14.334600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-24 15:26:14.334717: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 15:26:14.334749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6593 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'channels_selected'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'P3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'P4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'O1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F7'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F8'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'T6'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&lt;U3'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'channels_idx_selected'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;keras.src.engine.functional.Functional object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f730a624390</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'subject'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[1;36m300\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m160\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'channels_selected'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'P3'\u001b[0m, \u001b[32m'F4'\u001b[0m, \u001b[32m'P4'\u001b[0m, \u001b[32m'Pz'\u001b[0m, \u001b[32m'O1'\u001b[0m, \u001b[32m'F7'\u001b[0m, \u001b[32m'F8'\u001b[0m, \u001b[32m'A2'\u001b[0m, \u001b[32m'T6'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mU3\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'channels_idx_selected'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m6\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m13\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m15\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m16\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m17\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'model'\u001b[0m\u001b[39m: <keras.src.engine.functional.Functional object at \u001b[0m\u001b[1;36m0x7f730a624390\u001b[0m\u001b[1m>\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = np.load(subject_best_trials[0], allow_pickle=True).item()\n",
    "model_info = {\n",
    "    \"subject\": model.user_attrs[\"trial_data\"][\"subject\"] if hasattr(model.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(model.user_attrs[\"trial_data\"][\"data_path\"]).group(0).strip(\"[]\")),\n",
    "    \"sfreq\": model.params[\"sfreq\"] if \"sfreq\" in model.params else 128,\n",
    "    \"batch_size\": model.params[\"batch_size\"] if \"batch_size\" in model.params else 128,\n",
    "    \"channels_selected\": model.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "    \"channels_idx_selected\": channels_to_channels_idx(model.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "    \"model\": tf.keras.models.model_from_json(model.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "    \"test_acc\": model.user_attrs[\"trial_data\"][\"test_accuracy\"]\n",
    "}\n",
    "if \"weights\" in model.user_attrs[\"trial_data\"]:\n",
    "    model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "elif \"model_weights\" in model.user_attrs[\"trial_data\"]:\n",
    "    model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "\n",
    "rpprint(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 300.0, returning unmodified.\n",
      "Adding metadata with 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 15:26:17.354949: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-03-24 15:26:18.666268: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-24 15:26:18.972761: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    }
   ],
   "source": [
    "X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "\n",
    "model_info[\"model\"].compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "baseline_model_test = model_info[\"model\"].evaluate(X_test, y_test, batch_size=model_info[\"batch_size\"])\n",
    "\n",
    "baseline_test_acc = baseline_model_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_188098/3390911264.py:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_model_export/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/temp_model_export/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, keras_file = None, \"./temp_model_export/baseline_model.h5\"\n",
    "tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n",
    "rprint('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp_model = tf.keras.Model(\n",
    "# #     inputs=model_info[\"model\"].inputs,\n",
    "# #     outputs=model_info[\"model\"].outputs\n",
    "# # )\n",
    "# # temp_model.set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "\n",
    "# isinstance(model_info[\"model\"], tf.keras.Model), model_info[\"model\"]._is_graph_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.ceil(60000 / 128).astype(np.int32) * 2\n",
    "\n",
    "# np.ceil(len(X_train) / model_info[\"batch_size\"]).astype(np.int32) * epochs\n",
    "\n",
    "# 60000 / 128\n",
    "\n",
    "# len(X_train) / model_info[\"batch_size\"]\n",
    "\n",
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 9, 601, 1)]       0         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 9, 579, 70)        3292      \n",
      " _20 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 1, 579, 30)        37802     \n",
      " _21 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_  (None, 1, 579, 30)        121       \n",
      " normalization_10 (PruneLow                                      \n",
      " Magnitude)                                                      \n",
      "                                                                 \n",
      " prune_low_magnitude_activa  (None, 1, 579, 30)        1         \n",
      " tion_30 (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_averag  (None, 1, 25, 30)         1         \n",
      " e_pooling2d_10 (PruneLowMa                                      \n",
      " gnitude)                                                        \n",
      "                                                                 \n",
      " prune_low_magnitude_activa  (None, 1, 25, 30)         1         \n",
      " tion_31 (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 1, 25, 30)         1         \n",
      " t_10 (PruneLowMagnitude)                                        \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 750)               1         \n",
      " n_10 (PruneLowMagnitude)                                        \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 2)                 3004      \n",
      " 10 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_activa  (None, 2)                 1         \n",
      " tion_32 (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44225 (172.79 KB)\n",
      "Trainable params: 22142 (86.49 KB)\n",
      "Non-trainable params: 22083 (86.30 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "batch_size = model_info[\"batch_size\"]\n",
    "epochs = 5\n",
    "end_step = np.ceil(len(X_train) / batch_size).astype(np.int32) * epochs\n",
    "# end_step = model_info[\"batch_size\"]\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    #   'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.9,\n",
    "    #                                                           begin_step=0,\n",
    "    #                                                           frequency=100)\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.90,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "keras.utils.get_custom_objects().update({\n",
    "    **CUSTOM_OBJECTS\n",
    "})\n",
    "baseline_model_copy = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "model_for_pruning = prune_low_magnitude(baseline_model_copy, **pruning_params)\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tf_keras.src.initializers.initializers.GlorotUniform'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tf_keras.src.initializers.initializers.Zeros'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/keras/src/regularizers.py:426: UserWarning: The `keras.regularizers.serialize()` API should only be used for objects of type `keras.regularizers.Regularizer`. Found an instance of type <class 'tf_keras.src.regularizers.L2'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'tf_keras.src.constraints.MaxNorm'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tf_keras.src.initializers.initializers.Ones'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 15:28:00.850725: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_10/prune_low_magnitude_dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-03-24 15:28:04.678412: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7143cbd890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-24 15:28:04.678492: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2024-03-24 15:28:04.685524: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711315684.794497  188258 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 14.7465 - accuracy: 0.4559 - val_loss: 13.7009 - val_accuracy: 0.2778\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 13.4451 - accuracy: 0.5882 - val_loss: 13.3463 - val_accuracy: 0.2778\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 13.1472 - accuracy: 0.6029 - val_loss: 12.9814 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 12.7086 - accuracy: 0.6765 - val_loss: 12.6154 - val_accuracy: 0.3889\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 12.2913 - accuracy: 0.7500 - val_loss: 12.2496 - val_accuracy: 0.3889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f721b5539d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = \"logs/pruning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=model_info[\"batch_size\"], \n",
    "                  epochs=epochs, \n",
    "                  validation_split=0.2,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Baseline test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Baseline test accuracy: \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090638160706</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned test accuracy: \u001b[1;36m0.5909090638160706\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "rprint('Baseline test accuracy:', baseline_test_acc)\n",
    "rprint('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_188098/3865207160.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_model_export/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model to: .\u001b[35m/temp_model_export/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = None, \"./temp_model_export/pruned_model.h5\"\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "rprint('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxv1ejywf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxv1ejywf/assets\n",
      "2024-03-24 15:28:15.125403: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-24 15:28:15.125452: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-24 15:28:15.125775: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpxv1ejywf\n",
      "2024-03-24 15:28:15.127030: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-24 15:28:15.127053: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpxv1ejywf\n",
      "2024-03-24 15:28:15.131000: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-03-24 15:28:15.131972: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-24 15:28:15.159885: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpxv1ejywf\n",
      "2024-03-24 15:28:15.174032: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 48259 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_model_export/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/temp_model_export/\u001b[0m\u001b[95mpruned_model.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = None, \"./temp_model_export/pruned_model.tflite\"\n",
    "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "rprint('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86034.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86034.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85907.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m85907.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83934.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m83934.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    \n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "rprint(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "rprint(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphwzmpi90/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphwzmpi90/assets\n",
      "2024-03-24 15:29:05.264027: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-24 15:29:05.264091: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-24 15:29:05.264509: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphwzmpi90\n",
      "2024-03-24 15:29:05.266426: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-24 15:29:05.266507: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphwzmpi90\n",
      "2024-03-24 15:29:05.274695: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-24 15:29:05.298239: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphwzmpi90\n",
      "2024-03-24 15:29:05.315031: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 50531 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_model_export/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">quantized_and_pruned_model.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: .\u001b[35m/temp_model_export/\u001b[0m\u001b[95mquantized_and_pruned_model.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86034.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86034.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24794.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m24794.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = None, \"./temp_model_export/quantized_and_pruned_model.tflite\"\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "rprint('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "rprint(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090909090909</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5909090909090909\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090638160706</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5909090638160706\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # signatures = interpreter.get_signature_list()\n",
    "  # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  predictions = []\n",
    "  for i, v in enumerate(X_test):\n",
    "    v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    # if i % 1000 == 0:\n",
    "    #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # # the model's input data format.\n",
    "    # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, v)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "    predictions.append(class_prediction)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  predictions = np.asarray(predictions)\n",
    "  accuracy = (predictions == y_test).mean()\n",
    "  return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "rprint('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "rprint('Pruned TF test accuracy:', model_for_pruning_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
