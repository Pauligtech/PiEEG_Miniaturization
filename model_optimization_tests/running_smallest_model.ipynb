{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "    \n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "\n",
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "def get_test_acc(model, train_test_data):\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "    def evaluate_model(interpreter):\n",
    "        input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        # signatures = interpreter.get_signature_list()\n",
    "        # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "        # Run predictions on every image in the \"test\" dataset.\n",
    "        predictions = []\n",
    "        exec_times = []\n",
    "        for i, v in enumerate(X_test):\n",
    "            v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "            # if i % 1000 == 0:\n",
    "            #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "            # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "            # # the model's input data format.\n",
    "            # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, v)\n",
    "\n",
    "            # Run inference.\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            exec_time = (time.time() - start_time)\n",
    "            exec_times.append(exec_time)\n",
    "\n",
    "            # Post-processing: remove batch dimension and find the digit with highest\n",
    "            # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "            predictions.append(class_prediction)\n",
    "\n",
    "        print('\\n')\n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        predictions = np.asarray(predictions)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "        avg_exec_time = np.mean(exec_times)\n",
    "        return accuracy, avg_exec_time\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    test_accuracy, avg_exec_time = evaluate_model(interpreter)\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"avg_exec_time\": avg_exec_time\n",
    "    }\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 300.0, returning unmodified.\n",
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727272727273</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0006706172769719905</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.7272727272727273\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0006706172769719905\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363636363636</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0004418004642833363</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.8636363636363636\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0004418004642833363\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727272727273</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0002666495063088157</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.7272727272727273\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0002666495063088157\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545454545454</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0005249760367653587</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.5454545454545454\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0005249760367653587\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727272727273</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00019772486253218219</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.7272727272727273\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.00019772486253218219\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181818181818</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.003891587257385254</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.6818181818181818\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.003891587257385254\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545454545454</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0002664327621459961</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.5454545454545454\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0002664327621459961\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9090909090909091</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00039944865486838603</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.9090909090909091\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.00039944865486838603\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181818181818</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00039910186420787465</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.6818181818181818\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.00039910186420787465\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45454545454545453</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00024497509002685547</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.45454545454545453\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.00024497509002685547\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727272727273</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0013769431547685103</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.7272727272727273\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0013769431547685103\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636363636364</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0005718577991832386</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.6363636363636364\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0005718577991832386\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 300.0, returning unmodified.\n",
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636363636364</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0007188428531993519</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.6363636363636364\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0007188428531993519\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727272727272727</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0034680583260276103</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.7727272727272727\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.0034680583260276103\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636363636364</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'avg_exec_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00031250173395330256</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'test_accuracy'\u001b[0m: \u001b[1;36m0.6363636363636364\u001b[0m, \u001b[32m'avg_exec_time'\u001b[0m: \u001b[1;36m0.00031250173395330256\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparsity_level = 0.5\n",
    "quantization = \"int8\"\n",
    "model_files = glob.glob(f\"./results/**/**/**/int8/pruned_model_{sparsity_level}_sparsity_{quantization}_quant.tflite\")\n",
    "model_info_files = glob.glob(f\"./results/**/**/model_info.npy\")\n",
    "\n",
    "model_info_and_files = list(zip(model_info_files, model_files))\n",
    "\n",
    "for _model_info, _model in model_info_and_files:\n",
    "    \n",
    "    model_info = np.load(_model_info, allow_pickle=True).item()\n",
    "\n",
    "    X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "    y_encoded = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "    train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "    # Load tflite model from disk\n",
    "    model = open(_model, \"rb\").read()\n",
    "\n",
    "    rprint(get_test_acc(model, train_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.7272727272727273, 'avg_exec_time': 0.00018253109671852806}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = np.load(\"./results/11/shallow_conv_net/model_info.npy\", allow_pickle=True).item()\n",
    "\n",
    "X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "# Load tflite model from disk\n",
    "model = open(\"./results/11/shallow_conv_net/0.5/int8/pruned_model_0.5_sparsity_int8_quant.tflite\", \"rb\").read()\n",
    "\n",
    "get_test_acc(model, train_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.5454545454545454, 'avg_exec_time': 0.0005855560302734375}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = np.load(\"./results/11/deep_conv_net/model_info.npy\", allow_pickle=True).item()\n",
    "\n",
    "X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "# Load tflite model from disk\n",
    "model = open(\"./results/11/deep_conv_net/0.5/int8/pruned_model_0.5_sparsity_int8_quant.tflite\", \"rb\").read()\n",
    "\n",
    "get_test_acc(model, train_test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
