{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 16:29:13.946025: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-13 16:29:13.946083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-13 16:29:13.947162: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 16:29:13.953536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 16:29:14.709709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "from model_optim.model_optimizer import ModelOptimizer\n",
    "\n",
    "# Dataset\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "from custom_datasets.norm_cho import NormCho2017\n",
    "from custom_datasets.opt_game_mi import OptGameMI\n",
    "from custom_datasets.opt_std_mi import OptStdMI\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [\n",
    "    \"shallow_conv_net\",\n",
    "    \"lstm_net\",\n",
    "    \"deep_conv_net\",\n",
    "    \"eeg_net\",\n",
    "    \"lstm_cnn_net\",\n",
    "    \"lstm_cnn_net_v2\"\n",
    "]\n",
    "MODELS_HYPERPARAMS_DICT = {\n",
    "    \"shallow_conv_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"eeg_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"deep_conv_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"lstm_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net_v2\": {},\n",
    "}\n",
    "\n",
    "DATASETS_LIST = [\n",
    "    FatigueMI,\n",
    "    # NormCho2017,\n",
    "    # OptGameMI,\n",
    "    # OptStdMI,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_optim.utils import data_generator\n",
    "\n",
    "# data_generator(\n",
    "#     dataset=NormCho2017(),\n",
    "#     subjects=[1],\n",
    "#     channel_idx=[],\n",
    "#     sfreq=128,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files = glob.glob(\"./temp_v2/*/*/model/study_best_trial.npy\")\n",
    "subject_files_data = {}\n",
    "for subject_file in subject_files:\n",
    "    subject_files_data[subject_file] = np.load(subject_file, allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort subject_files_data by subject_file_data.user_attrs['trial_data']['test_accuracy']\n",
    "sorted_subject_files_data = dict(sorted(subject_files_data.items(), key=lambda item: item[1].user_attrs['trial_data']['test_accuracy'], reverse=True))\n",
    "sorted_subject_files_data_test_acc = {k: v.user_attrs['trial_data']['test_accuracy'] for k, v in sorted_subject_files_data.items()}\n",
    "rpprint(sorted_subject_files_data_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n"
     ]
    }
   ],
   "source": [
    "model_optimizer = ModelOptimizer(\n",
    "    dataset=FatigueMI(),\n",
    "    model_name=\"shallow_conv_net\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n",
      "Found previous study in ./temp/FatigueMI/[4]/c67f6477f55c43b89f616757c38abfe3/model/deep_conv_net_study_best_trial.npy, removing...\n",
      "Found previous study in ./temp/FatigueMI/[4]/c67f6477f55c43b89f616757c38abfe3/model/deep_conv_net_study.npy, removing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba099ae6bc0c4ad3874b20eb43331d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 16:33:07.347254: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_14/dropout_56/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.2798 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2798 - accuracy: 0.5294 - val_loss: 1.1374 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6593 - accuracy: 0.6029\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6593 - accuracy: 0.6029 - val_loss: 1.1608 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4164 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4164 - accuracy: 0.5147 - val_loss: 2.6830 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2889 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2889 - accuracy: 0.4853 - val_loss: 0.8726 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.6912\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6335 - accuracy: 0.6912 - val_loss: 0.9557 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1814 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1814 - accuracy: 0.5000 - val_loss: 1.4295 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8993 - accuracy: 0.5147\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.8993 - accuracy: 0.5147 - val_loss: 1.1184 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3549 - accuracy: 0.5000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3549 - accuracy: 0.5000 - val_loss: 1.1149 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0262 - accuracy: 0.5735\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0262 - accuracy: 0.5735 - val_loss: 1.0122 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.5588\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8729 - accuracy: 0.5588 - val_loss: 1.0549 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.6765\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6991 - accuracy: 0.6765 - val_loss: 0.9372 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.6324\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5891 - accuracy: 0.6324 - val_loss: 0.9751 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.6765\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6570 - accuracy: 0.6765 - val_loss: 0.8944 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.6765\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6825 - accuracy: 0.6765 - val_loss: 0.9283 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7500\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.9075 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.7206\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5684 - accuracy: 0.7206 - val_loss: 0.8901 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4864 - accuracy: 0.8088\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4864 - accuracy: 0.8088 - val_loss: 0.8756 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4979 - accuracy: 0.7500 - val_loss: 0.8634 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.6618\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5257 - accuracy: 0.6618 - val_loss: 0.8550 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.7206\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5877 - accuracy: 0.7206 - val_loss: 0.8466 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.6618\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5397 - accuracy: 0.6618 - val_loss: 0.8370 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5407 - accuracy: 0.7500\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5407 - accuracy: 0.7500 - val_loss: 0.8335 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.6324\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5671 - accuracy: 0.6324 - val_loss: 0.8298 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5140 - accuracy: 0.7941\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5140 - accuracy: 0.7941 - val_loss: 0.8301 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.7941\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4757 - accuracy: 0.7941 - val_loss: 0.8267 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3142 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6395 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6395 - accuracy: 0.4853 - val_loss: 2.7708 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4464 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4464 - accuracy: 0.5147 - val_loss: 2.6610 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8392 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8392 - accuracy: 0.4853 - val_loss: 1.0596 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0512 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0512 - accuracy: 0.5735 - val_loss: 1.3917 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5102 - accuracy: 0.5000\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5102 - accuracy: 0.5000 - val_loss: 1.2239 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3123 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3123 - accuracy: 0.5147 - val_loss: 1.2043 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2752 - accuracy: 0.5294\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2752 - accuracy: 0.5294 - val_loss: 1.0286 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.6324\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7308 - accuracy: 0.6324 - val_loss: 0.9478 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.6176\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6660 - accuracy: 0.6176 - val_loss: 0.9150 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.6618\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6070 - accuracy: 0.6618 - val_loss: 0.9073 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.6471\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6849 - accuracy: 0.6471 - val_loss: 0.9517 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.5882\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6562 - accuracy: 0.5882 - val_loss: 0.9102 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.6176\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7056 - accuracy: 0.6176 - val_loss: 0.9697 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7908 - accuracy: 0.6324\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7908 - accuracy: 0.6324 - val_loss: 0.9136 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.5735\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7257 - accuracy: 0.5735 - val_loss: 0.9928 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.6471\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6991 - accuracy: 0.6471 - val_loss: 0.9437 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.6765\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5499 - accuracy: 0.6765 - val_loss: 0.9639 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.6765\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5703 - accuracy: 0.6765 - val_loss: 0.8793 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.7206\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5483 - accuracy: 0.7206 - val_loss: 0.8948 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.7941\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4879 - accuracy: 0.7941 - val_loss: 0.8816 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.7647\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5052 - accuracy: 0.7647 - val_loss: 0.8786 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.7941\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4801 - accuracy: 0.7941 - val_loss: 0.8822 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.7059\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5312 - accuracy: 0.7059 - val_loss: 0.9335 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.7353\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5451 - accuracy: 0.7353 - val_loss: 0.9283 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.6912\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5782 - accuracy: 0.6912 - val_loss: 1.0562 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Using epoch 00002 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.8436 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0624 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0624 - accuracy: 0.5147 - val_loss: 0.6820 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9372 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9372 - accuracy: 0.5147 - val_loss: 3.1566 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9936 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9936 - accuracy: 0.4853 - val_loss: 0.6807 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9183 - accuracy: 0.5441\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9183 - accuracy: 0.5441 - val_loss: 1.0401 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0214 - accuracy: 0.4853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0214 - accuracy: 0.4853 - val_loss: 1.1788 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6360 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6360 - accuracy: 0.5147 - val_loss: 0.7269 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0957 - accuracy: 0.5294\n",
      "Epoch 00007: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0957 - accuracy: 0.5294 - val_loss: 0.8385 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8946 - accuracy: 0.5735\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8946 - accuracy: 0.5735 - val_loss: 0.7132 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8069 - accuracy: 0.5735\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8069 - accuracy: 0.5735 - val_loss: 0.7060 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7521 - accuracy: 0.6176\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7521 - accuracy: 0.6176 - val_loss: 0.7184 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.6471\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6309 - accuracy: 0.6471 - val_loss: 0.6899 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.7206\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5119 - accuracy: 0.7206 - val_loss: 0.6984 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.6765\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6326 - accuracy: 0.6765 - val_loss: 0.7000 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.6912\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5951 - accuracy: 0.6912 - val_loss: 0.6997 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.6912\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5459 - accuracy: 0.6912 - val_loss: 0.6985 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.6176\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5703 - accuracy: 0.6176 - val_loss: 0.6974 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.6912\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5502 - accuracy: 0.6912 - val_loss: 0.6969 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4937 - accuracy: 0.7500 - val_loss: 0.6965 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.6618\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5520 - accuracy: 0.6618 - val_loss: 0.6961 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.7353\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5095 - accuracy: 0.7353 - val_loss: 0.6963 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.6912\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5249 - accuracy: 0.6912 - val_loss: 0.6965 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.7353\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5301 - accuracy: 0.7353 - val_loss: 0.6956 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7353\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5620 - accuracy: 0.7353 - val_loss: 0.6940 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.6912\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5647 - accuracy: 0.6912 - val_loss: 0.6934 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.7647\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4629 - accuracy: 0.7647 - val_loss: 0.6931 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Using epoch 00007 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.2122 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3749 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3749 - accuracy: 0.5294 - val_loss: 0.7851 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7041 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7041 - accuracy: 0.4853 - val_loss: 4.3956 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4962 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.4962 - accuracy: 0.5147 - val_loss: 0.9916 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6894 - accuracy: 0.5735 - val_loss: 0.7067 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.5441\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6286 - accuracy: 0.5441 - val_loss: 0.9815 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8543 - accuracy: 0.6029\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8543 - accuracy: 0.6029 - val_loss: 0.7629 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4092 - accuracy: 0.4853\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4092 - accuracy: 0.4853 - val_loss: 1.4137 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7540 - accuracy: 0.5147\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7540 - accuracy: 0.5147 - val_loss: 0.7265 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0118 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0118 - accuracy: 0.5441 - val_loss: 0.8971 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.5294\n",
      "Epoch 00010: val_accuracy improved from 0.55556 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9230 - accuracy: 0.5294 - val_loss: 0.7113 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.6471\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6839 - accuracy: 0.6471 - val_loss: 0.7056 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.6176\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6387 - accuracy: 0.6176 - val_loss: 0.7533 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.6324\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6611 - accuracy: 0.6324 - val_loss: 0.7053 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7059\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5668 - accuracy: 0.7059 - val_loss: 0.7266 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.6912\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - accuracy: 0.6912 - val_loss: 0.7115 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.7647\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5089 - accuracy: 0.7647 - val_loss: 0.7211 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.7794\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4923 - accuracy: 0.7794 - val_loss: 0.7193 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.6765\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5537 - accuracy: 0.6765 - val_loss: 0.7248 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.7941\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4570 - accuracy: 0.7941 - val_loss: 0.7419 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.7647\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4508 - accuracy: 0.7647 - val_loss: 0.7339 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.7647\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4470 - accuracy: 0.7647 - val_loss: 0.7517 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.7647\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4750 - accuracy: 0.7647 - val_loss: 0.7379 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.7206\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5562 - accuracy: 0.7206 - val_loss: 0.7906 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9209 - accuracy: 0.6176\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9209 - accuracy: 0.6176 - val_loss: 0.7744 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.6471\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6951 - accuracy: 0.6471 - val_loss: 0.7645 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00010 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8647 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6061 - accuracy: 0.4412\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6061 - accuracy: 0.4412 - val_loss: 1.1853 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8313 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8313 - accuracy: 0.5147 - val_loss: 2.6747 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9538 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.9538 - accuracy: 0.4853 - val_loss: 0.8710 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7475 - accuracy: 0.5735 - val_loss: 0.9040 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.5294\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8668 - accuracy: 0.5294 - val_loss: 1.3358 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5844 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5844 - accuracy: 0.5147 - val_loss: 1.0955 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2504 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2504 - accuracy: 0.5441 - val_loss: 1.0578 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9678 - accuracy: 0.5882\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9678 - accuracy: 0.5882 - val_loss: 0.9754 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9179 - accuracy: 0.5735\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9179 - accuracy: 0.5735 - val_loss: 0.9888 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.6912\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6546 - accuracy: 0.6912 - val_loss: 0.8860 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5985 - accuracy: 0.6765\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5985 - accuracy: 0.6765 - val_loss: 0.8844 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.6765\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5843 - accuracy: 0.6765 - val_loss: 0.8321 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6733 - accuracy: 0.5882\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6733 - accuracy: 0.5882 - val_loss: 0.8793 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.6765\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5897 - accuracy: 0.6765 - val_loss: 0.7963 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.6618\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5939 - accuracy: 0.6618 - val_loss: 0.8904 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.7206\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6017 - accuracy: 0.7206 - val_loss: 0.7816 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.6912\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5626 - accuracy: 0.6912 - val_loss: 0.8710 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4960 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4960 - accuracy: 0.7500 - val_loss: 0.7779 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.6912\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5986 - accuracy: 0.6912 - val_loss: 0.9156 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.5882\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7942 - accuracy: 0.5882 - val_loss: 0.8777 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9478 - accuracy: 0.5735\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9478 - accuracy: 0.5735 - val_loss: 1.0918 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7763 - accuracy: 0.6029\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7763 - accuracy: 0.6029 - val_loss: 0.8800 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.6176\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6757 - accuracy: 0.6176 - val_loss: 1.0069 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.7794\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4585 - accuracy: 0.7794 - val_loss: 0.8851 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5131 - accuracy: 0.7500 - val_loss: 1.0317 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00002 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.8565 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2372 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2372 - accuracy: 0.5294 - val_loss: 0.8463 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8264 - accuracy: 0.4559\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8264 - accuracy: 0.4559 - val_loss: 3.6912 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6688 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6688 - accuracy: 0.5147 - val_loss: 0.9628 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4880 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.4880 - accuracy: 0.4853 - val_loss: 2.1134 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9635 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.9635 - accuracy: 0.5147 - val_loss: 0.6765 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0705 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0705 - accuracy: 0.5000 - val_loss: 1.2398 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2246 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2246 - accuracy: 0.5441 - val_loss: 0.6490 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0080 - accuracy: 0.5588\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0080 - accuracy: 0.5588 - val_loss: 0.7852 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7326 - accuracy: 0.5882\n",
      "Epoch 00009: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7326 - accuracy: 0.5882 - val_loss: 0.6847 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8262 - accuracy: 0.5882\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8262 - accuracy: 0.5882 - val_loss: 0.6989 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.6471\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7393 - accuracy: 0.6471 - val_loss: 0.6782 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.6471\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6509 - accuracy: 0.6471 - val_loss: 0.6960 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.6471\n",
      "Epoch 00013: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5675 - accuracy: 0.6471 - val_loss: 0.6978 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.6912\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6038 - accuracy: 0.6912 - val_loss: 0.6659 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.6618\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5971 - accuracy: 0.6618 - val_loss: 0.6824 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.6912\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5537 - accuracy: 0.6912 - val_loss: 0.6835 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.7941\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5271 - accuracy: 0.7941 - val_loss: 0.7180 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.7353\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5245 - accuracy: 0.7353 - val_loss: 0.7167 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.7941\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4860 - accuracy: 0.7941 - val_loss: 0.7121 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.7353\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4836 - accuracy: 0.7353 - val_loss: 0.7117 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7647\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5041 - accuracy: 0.7647 - val_loss: 0.7091 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.7353\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5581 - accuracy: 0.7353 - val_loss: 0.7075 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8235\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4573 - accuracy: 0.8235 - val_loss: 0.7076 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.8235\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4855 - accuracy: 0.8235 - val_loss: 0.7042 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.6471\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5345 - accuracy: 0.6471 - val_loss: 0.7048 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Using epoch 00013 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9628 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1654 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33333, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1654 - accuracy: 0.4853 - val_loss: 0.8580 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7811 - accuracy: 0.5735\n",
      "Epoch 00002: val_accuracy improved from 0.33333 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7811 - accuracy: 0.5735 - val_loss: 3.8264 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7001 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7001 - accuracy: 0.4853 - val_loss: 1.1610 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1122 - accuracy: 0.5147\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1122 - accuracy: 0.5147 - val_loss: 2.4667 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3445 - accuracy: 0.4853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3445 - accuracy: 0.4853 - val_loss: 1.1793 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1042 - accuracy: 0.5588\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1042 - accuracy: 0.5588 - val_loss: 1.6842 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1428 - accuracy: 0.5735\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1428 - accuracy: 0.5735 - val_loss: 1.0097 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.6618\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6513 - accuracy: 0.6618 - val_loss: 0.9447 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.6471\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6617 - accuracy: 0.6471 - val_loss: 0.9239 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.6912\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5872 - accuracy: 0.6912 - val_loss: 0.8373 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.6176\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6812 - accuracy: 0.6176 - val_loss: 0.9078 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7373 - accuracy: 0.6176\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7373 - accuracy: 0.6176 - val_loss: 0.8672 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.6324\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8728 - accuracy: 0.6324 - val_loss: 0.9324 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8754 - accuracy: 0.5882\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8754 - accuracy: 0.5882 - val_loss: 0.8637 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8554 - accuracy: 0.6029\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8554 - accuracy: 0.6029 - val_loss: 0.9177 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.6324\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6710 - accuracy: 0.6324 - val_loss: 0.8416 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.6618\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5722 - accuracy: 0.6618 - val_loss: 0.9093 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.6912\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6320 - accuracy: 0.6912 - val_loss: 0.8736 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.6765\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6449 - accuracy: 0.6765 - val_loss: 0.9012 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.7500\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5518 - accuracy: 0.7500 - val_loss: 0.8299 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7206\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4784 - accuracy: 0.7206 - val_loss: 0.8327 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5101 - accuracy: 0.7206\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5101 - accuracy: 0.7206 - val_loss: 0.8494 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.7941\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4603 - accuracy: 0.7941 - val_loss: 0.8354 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8382\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4331 - accuracy: 0.8382 - val_loss: 0.8276 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4837 - accuracy: 0.7500 - val_loss: 0.8039 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00002 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.2451 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8595 - accuracy: 0.6471\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8595 - accuracy: 0.6471 - val_loss: 1.0772 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9080 - accuracy: 0.4853 - val_loss: 3.4821 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3921 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.3921 - accuracy: 0.5147 - val_loss: 1.4751 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2117 - accuracy: 0.5294\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2117 - accuracy: 0.5294 - val_loss: 1.7644 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3393 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3393 - accuracy: 0.5147 - val_loss: 1.2939 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2910 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2910 - accuracy: 0.5294 - val_loss: 1.1841 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1798 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1798 - accuracy: 0.5441 - val_loss: 1.0747 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.5441\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9237 - accuracy: 0.5441 - val_loss: 1.1017 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8434 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8434 - accuracy: 0.6029 - val_loss: 0.9620 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.6471\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6670 - accuracy: 0.6471 - val_loss: 1.0173 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.6912\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6143 - accuracy: 0.6912 - val_loss: 0.9213 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.6618\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6037 - accuracy: 0.6618 - val_loss: 0.9386 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7353\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5875 - accuracy: 0.7353 - val_loss: 0.8698 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.6176\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6337 - accuracy: 0.6176 - val_loss: 0.9373 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.7059\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5371 - accuracy: 0.7059 - val_loss: 0.8476 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.6765\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6533 - accuracy: 0.6765 - val_loss: 0.9612 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.6471\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5972 - accuracy: 0.6471 - val_loss: 0.8655 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.6029\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6725 - accuracy: 0.6029 - val_loss: 0.9652 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.6324\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6221 - accuracy: 0.6324 - val_loss: 0.8730 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.6176\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6927 - accuracy: 0.6176 - val_loss: 1.0228 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7444 - accuracy: 0.5882\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7444 - accuracy: 0.5882 - val_loss: 0.9017 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7813 - accuracy: 0.6324\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7813 - accuracy: 0.6324 - val_loss: 1.0540 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.6471\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6303 - accuracy: 0.6471 - val_loss: 0.9343 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7353\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5417 - accuracy: 0.7353 - val_loss: 0.9737 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4599 - accuracy: 0.8235\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4599 - accuracy: 0.8235 - val_loss: 0.8767 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0070 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4022 - accuracy: 0.4412\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4022 - accuracy: 0.4412 - val_loss: 1.0972 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1278 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1278 - accuracy: 0.5147 - val_loss: 3.8291 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9845 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9845 - accuracy: 0.5147 - val_loss: 0.6812 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5882\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6926 - accuracy: 0.5882 - val_loss: 1.1331 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1289 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1289 - accuracy: 0.5147 - val_loss: 1.1419 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4370 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.4370 - accuracy: 0.4853 - val_loss: 1.1498 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3018 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3018 - accuracy: 0.5441 - val_loss: 0.7706 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1915 - accuracy: 0.5147\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1915 - accuracy: 0.5147 - val_loss: 0.9435 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8544 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8544 - accuracy: 0.5441 - val_loss: 0.7220 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8337 - accuracy: 0.5882\n",
      "Epoch 00010: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8337 - accuracy: 0.5882 - val_loss: 0.7338 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.6324\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7371 - accuracy: 0.6324 - val_loss: 0.7108 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.6324\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6757 - accuracy: 0.6324 - val_loss: 0.7358 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.7059\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5876 - accuracy: 0.7059 - val_loss: 0.7409 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.6765\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6372 - accuracy: 0.6765 - val_loss: 0.7285 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5560 - accuracy: 0.7206\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5560 - accuracy: 0.7206 - val_loss: 0.7209 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.6912\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6004 - accuracy: 0.6912 - val_loss: 0.7169 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.7647\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5614 - accuracy: 0.7647 - val_loss: 0.7145 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5810 - accuracy: 0.7206\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5810 - accuracy: 0.7206 - val_loss: 0.7140 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.7206\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5546 - accuracy: 0.7206 - val_loss: 0.7102 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.7353\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5470 - accuracy: 0.7353 - val_loss: 0.7101 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.7059\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4977 - accuracy: 0.7059 - val_loss: 0.7092 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7206\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5300 - accuracy: 0.7206 - val_loss: 0.7088 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.7059\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5566 - accuracy: 0.7059 - val_loss: 0.7080 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.6618\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5471 - accuracy: 0.6618 - val_loss: 0.7075 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.6912\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4843 - accuracy: 0.6912 - val_loss: 0.7070 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Using epoch 00010 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1000 - accuracy: 0.4091\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3007 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 2s 465ms/step - loss: 1.3007 - accuracy: 0.5000 - val_loss: 2.0526 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.8121 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.7631 - accuracy: 0.5147 - val_loss: 0.9058 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8478 - accuracy: 0.5312\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.72222, storing weights.\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8509 - accuracy: 0.5441 - val_loss: 0.6440 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7727 - accuracy: 0.5469\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7439 - accuracy: 0.5735 - val_loss: 0.6848 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1090 - accuracy: 0.5781\n",
      "Epoch 00005: val_accuracy improved from 0.72222 to 0.77778, storing weights.\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1522 - accuracy: 0.5735 - val_loss: 0.6870 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8502 - accuracy: 0.5312\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.9301 - accuracy: 0.5294 - val_loss: 0.7144 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9732 - accuracy: 0.5000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.9281 - accuracy: 0.5294 - val_loss: 0.9136 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1567 - accuracy: 0.5312\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1495 - accuracy: 0.5294 - val_loss: 0.7732 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6013 - accuracy: 0.6250\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6210 - accuracy: 0.6029 - val_loss: 0.9153 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7003 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.6323 - accuracy: 0.5147 - val_loss: 0.7254 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6522 - accuracy: 0.5938\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6573 - accuracy: 0.5882 - val_loss: 0.8388 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1662 - accuracy: 0.5156\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1469 - accuracy: 0.5294 - val_loss: 0.7138 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6339 - accuracy: 0.6406\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6483 - accuracy: 0.6471 - val_loss: 0.6897 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5902 - accuracy: 0.6875\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5911 - accuracy: 0.6765 - val_loss: 0.6831 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5416 - accuracy: 0.7812\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5216 - accuracy: 0.7941 - val_loss: 0.6855 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5327 - accuracy: 0.7188\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5285 - accuracy: 0.7206 - val_loss: 0.6916 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5667 - accuracy: 0.7031\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5509 - accuracy: 0.7206 - val_loss: 0.6926 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5923 - accuracy: 0.7031\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5811 - accuracy: 0.7059 - val_loss: 0.6943 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5991 - accuracy: 0.6875\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5751 - accuracy: 0.7059 - val_loss: 0.6949 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6308 - accuracy: 0.6250\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6211 - accuracy: 0.6471 - val_loss: 0.6968 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5619 - accuracy: 0.6719\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5509 - accuracy: 0.6765 - val_loss: 0.6955 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6459 - accuracy: 0.7031\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6486 - accuracy: 0.7059 - val_loss: 0.6957 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5732 - accuracy: 0.6875\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5748 - accuracy: 0.6912 - val_loss: 0.6955 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5899 - accuracy: 0.6875\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5847 - accuracy: 0.6912 - val_loss: 0.6956 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4558 - accuracy: 0.7812\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4702 - accuracy: 0.7794 - val_loss: 0.6971 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Using epoch 00005 with val_accuracy: 0.77778\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7164 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8179 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 3s 239ms/step - loss: 0.8179 - accuracy: 0.5294 - val_loss: 1.3417 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9816 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0629 - accuracy: 0.4412 - val_loss: 0.8023 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6577 - accuracy: 0.6562\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8387 - accuracy: 0.5000 - val_loss: 0.8020 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6290 - accuracy: 0.6875\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8087 - accuracy: 0.6176 - val_loss: 0.7819 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5836 - accuracy: 0.6562\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7467 - accuracy: 0.6029 - val_loss: 0.7917 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5336 - accuracy: 0.6562\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6740 - accuracy: 0.6029 - val_loss: 0.7763 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7415 - accuracy: 0.5625\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6768 - accuracy: 0.5882 - val_loss: 0.8226 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6677 - accuracy: 0.7188\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6053 - accuracy: 0.6912 - val_loss: 0.7793 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7144 - accuracy: 0.6250\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7651 - accuracy: 0.6029 - val_loss: 0.7413 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9758 - accuracy: 0.4062\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8119 - accuracy: 0.5147 - val_loss: 0.7430 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5502 - accuracy: 0.6562\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5437 - accuracy: 0.6765 - val_loss: 0.7381 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8326 - accuracy: 0.4688\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7126 - accuracy: 0.6176 - val_loss: 0.7282 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3858 - accuracy: 0.8750\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5641 - accuracy: 0.7794 - val_loss: 0.7486 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8115 - accuracy: 0.6250\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7040 - accuracy: 0.6471 - val_loss: 0.7562 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5666 - accuracy: 0.7188\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6359 - accuracy: 0.6765 - val_loss: 0.7918 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6634 - accuracy: 0.6250\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6381 - accuracy: 0.6765 - val_loss: 0.7703 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5724 - accuracy: 0.7188\n",
      "Epoch 00017: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6070 - accuracy: 0.6765 - val_loss: 0.8420 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2120 - accuracy: 0.4062\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8331 - accuracy: 0.5882 - val_loss: 0.8031 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4061 - accuracy: 0.8438\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4866 - accuracy: 0.7647 - val_loss: 0.7771 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5007 - accuracy: 0.8438\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4752 - accuracy: 0.8088 - val_loss: 0.8065 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5981 - accuracy: 0.6875\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5323 - accuracy: 0.7353 - val_loss: 0.8233 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5277 - accuracy: 0.7812\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5561 - accuracy: 0.7059 - val_loss: 0.8317 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4876 - accuracy: 0.7188\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4818 - accuracy: 0.7206 - val_loss: 0.8362 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5474 - accuracy: 0.7188\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5267 - accuracy: 0.7647 - val_loss: 0.8327 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6406 - accuracy: 0.6250\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6064 - accuracy: 0.7206 - val_loss: 0.8390 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Using epoch 00017 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5855 - accuracy: 0.6818\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 1.0427 - accuracy: 0.5938\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 2s 125ms/step - loss: 1.1333 - accuracy: 0.5294 - val_loss: 1.2887 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.1012 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.1070 - accuracy: 0.4853 - val_loss: 0.7850 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4993 - accuracy: 0.7812\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7542 - accuracy: 0.6176 - val_loss: 0.7264 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6483 - accuracy: 0.5938\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7274 - accuracy: 0.5441 - val_loss: 0.7136 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8050 - accuracy: 0.5625\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7532 - accuracy: 0.6029 - val_loss: 0.8000 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6597 - accuracy: 0.6562\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7928 - accuracy: 0.6176 - val_loss: 0.7536 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7990 - accuracy: 0.5312\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7279 - accuracy: 0.5882 - val_loss: 0.8050 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6811 - accuracy: 0.7188\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7074 - accuracy: 0.6029 - val_loss: 0.7469 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5151 - accuracy: 0.7500\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6900 - accuracy: 0.6176 - val_loss: 0.7238 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7414 - accuracy: 0.5312\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6478 - accuracy: 0.6471 - val_loss: 0.7449 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5431 - accuracy: 0.7188\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6461 - accuracy: 0.6912 - val_loss: 0.7446 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7994 - accuracy: 0.5625\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6823 - accuracy: 0.6176 - val_loss: 0.7311 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5297 - accuracy: 0.8125\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6086 - accuracy: 0.7059 - val_loss: 0.7627 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4445 - accuracy: 0.8438\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5500 - accuracy: 0.7647 - val_loss: 0.7806 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5706 - accuracy: 0.6875\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6023 - accuracy: 0.7059 - val_loss: 0.7933 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5848 - accuracy: 0.6250\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5530 - accuracy: 0.6765 - val_loss: 0.7988 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4955 - accuracy: 0.7812\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4564 - accuracy: 0.8382 - val_loss: 0.8087 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4825 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5489 - accuracy: 0.6912 - val_loss: 0.8184 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4822 - accuracy: 0.8125\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5776 - accuracy: 0.7206 - val_loss: 0.8136 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5615 - accuracy: 0.6562\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5794 - accuracy: 0.6765 - val_loss: 0.8093 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4803 - accuracy: 0.7500\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5098 - accuracy: 0.7353 - val_loss: 0.8128 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5058 - accuracy: 0.7812\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5421 - accuracy: 0.7647 - val_loss: 0.8115 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4192 - accuracy: 0.8438\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5253 - accuracy: 0.7794 - val_loss: 0.8180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4480 - accuracy: 0.7812\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5191 - accuracy: 0.7353 - val_loss: 0.8142 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5599 - accuracy: 0.6875\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5659 - accuracy: 0.7206 - val_loss: 0.8149 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Using epoch 00004 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6846 - accuracy: 0.4091\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7291 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 4s 457ms/step - loss: 1.7291 - accuracy: 0.5000 - val_loss: 3.3869 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7990 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.5172 - accuracy: 0.4706 - val_loss: 0.8175 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6442 - accuracy: 0.6875\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.61111, storing weights.\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7135 - accuracy: 0.6324 - val_loss: 0.7975 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0178 - accuracy: 0.5625\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.1732 - accuracy: 0.5588 - val_loss: 0.8262 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8839 - accuracy: 0.6250\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6998 - accuracy: 0.7206 - val_loss: 0.8825 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5901 - accuracy: 0.6562\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6279 - accuracy: 0.6471 - val_loss: 0.9214 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9104 - accuracy: 0.5938\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7155 - accuracy: 0.7059 - val_loss: 1.0255 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7432 - accuracy: 0.7188\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7000 - accuracy: 0.7353 - val_loss: 0.8904 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6450 - accuracy: 0.6875\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6924 - accuracy: 0.6912 - val_loss: 0.7225 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5798 - accuracy: 0.6562\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5318 - accuracy: 0.7059 - val_loss: 0.7468 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5640 - accuracy: 0.6875\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6210 - accuracy: 0.6618 - val_loss: 0.7898 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9811 - accuracy: 0.4688\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.1600 - accuracy: 0.4706 - val_loss: 0.8614 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6923 - accuracy: 0.7500\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9097 - accuracy: 0.6471 - val_loss: 0.8765 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6580 - accuracy: 0.6250\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5889 - accuracy: 0.6765 - val_loss: 1.2280 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6464 - accuracy: 0.7500\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5670 - accuracy: 0.7647 - val_loss: 1.2230 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4798 - accuracy: 0.7812\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4947 - accuracy: 0.7941 - val_loss: 0.9611 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5049 - accuracy: 0.7812\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5259 - accuracy: 0.7647 - val_loss: 0.7935 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4547 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5360 - accuracy: 0.7647 - val_loss: 0.9923 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6380 - accuracy: 0.7188\n",
      "Epoch 00019: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5850 - accuracy: 0.7059 - val_loss: 0.8881 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7065 - accuracy: 0.7188\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6997 - accuracy: 0.7353 - val_loss: 0.8558 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6982 - accuracy: 0.7188\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6684 - accuracy: 0.7353 - val_loss: 0.8262 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5924 - accuracy: 0.7812\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5702 - accuracy: 0.7794 - val_loss: 0.8208 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6955 - accuracy: 0.6875\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5286 - accuracy: 0.7794 - val_loss: 0.8148 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4487 - accuracy: 0.7812\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4859 - accuracy: 0.7794 - val_loss: 0.8011 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5464 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4658 - accuracy: 0.7941 - val_loss: 0.8227 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Using epoch 00019 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5285 - accuracy: 0.8182\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 16:34:08.621455: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_27/dropout_108/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.9610 - accuracy: 0.5882\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9610 - accuracy: 0.5882 - val_loss: 0.7702 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7712 - accuracy: 0.5735\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7712 - accuracy: 0.5735 - val_loss: 3.8611 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2506 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.2506 - accuracy: 0.5147 - val_loss: 2.6794 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8287 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.8287 - accuracy: 0.4853 - val_loss: 2.0498 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2861 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2861 - accuracy: 0.5147 - val_loss: 1.9515 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4225 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4225 - accuracy: 0.5147 - val_loss: 1.3464 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9400 - accuracy: 0.6176\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9400 - accuracy: 0.6176 - val_loss: 1.0059 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6559 - accuracy: 0.6176\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6559 - accuracy: 0.6176 - val_loss: 1.1509 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.6618\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6059 - accuracy: 0.6618 - val_loss: 0.9578 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.6471\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6174 - accuracy: 0.6471 - val_loss: 1.0849 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.6912\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6950 - accuracy: 0.6912 - val_loss: 0.9392 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7353\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5486 - accuracy: 0.7353 - val_loss: 0.9237 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.7500\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5903 - accuracy: 0.7500 - val_loss: 0.9095 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.7353\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4980 - accuracy: 0.7353 - val_loss: 0.8998 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5198 - accuracy: 0.7353\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5198 - accuracy: 0.7353 - val_loss: 0.8925 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7794\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5687 - accuracy: 0.7794 - val_loss: 0.8846 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.8088\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4778 - accuracy: 0.8088 - val_loss: 0.8773 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.7353\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5276 - accuracy: 0.7353 - val_loss: 0.8765 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.7647\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4851 - accuracy: 0.7647 - val_loss: 0.8731 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.7941\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4406 - accuracy: 0.7941 - val_loss: 0.8684 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8088\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4289 - accuracy: 0.8088 - val_loss: 0.8645 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5099 - accuracy: 0.7794\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5099 - accuracy: 0.7794 - val_loss: 0.8620 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7794\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4468 - accuracy: 0.7794 - val_loss: 0.8596 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7794\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4548 - accuracy: 0.7794 - val_loss: 0.8583 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5226 - accuracy: 0.7500 - val_loss: 0.8568 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Using epoch 00003 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.8105 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9965 - accuracy: 0.6324\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 4s 382ms/step - loss: 0.9965 - accuracy: 0.6324 - val_loss: 3.1867 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.9998 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.9463 - accuracy: 0.5147 - val_loss: 1.0006 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0009 - accuracy: 0.4844\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0086 - accuracy: 0.4853 - val_loss: 0.6854 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7893 - accuracy: 0.5625\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7716 - accuracy: 0.5735 - val_loss: 0.7372 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0554 - accuracy: 0.5625\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1412 - accuracy: 0.5588 - val_loss: 0.7484 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0172 - accuracy: 0.5625\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0158 - accuracy: 0.5588 - val_loss: 0.7555 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8738 - accuracy: 0.5781\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8314 - accuracy: 0.6029 - val_loss: 1.0533 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4469 - accuracy: 0.5156\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.4754 - accuracy: 0.5147 - val_loss: 0.7800 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6093 - accuracy: 0.5938\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6107 - accuracy: 0.5882 - val_loss: 0.8135 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6363 - accuracy: 0.4844\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.5821 - accuracy: 0.5000 - val_loss: 0.6995 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7617 - accuracy: 0.5938\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7740 - accuracy: 0.5882 - val_loss: 0.7651 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8797 - accuracy: 0.5312\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8376 - accuracy: 0.5588 - val_loss: 0.7196 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4857 - accuracy: 0.8125\n",
      "Epoch 00013: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5114 - accuracy: 0.7941 - val_loss: 0.6779 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7646 - accuracy: 0.6406\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7558 - accuracy: 0.6324 - val_loss: 0.9434 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8162 - accuracy: 0.6406\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7878 - accuracy: 0.6471 - val_loss: 1.0067 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5743 - accuracy: 0.6875\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5917 - accuracy: 0.6912 - val_loss: 0.8986 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8122 - accuracy: 0.6250\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7846 - accuracy: 0.6324 - val_loss: 0.8139 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1939 - accuracy: 0.5469\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1604 - accuracy: 0.5441 - val_loss: 0.8193 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9680 - accuracy: 0.5938\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9817 - accuracy: 0.5882 - val_loss: 0.7201 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5753 - accuracy: 0.7031\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5608 - accuracy: 0.7206 - val_loss: 0.8444 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9535 - accuracy: 0.6094\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.9230 - accuracy: 0.6029 - val_loss: 0.9114 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5129 - accuracy: 0.7656\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5532 - accuracy: 0.7500 - val_loss: 0.7924 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7475 - accuracy: 0.6250\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7542 - accuracy: 0.6324 - val_loss: 0.7625 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6000 - accuracy: 0.6719\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5990 - accuracy: 0.6765 - val_loss: 0.7518 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5970 - accuracy: 0.6719\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5742 - accuracy: 0.6912 - val_loss: 0.7599 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00013 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6012 - accuracy: 0.6818\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 1.4462 - accuracy: 0.4688\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 2s 140ms/step - loss: 1.8783 - accuracy: 0.4853 - val_loss: 3.7206 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6760 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.5797 - accuracy: 0.4706 - val_loss: 0.8993 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6499 - accuracy: 0.6875\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7144 - accuracy: 0.6029 - val_loss: 0.7900 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8681 - accuracy: 0.6875\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3264 - accuracy: 0.5735 - val_loss: 0.8178 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0379 - accuracy: 0.5938\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8095 - accuracy: 0.6618 - val_loss: 0.8268 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5737 - accuracy: 0.7500\n",
      "Epoch 00006: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7155 - accuracy: 0.6618 - val_loss: 0.8902 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8492 - accuracy: 0.6250\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6322 - accuracy: 0.7059 - val_loss: 1.0107 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6249 - accuracy: 0.7500\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5442 - accuracy: 0.7794 - val_loss: 0.8146 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.1648 - accuracy: 0.5625\n",
      "Epoch 00009: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9137 - accuracy: 0.6029 - val_loss: 0.7192 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6041 - accuracy: 0.6562\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7250 - accuracy: 0.6471 - val_loss: 0.7977 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6683 - accuracy: 0.7188\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5931 - accuracy: 0.7059 - val_loss: 0.8394 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7728 - accuracy: 0.5938\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7789 - accuracy: 0.6324 - val_loss: 0.9074 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3997 - accuracy: 0.8438\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5660 - accuracy: 0.7059 - val_loss: 0.8917 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8050 - accuracy: 0.7188\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6771 - accuracy: 0.6618 - val_loss: 1.1563 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4883 - accuracy: 0.8125\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5065 - accuracy: 0.7794 - val_loss: 1.1832 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4940 - accuracy: 0.7500\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4835 - accuracy: 0.7353 - val_loss: 0.8966 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5056 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5694 - accuracy: 0.7500 - val_loss: 1.0059 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.1349 - accuracy: 0.6250\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8258 - accuracy: 0.6618 - val_loss: 0.9260 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4515 - accuracy: 0.8125\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4261 - accuracy: 0.8088 - val_loss: 0.8771 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3775 - accuracy: 0.8438\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4019 - accuracy: 0.8382 - val_loss: 0.8685 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4145 - accuracy: 0.8125\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4768 - accuracy: 0.7647 - val_loss: 0.8588 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4512 - accuracy: 0.8438\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5478 - accuracy: 0.7500 - val_loss: 0.8671 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3894 - accuracy: 0.7812\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4106 - accuracy: 0.8382 - val_loss: 0.8762 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3552 - accuracy: 0.8750\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4401 - accuracy: 0.8088 - val_loss: 0.8745 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4456 - accuracy: 0.8125\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4206 - accuracy: 0.8529 - val_loss: 0.8981 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00009 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5895 - accuracy: 0.6364\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 1.1550 - accuracy: 0.5781\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 2s 239ms/step - loss: 1.1273 - accuracy: 0.5882 - val_loss: 2.3358 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2426 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.4353 - accuracy: 0.5147 - val_loss: 0.6731 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4102 - accuracy: 0.4844\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.4905 - accuracy: 0.4853 - val_loss: 0.8860 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8330 - accuracy: 0.5312\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.66667, storing weights.\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8082 - accuracy: 0.5441 - val_loss: 0.7265 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0027 - accuracy: 0.5625\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0624 - accuracy: 0.5588 - val_loss: 0.7891 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0242 - accuracy: 0.5781\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0446 - accuracy: 0.5735 - val_loss: 0.8285 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9962 - accuracy: 0.6094\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.9551 - accuracy: 0.6176 - val_loss: 1.1053 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0888 - accuracy: 0.6094\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1230 - accuracy: 0.6029 - val_loss: 0.7969 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5580 - accuracy: 0.7188\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5769 - accuracy: 0.7059 - val_loss: 0.8393 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2389 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1986 - accuracy: 0.5147 - val_loss: 0.7358 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5909 - accuracy: 0.7500\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6106 - accuracy: 0.7206 - val_loss: 0.9024 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9561 - accuracy: 0.5781\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9409 - accuracy: 0.5735 - val_loss: 0.7626 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8707 - accuracy: 0.6406\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8857 - accuracy: 0.6176 - val_loss: 0.7512 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7338 - accuracy: 0.5469\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7215 - accuracy: 0.5588 - val_loss: 0.7488 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6386 - accuracy: 0.6250\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6334 - accuracy: 0.6324 - val_loss: 0.7517 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5747 - accuracy: 0.7500\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5693 - accuracy: 0.7353 - val_loss: 0.7486 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6316 - accuracy: 0.6875\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6365 - accuracy: 0.6912 - val_loss: 0.7589 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5614 - accuracy: 0.7812\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5391 - accuracy: 0.7941 - val_loss: 0.7656 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5295 - accuracy: 0.7500\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5147 - accuracy: 0.7647 - val_loss: 0.7570 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5232 - accuracy: 0.7812\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5015 - accuracy: 0.7941 - val_loss: 0.7674 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5524 - accuracy: 0.6562\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5314 - accuracy: 0.6765 - val_loss: 0.7764 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5823 - accuracy: 0.7188\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5659 - accuracy: 0.7206 - val_loss: 0.7724 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5685 - accuracy: 0.7344\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5823 - accuracy: 0.7206 - val_loss: 0.7719 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5213 - accuracy: 0.7188\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5227 - accuracy: 0.7059 - val_loss: 0.7704 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5882 - accuracy: 0.6875\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5731 - accuracy: 0.7059 - val_loss: 0.7734 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Using epoch 00004 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8129 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 1.2440 - accuracy: 0.5469\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 2s 236ms/step - loss: 1.2636 - accuracy: 0.5294 - val_loss: 1.8716 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.5817 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.5156 - accuracy: 0.5147 - val_loss: 0.7129 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0184 - accuracy: 0.5781\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.66667, storing weights.\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0361 - accuracy: 0.5735 - val_loss: 0.6491 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7588 - accuracy: 0.5781\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7579 - accuracy: 0.5882 - val_loss: 0.6544 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8033 - accuracy: 0.5625\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8412 - accuracy: 0.5588 - val_loss: 0.7962 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1057 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1843 - accuracy: 0.5000 - val_loss: 0.8182 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0454 - accuracy: 0.5781\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.9949 - accuracy: 0.6029 - val_loss: 1.1664 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3850 - accuracy: 0.5312\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.3920 - accuracy: 0.5147 - val_loss: 0.8747 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5734 - accuracy: 0.7031\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5813 - accuracy: 0.7059 - val_loss: 0.8962 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4174 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.3542 - accuracy: 0.5147 - val_loss: 0.7812 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4938 - accuracy: 0.7969\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4863 - accuracy: 0.7941 - val_loss: 0.8711 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9692 - accuracy: 0.5312\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.9210 - accuracy: 0.5588 - val_loss: 0.8013 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6627 - accuracy: 0.6562\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6840 - accuracy: 0.6324 - val_loss: 0.7761 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7257 - accuracy: 0.6562\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6996 - accuracy: 0.6765 - val_loss: 0.7690 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6196 - accuracy: 0.6875\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6000 - accuracy: 0.7059 - val_loss: 0.7739 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6790 - accuracy: 0.6875\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6614 - accuracy: 0.6912 - val_loss: 0.7599 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5354 - accuracy: 0.7031\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5185 - accuracy: 0.7206 - val_loss: 0.7673 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6310 - accuracy: 0.7031\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6154 - accuracy: 0.7206 - val_loss: 0.7682 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5681 - accuracy: 0.7031\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5534 - accuracy: 0.7059 - val_loss: 0.7573 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5233 - accuracy: 0.7812\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5156 - accuracy: 0.7941 - val_loss: 0.7638 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5781 - accuracy: 0.6875\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5708 - accuracy: 0.6912 - val_loss: 0.7666 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5962 - accuracy: 0.7031\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5814 - accuracy: 0.7059 - val_loss: 0.7618 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5988 - accuracy: 0.6562\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5971 - accuracy: 0.6618 - val_loss: 0.7687 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4480 - accuracy: 0.7500\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4762 - accuracy: 0.7206 - val_loss: 0.7663 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5023 - accuracy: 0.7344\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4998 - accuracy: 0.7353 - val_loss: 0.7701 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Using epoch 00003 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7806 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3507 - accuracy: 0.5882\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3507 - accuracy: 0.5882 - val_loss: 1.8771 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5324 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.5324 - accuracy: 0.5147 - val_loss: 2.6594 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5099 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.5099 - accuracy: 0.4853 - val_loss: 0.8754 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5096 - accuracy: 0.5147\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5096 - accuracy: 0.5147 - val_loss: 2.0689 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.6870 - accuracy: 0.4853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.6870 - accuracy: 0.4853 - val_loss: 0.8163 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4748 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4748 - accuracy: 0.5147 - val_loss: 1.6832 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0612 - accuracy: 0.4853\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0612 - accuracy: 0.4853 - val_loss: 0.8557 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7235 - accuracy: 0.5147\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7235 - accuracy: 0.5147 - val_loss: 1.4047 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4345 - accuracy: 0.4853\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.4345 - accuracy: 0.4853 - val_loss: 0.8398 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.5147\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5848 - accuracy: 0.5147 - val_loss: 1.2064 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9130 - accuracy: 0.4853\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.9130 - accuracy: 0.4853 - val_loss: 0.8890 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5500 - accuracy: 0.5147\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.5500 - accuracy: 0.5147 - val_loss: 1.0682 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6755 - accuracy: 0.4853\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.6755 - accuracy: 0.4853 - val_loss: 0.9451 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4396 - accuracy: 0.5588\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4396 - accuracy: 0.5588 - val_loss: 0.9765 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2711 - accuracy: 0.5294\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2711 - accuracy: 0.5294 - val_loss: 1.0187 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2648 - accuracy: 0.5735\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2648 - accuracy: 0.5735 - val_loss: 1.0434 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8745 - accuracy: 0.6029\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8745 - accuracy: 0.6029 - val_loss: 1.0808 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7654 - accuracy: 0.6176\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7654 - accuracy: 0.6176 - val_loss: 1.1226 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.6324\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6970 - accuracy: 0.6324 - val_loss: 1.1709 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.6618\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5314 - accuracy: 0.6618 - val_loss: 1.2154 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.7206\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5268 - accuracy: 0.7206 - val_loss: 1.2596 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.6618\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6069 - accuracy: 0.6618 - val_loss: 1.2963 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.7794\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5341 - accuracy: 0.7794 - val_loss: 1.3383 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7500\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4749 - accuracy: 0.7500 - val_loss: 1.3709 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.6471\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6868 - accuracy: 0.6471 - val_loss: 1.4023 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00002 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0193 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 1.3119 - accuracy: 0.5312\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 2s 125ms/step - loss: 1.0855 - accuracy: 0.4853 - val_loss: 1.9517 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6395 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.9983 - accuracy: 0.4559 - val_loss: 0.8347 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9606 - accuracy: 0.5938\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.61111, storing weights.\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9873 - accuracy: 0.5882 - val_loss: 0.7835 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5027 - accuracy: 0.6875\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7342 - accuracy: 0.6324 - val_loss: 0.8303 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2608 - accuracy: 0.6250\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9088 - accuracy: 0.6765 - val_loss: 0.8134 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5577 - accuracy: 0.7500\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6956 - accuracy: 0.6471 - val_loss: 0.8116 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7236 - accuracy: 0.5938\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5916 - accuracy: 0.7353 - val_loss: 0.9639 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6679 - accuracy: 0.7500\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6381 - accuracy: 0.7059 - val_loss: 0.7676 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0823 - accuracy: 0.5625\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9160 - accuracy: 0.6029 - val_loss: 0.7465 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9163 - accuracy: 0.4688\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0786 - accuracy: 0.4853 - val_loss: 0.8135 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5800 - accuracy: 0.6875\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5430 - accuracy: 0.7353 - val_loss: 0.7739 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0263 - accuracy: 0.5000\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8543 - accuracy: 0.6029 - val_loss: 0.9225 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4217 - accuracy: 0.8438\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6369 - accuracy: 0.6765 - val_loss: 0.7680 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5928 - accuracy: 0.7812\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5182 - accuracy: 0.7647 - val_loss: 1.0327 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3870 - accuracy: 0.7500\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4789 - accuracy: 0.7059 - val_loss: 0.9323 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5095 - accuracy: 0.7500\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5041 - accuracy: 0.7500 - val_loss: 0.8660 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5732 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5849 - accuracy: 0.7206 - val_loss: 0.8828 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9073 - accuracy: 0.6250\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7957 - accuracy: 0.6029 - val_loss: 0.9574 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6752 - accuracy: 0.6562\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5466 - accuracy: 0.7353 - val_loss: 0.9059 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3784 - accuracy: 0.8438\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4735 - accuracy: 0.8088 - val_loss: 0.8923 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4764 - accuracy: 0.7500\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4668 - accuracy: 0.7500 - val_loss: 0.8756 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4649 - accuracy: 0.7188\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4376 - accuracy: 0.7794 - val_loss: 0.8829 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4928 - accuracy: 0.7500\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4752 - accuracy: 0.7353 - val_loss: 0.8824 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4759 - accuracy: 0.6875\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5285 - accuracy: 0.6912 - val_loss: 0.8748 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4580 - accuracy: 0.7812\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4261 - accuracy: 0.8235 - val_loss: 0.8913 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00017 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5106 - accuracy: 0.8182\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6729 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 2s 246ms/step - loss: 1.6729 - accuracy: 0.5147 - val_loss: 3.8425 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8731 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2.5978 - accuracy: 0.4706 - val_loss: 0.8345 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6678 - accuracy: 0.7188\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9281 - accuracy: 0.5588 - val_loss: 0.8419 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6838 - accuracy: 0.6250\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7091 - accuracy: 0.6029 - val_loss: 0.7837 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8546 - accuracy: 0.6250\n",
      "Epoch 00005: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6752 - accuracy: 0.6765 - val_loss: 0.9167 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6385 - accuracy: 0.6562\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6844 - accuracy: 0.6176 - val_loss: 0.9293 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8352 - accuracy: 0.5938\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6965 - accuracy: 0.6618 - val_loss: 0.9865 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6127 - accuracy: 0.7188\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6492 - accuracy: 0.6618 - val_loss: 0.9538 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9681 - accuracy: 0.6250\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7591 - accuracy: 0.6912 - val_loss: 0.7656 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5963 - accuracy: 0.7500\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5022 - accuracy: 0.7647 - val_loss: 0.8229 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5808 - accuracy: 0.7188\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5667 - accuracy: 0.6912 - val_loss: 0.9375 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0703 - accuracy: 0.5000\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9091 - accuracy: 0.5735 - val_loss: 0.9548 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4992 - accuracy: 0.8125\n",
      "Epoch 00013: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5894 - accuracy: 0.7059 - val_loss: 0.8051 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6914 - accuracy: 0.7188\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5901 - accuracy: 0.7353 - val_loss: 1.1231 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4601 - accuracy: 0.7812\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5477 - accuracy: 0.7206 - val_loss: 1.0456 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6075 - accuracy: 0.7188\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5547 - accuracy: 0.7059 - val_loss: 0.8983 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6138 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5840 - accuracy: 0.7206 - val_loss: 1.0051 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3645 - accuracy: 0.5312\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9986 - accuracy: 0.6176 - val_loss: 0.9588 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3937 - accuracy: 0.8438\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4022 - accuracy: 0.8235 - val_loss: 0.9232 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4909 - accuracy: 0.7812\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4705 - accuracy: 0.7941 - val_loss: 0.8852 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4344 - accuracy: 0.7500\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5493 - accuracy: 0.6765 - val_loss: 0.8569 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5149 - accuracy: 0.7500\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5022 - accuracy: 0.7647 - val_loss: 0.8722 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3754 - accuracy: 0.8750\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3936 - accuracy: 0.8088 - val_loss: 0.8700 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3791 - accuracy: 0.7812\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4460 - accuracy: 0.7647 - val_loss: 0.8594 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6056 - accuracy: 0.6562\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4535 - accuracy: 0.7794 - val_loss: 0.8757 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00013 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6346 - accuracy: 0.7273\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 1.0411 - accuracy: 0.5781\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 2s 246ms/step - loss: 1.0297 - accuracy: 0.5882 - val_loss: 1.7006 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9544 - accuracy: 0.5312\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1561 - accuracy: 0.5294 - val_loss: 0.7859 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6396 - accuracy: 0.6250\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6295 - accuracy: 0.6471 - val_loss: 0.7797 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7435 - accuracy: 0.6094\n",
      "Epoch 00004: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7367 - accuracy: 0.6176 - val_loss: 0.7929 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9390 - accuracy: 0.5469\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0682 - accuracy: 0.5441 - val_loss: 0.8250 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7343 - accuracy: 0.5938\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7686 - accuracy: 0.5882 - val_loss: 0.8444 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1744 - accuracy: 0.5312\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1092 - accuracy: 0.5588 - val_loss: 1.1173 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0862 - accuracy: 0.5781\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0835 - accuracy: 0.5735 - val_loss: 0.7945 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6588 - accuracy: 0.6250\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7046 - accuracy: 0.5882 - val_loss: 0.8269 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2671 - accuracy: 0.4844\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.2508 - accuracy: 0.4853 - val_loss: 0.7291 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6873 - accuracy: 0.5781\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6914 - accuracy: 0.5882 - val_loss: 0.7702 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7681 - accuracy: 0.5625\n",
      "Epoch 00012: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7352 - accuracy: 0.5882 - val_loss: 0.7297 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6479 - accuracy: 0.6406\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6523 - accuracy: 0.6471 - val_loss: 0.7710 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9149 - accuracy: 0.5312\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8894 - accuracy: 0.5441 - val_loss: 0.7981 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6305 - accuracy: 0.7344\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6330 - accuracy: 0.7206 - val_loss: 1.0621 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6328 - accuracy: 0.7344\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6479 - accuracy: 0.7206 - val_loss: 0.7929 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7585 - accuracy: 0.5781\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7429 - accuracy: 0.5882 - val_loss: 1.1152 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6323 - accuracy: 0.5156\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.5692 - accuracy: 0.5294 - val_loss: 0.9007 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7292 - accuracy: 0.6719\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7210 - accuracy: 0.6618 - val_loss: 0.7987 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6337 - accuracy: 0.6562\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6110 - accuracy: 0.6618 - val_loss: 0.9029 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7994 - accuracy: 0.6562\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7550 - accuracy: 0.6765 - val_loss: 0.8756 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7050 - accuracy: 0.6875\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7331 - accuracy: 0.6912 - val_loss: 0.8457 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5467 - accuracy: 0.7344\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5932 - accuracy: 0.7059 - val_loss: 0.8246 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5185 - accuracy: 0.7344\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5116 - accuracy: 0.7353 - val_loss: 0.8277 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4888 - accuracy: 0.7812\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4759 - accuracy: 0.7941 - val_loss: 0.8299 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Using epoch 00012 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6138 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 1.3191 - accuracy: 0.4375\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 2s 140ms/step - loss: 1.4763 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.1598 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.61111, storing weights.\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2.1886 - accuracy: 0.4559 - val_loss: 0.6557 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7574 - accuracy: 0.6562\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7587 - accuracy: 0.6618 - val_loss: 0.6631 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.7206\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6344 - accuracy: 0.7206 - val_loss: 0.6808 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6717 - accuracy: 0.6406\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6875 - accuracy: 0.6471 - val_loss: 0.7384 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.6912\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5558 - accuracy: 0.6912 - val_loss: 0.7432 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7181 - accuracy: 0.5625\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6048 - accuracy: 0.6765 - val_loss: 0.9841 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0812 - accuracy: 0.5938\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.1395 - accuracy: 0.5882 - val_loss: 0.7277 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8227 - accuracy: 0.5882\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.8227 - accuracy: 0.5882 - val_loss: 0.6876 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9577 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.1147 - accuracy: 0.5000 - val_loss: 0.7158 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5589 - accuracy: 0.7500\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5499 - accuracy: 0.7353 - val_loss: 0.8079 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2029 - accuracy: 0.4062\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1112 - accuracy: 0.4706 - val_loss: 0.8611 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4304 - accuracy: 0.8125\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5272 - accuracy: 0.7647 - val_loss: 0.8323 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4501 - accuracy: 0.7812\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4445 - accuracy: 0.7941 - val_loss: 0.8391 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4983 - accuracy: 0.7500\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5107 - accuracy: 0.7500 - val_loss: 0.8397 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4793 - accuracy: 0.6250\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4809 - accuracy: 0.6765 - val_loss: 0.7869 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4770 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4850 - accuracy: 0.7647 - val_loss: 0.8258 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5954 - accuracy: 0.7188\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5610 - accuracy: 0.7059 - val_loss: 0.8266 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4673 - accuracy: 0.6875\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4658 - accuracy: 0.7206 - val_loss: 0.8028 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5534 - accuracy: 0.6875\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6177 - accuracy: 0.6618 - val_loss: 0.8143 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3857 - accuracy: 0.8125\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5149 - accuracy: 0.7941 - val_loss: 0.7945 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5951 - accuracy: 0.6875\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5252 - accuracy: 0.7353 - val_loss: 0.7872 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4036 - accuracy: 0.8125\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4437 - accuracy: 0.7647 - val_loss: 0.7879 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4652 - accuracy: 0.7188\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5176 - accuracy: 0.7206 - val_loss: 0.7863 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6299 - accuracy: 0.6562\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5188 - accuracy: 0.7647 - val_loss: 0.7892 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00002 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8230 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 1.7043 - accuracy: 0.4531\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 2s 227ms/step - loss: 1.6532 - accuracy: 0.4559 - val_loss: 2.8870 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3949 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2.5396 - accuracy: 0.5147 - val_loss: 0.8491 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9827 - accuracy: 0.5938\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0438 - accuracy: 0.5882 - val_loss: 0.7833 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7141 - accuracy: 0.6250\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7087 - accuracy: 0.6324 - val_loss: 0.8016 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9736 - accuracy: 0.5625\n",
      "Epoch 00005: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0439 - accuracy: 0.5588 - val_loss: 0.8207 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1351 - accuracy: 0.5156\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1132 - accuracy: 0.5294 - val_loss: 0.7916 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6218 - accuracy: 0.6719\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6112 - accuracy: 0.6765 - val_loss: 1.1820 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7823 - accuracy: 0.5156\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.7656 - accuracy: 0.5000 - val_loss: 0.8307 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8148 - accuracy: 0.5000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8108 - accuracy: 0.5000 - val_loss: 0.8593 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8930 - accuracy: 0.5625\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.8739 - accuracy: 0.5735 - val_loss: 0.7421 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8906 - accuracy: 0.5625\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8734 - accuracy: 0.5588 - val_loss: 0.8238 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6884 - accuracy: 0.6406\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6804 - accuracy: 0.6471 - val_loss: 0.7556 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6143 - accuracy: 0.7344\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6169 - accuracy: 0.7353 - val_loss: 0.8505 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7799 - accuracy: 0.5625\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7541 - accuracy: 0.5735 - val_loss: 0.8011 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5937 - accuracy: 0.6875\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5759 - accuracy: 0.6912 - val_loss: 1.1811 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6193 - accuracy: 0.6562\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6348 - accuracy: 0.6471 - val_loss: 0.8848 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7445 - accuracy: 0.6562\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7675 - accuracy: 0.6471 - val_loss: 1.0991 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1745 - accuracy: 0.5625\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1199 - accuracy: 0.5882 - val_loss: 0.8950 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5185 - accuracy: 0.7500\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5221 - accuracy: 0.7353 - val_loss: 0.8571 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5995 - accuracy: 0.7500\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5830 - accuracy: 0.7647 - val_loss: 0.9624 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7194 - accuracy: 0.6250\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6835 - accuracy: 0.6471 - val_loss: 0.9310 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5547 - accuracy: 0.7031\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6065 - accuracy: 0.6912 - val_loss: 0.8836 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5757 - accuracy: 0.7031\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6157 - accuracy: 0.6912 - val_loss: 0.8673 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5010 - accuracy: 0.7500\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5131 - accuracy: 0.7500 - val_loss: 0.8616 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5193 - accuracy: 0.7969\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5214 - accuracy: 0.7941 - val_loss: 0.8702 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Using epoch 00005 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7809 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9602 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66667, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9602 - accuracy: 0.5294 - val_loss: 0.6789 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0065 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0065 - accuracy: 0.5441 - val_loss: 3.9523 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.0417 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy improved from 0.66667 to 0.72222, storing weights.\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.0417 - accuracy: 0.4853 - val_loss: 0.7214 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7292 - accuracy: 0.6324\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7292 - accuracy: 0.6324 - val_loss: 1.2602 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3637 - accuracy: 0.5000\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3637 - accuracy: 0.5000 - val_loss: 1.6896 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4853 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.4853 - accuracy: 0.5147 - val_loss: 1.3619 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2482 - accuracy: 0.5441\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2482 - accuracy: 0.5441 - val_loss: 1.0614 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.6176\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9885 - accuracy: 0.6176 - val_loss: 1.1278 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9750 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9750 - accuracy: 0.6029 - val_loss: 0.9972 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7814 - accuracy: 0.6029\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7814 - accuracy: 0.6029 - val_loss: 0.9592 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.6176\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7896 - accuracy: 0.6176 - val_loss: 1.0106 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.6765\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6542 - accuracy: 0.6765 - val_loss: 0.9640 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7059\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5678 - accuracy: 0.7059 - val_loss: 0.9296 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5791 - accuracy: 0.6912\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5791 - accuracy: 0.6912 - val_loss: 0.9029 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.7353\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5319 - accuracy: 0.7353 - val_loss: 0.8842 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.6176\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6234 - accuracy: 0.6176 - val_loss: 0.8708 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.6912\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5506 - accuracy: 0.6912 - val_loss: 0.8581 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7059\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5853 - accuracy: 0.7059 - val_loss: 0.8485 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7941\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5656 - accuracy: 0.7941 - val_loss: 0.8439 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.7647\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4508 - accuracy: 0.7647 - val_loss: 0.8398 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.7059\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5217 - accuracy: 0.7059 - val_loss: 0.8359 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.6912\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5110 - accuracy: 0.6912 - val_loss: 0.8335 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.7500\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4872 - accuracy: 0.7500 - val_loss: 0.8311 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.7647\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4920 - accuracy: 0.7647 - val_loss: 0.8295 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.7206\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4831 - accuracy: 0.7206 - val_loss: 0.8279 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
      "Using epoch 00003 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7665 - accuracy: 0.5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in [FatigueMI]:\n",
    "    for model in [\"deep_conv_net\"]:\n",
    "        model_optimizer = ModelOptimizer(\n",
    "            dataset=dataset(),\n",
    "            model_name=model\n",
    "        )\n",
    "        for subject in [4]:\n",
    "            max_epochs = MODELS_HYPERPARAMS_DICT[model][\"max_epochs\"]\n",
    "            study = model_optimizer.search_best_model(\n",
    "                subjects = [subject],\n",
    "                max_iter = 25,\n",
    "                max_epochs = max_epochs,\n",
    "                max_stag_count = 10,\n",
    "                rounds = 1,\n",
    "                replace_previous_study_for_subjects = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.746527</td>\n",
       "      <td>0.320440</td>\n",
       "      <td>0.510645</td>\n",
       "      <td>0.111411</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.465769</td>\n",
       "      <td>0.722489</td>\n",
       "      <td>0.256720</td>\n",
       "      <td>0.528529</td>\n",
       "      <td>0.111461</td>\n",
       "      <td>[C3, F3, P4, Pz, Fp1, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.511425</td>\n",
       "      <td>0.677925</td>\n",
       "      <td>0.166501</td>\n",
       "      <td>0.601170</td>\n",
       "      <td>0.151535</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.212418</td>\n",
       "      <td>0.393579</td>\n",
       "      <td>0.765586</td>\n",
       "      <td>0.372007</td>\n",
       "      <td>0.634555</td>\n",
       "      <td>0.151635</td>\n",
       "      <td>[C3, F3, P4, Pz, Fp1, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.297386</td>\n",
       "      <td>0.401931</td>\n",
       "      <td>0.719241</td>\n",
       "      <td>0.317310</td>\n",
       "      <td>0.589530</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[C3, F3, P4, Pz, Fp1, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.253268</td>\n",
       "      <td>0.475239</td>\n",
       "      <td>0.728204</td>\n",
       "      <td>0.252965</td>\n",
       "      <td>0.585471</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[C3, F3, P4, Pz, Fp1, F8, A2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.282680</td>\n",
       "      <td>0.433113</td>\n",
       "      <td>0.803900</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>4.245121</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.459921</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.387653</td>\n",
       "      <td>1.007001</td>\n",
       "      <td>0.198181</td>\n",
       "      <td>[P3, Fz, F4, C4, P4, Pz, Fp2, T3, O2, F7, F8, ...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.643993</td>\n",
       "      <td>0.173841</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.299933</td>\n",
       "      <td>[F3, Fz, F4, C4, P4, Fp1, T3, F7, F8, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>0.450798</td>\n",
       "      <td>0.678867</td>\n",
       "      <td>0.228069</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.327461</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.501527</td>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.171614</td>\n",
       "      <td>0.812934</td>\n",
       "      <td>0.361411</td>\n",
       "      <td>[F3, P4, Pz, Fp1, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.475896</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.253248</td>\n",
       "      <td>0.613841</td>\n",
       "      <td>0.361411</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.476239</td>\n",
       "      <td>0.649146</td>\n",
       "      <td>0.172907</td>\n",
       "      <td>0.780630</td>\n",
       "      <td>0.361461</td>\n",
       "      <td>[C3, F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.457281</td>\n",
       "      <td>0.649031</td>\n",
       "      <td>0.191750</td>\n",
       "      <td>0.962770</td>\n",
       "      <td>0.361561</td>\n",
       "      <td>[C3, C4, Pz, Fp1, T3, T5, O2, F7, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.447038</td>\n",
       "      <td>0.705257</td>\n",
       "      <td>0.258219</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>[Fz, F4, Cz, Pz, Fp2, T5, O1, O2, F7, A2, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.513062</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.229076</td>\n",
       "      <td>0.780920</td>\n",
       "      <td>0.401535</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.443732</td>\n",
       "      <td>0.655729</td>\n",
       "      <td>0.211996</td>\n",
       "      <td>0.822956</td>\n",
       "      <td>0.401535</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>0.484263</td>\n",
       "      <td>0.681239</td>\n",
       "      <td>0.196976</td>\n",
       "      <td>1.099974</td>\n",
       "      <td>0.401685</td>\n",
       "      <td>[F4, Cz, T3, T5, O1, O2, F7, A2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>0.462898</td>\n",
       "      <td>0.680737</td>\n",
       "      <td>0.217839</td>\n",
       "      <td>1.212218</td>\n",
       "      <td>0.401985</td>\n",
       "      <td>[P3, F3, F4, C4, P4, Cz, Pz, Fp2, T3, T5, O1, ...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.223856</td>\n",
       "      <td>0.474950</td>\n",
       "      <td>0.816264</td>\n",
       "      <td>0.341315</td>\n",
       "      <td>3.019331</td>\n",
       "      <td>0.447831</td>\n",
       "      <td>[P3, C3, Fz, Fp1, Fp2, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.282680</td>\n",
       "      <td>0.456388</td>\n",
       "      <td>0.713644</td>\n",
       "      <td>0.257256</td>\n",
       "      <td>0.684647</td>\n",
       "      <td>0.447881</td>\n",
       "      <td>[C3, F3, P4, Pz, Fp1, F8, A2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.253268</td>\n",
       "      <td>0.428921</td>\n",
       "      <td>0.770177</td>\n",
       "      <td>0.341256</td>\n",
       "      <td>2.810461</td>\n",
       "      <td>0.447881</td>\n",
       "      <td>[C3, F3, P4, Pz, Fp1, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.238562</td>\n",
       "      <td>0.480138</td>\n",
       "      <td>0.878601</td>\n",
       "      <td>0.398463</td>\n",
       "      <td>2.843585</td>\n",
       "      <td>0.447931</td>\n",
       "      <td>[C3, F3, P4, Cz, T3, O2, F8, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.253268</td>\n",
       "      <td>0.475721</td>\n",
       "      <td>0.826690</td>\n",
       "      <td>0.350970</td>\n",
       "      <td>1.314247</td>\n",
       "      <td>0.448031</td>\n",
       "      <td>[P3, F3, Fz, C4, Fp1, T5, O1, O2, F8, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.223856</td>\n",
       "      <td>0.458450</td>\n",
       "      <td>0.777889</td>\n",
       "      <td>0.319439</td>\n",
       "      <td>2.856455</td>\n",
       "      <td>0.448181</td>\n",
       "      <td>[P3, C3, F3, C4, P4, Cz, Pz, Fp2, T5, O1, O2, ...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff  train_loss  val_loss  \\\n",
       "19   0.823529  0.818182  0.666667            0.156863    0.426087  0.746527   \n",
       "12   0.794118  0.818182  0.666667            0.127451    0.465769  0.722489   \n",
       "14   0.794118  0.681818  0.611111            0.183007    0.511425  0.677925   \n",
       "20   0.823529  0.727273  0.611111            0.212418    0.393579  0.765586   \n",
       "15   0.852941  0.636364  0.555556            0.297386    0.401931  0.719241   \n",
       "10   0.808824  0.681818  0.555556            0.253268    0.475239  0.728204   \n",
       "6    0.838235  0.500000  0.555556            0.282680    0.433113  0.803900   \n",
       "7    0.823529  0.500000  0.555556            0.267974    0.459921  0.847574   \n",
       "9    0.794118  0.500000  0.777778            0.016340    0.470152  0.643993   \n",
       "24   0.794118  0.500000  0.722222            0.071895    0.450798  0.678867   \n",
       "16   0.794118  0.545455  0.666667            0.127451    0.501527  0.673141   \n",
       "21   0.794118  0.545455  0.666667            0.127451    0.475896  0.729144   \n",
       "17   0.794118  0.454545  0.666667            0.127451    0.476239  0.649146   \n",
       "5    0.823529  0.454545  0.666667            0.156863    0.457281  0.649031   \n",
       "3    0.794118  0.454545  0.666667            0.127451    0.447038  0.705257   \n",
       "23   0.794118  0.545455  0.611111            0.183007    0.513062  0.742138   \n",
       "22   0.794118  0.545455  0.611111            0.183007    0.443732  0.655729   \n",
       "8    0.764706  0.409091  0.611111            0.153595    0.484263  0.681239   \n",
       "2    0.764706  0.500000  0.611111            0.153595    0.462898  0.680737   \n",
       "18   0.779412  0.500000  0.555556            0.223856    0.474950  0.816264   \n",
       "11   0.838235  0.409091  0.555556            0.282680    0.456388  0.713644   \n",
       "13   0.808824  0.500000  0.555556            0.253268    0.428921  0.770177   \n",
       "1    0.794118  0.500000  0.555556            0.238562    0.480138  0.878601   \n",
       "0    0.808824  0.500000  0.555556            0.253268    0.475721  0.826690   \n",
       "4    0.779412  0.500000  0.555556            0.223856    0.458450  0.777889   \n",
       "\n",
       "    train_val_loss_diff  test_loss    scores  \\\n",
       "19             0.320440   0.510645  0.111411   \n",
       "12             0.256720   0.528529  0.111461   \n",
       "14             0.166501   0.601170  0.151535   \n",
       "20             0.372007   0.634555  0.151635   \n",
       "15             0.317310   0.589530  0.197881   \n",
       "10             0.252965   0.585471  0.197881   \n",
       "6              0.370787   4.245121  0.197881   \n",
       "7              0.387653   1.007001  0.198181   \n",
       "9              0.173841   0.716353  0.299933   \n",
       "24             0.228069   0.766537  0.327461   \n",
       "16             0.171614   0.812934  0.361411   \n",
       "21             0.253248   0.613841  0.361411   \n",
       "17             0.172907   0.780630  0.361461   \n",
       "5              0.191750   0.962770  0.361561   \n",
       "3              0.258219   0.864734  0.361711   \n",
       "23             0.229076   0.780920  0.401535   \n",
       "22             0.211996   0.822956  0.401535   \n",
       "8              0.196976   1.099974  0.401685   \n",
       "2              0.217839   1.212218  0.401985   \n",
       "18             0.341315   3.019331  0.447831   \n",
       "11             0.257256   0.684647  0.447881   \n",
       "13             0.341256   2.810461  0.447881   \n",
       "1              0.398463   2.843585  0.447931   \n",
       "0              0.350970   1.314247  0.448031   \n",
       "4              0.319439   2.856455  0.448181   \n",
       "\n",
       "                                    channels_selected  sfreq  batch_size  \\\n",
       "19                           [F3, P4, Pz, F7, F8, A2]  300.0          32   \n",
       "12                      [C3, F3, P4, Pz, Fp1, F8, A2]  300.0          32   \n",
       "14                           [F3, P4, Pz, F7, F8, A2]  300.0          64   \n",
       "20                  [C3, F3, P4, Pz, Fp1, F7, F8, A2]  300.0          32   \n",
       "15                      [C3, F3, P4, Pz, Fp1, F8, A2]  300.0          32   \n",
       "10                      [C3, F3, P4, Pz, Fp1, F8, A2]  128.0          32   \n",
       "6                        [F3, P4, Pz, F7, F8, A2, T4]  256.0          96   \n",
       "7   [P3, Fz, F4, C4, P4, Pz, Fp2, T3, O2, F7, F8, ...  256.0          96   \n",
       "9       [F3, Fz, F4, C4, P4, Fp1, T3, F7, F8, T6, T4]  256.0          64   \n",
       "24                           [F3, P4, Pz, F7, F8, A2]  300.0         128   \n",
       "16                          [F3, P4, Pz, Fp1, F8, A2]  300.0          64   \n",
       "21                           [F3, P4, Pz, F7, F8, A2]  300.0          64   \n",
       "17                       [C3, F3, P4, Pz, F7, F8, A2]  300.0          64   \n",
       "5               [C3, C4, Pz, Fp1, T3, T5, O2, F7, A2]  256.0         256   \n",
       "3   [Fz, F4, Cz, Pz, Fp2, T5, O1, O2, F7, A2, T6, T4]  256.0         192   \n",
       "23                           [F3, P4, Pz, F7, F8, A2]  300.0          64   \n",
       "22                           [F3, P4, Pz, F7, F8, A2]  300.0          32   \n",
       "8                [F4, Cz, T3, T5, O1, O2, F7, A2, T6]  256.0         192   \n",
       "2   [P3, F3, F4, C4, P4, Cz, Pz, Fp2, T3, T5, O1, ...  256.0          96   \n",
       "18                         [P3, C3, Fz, Fp1, Fp2, T6]  300.0         128   \n",
       "11                      [C3, F3, P4, Pz, Fp1, F8, A2]  128.0          32   \n",
       "13                      [C3, F3, P4, Pz, Fp1, F8, A2]  300.0          96   \n",
       "1                    [C3, F3, P4, Cz, T3, O2, F8, T4]  256.0         160   \n",
       "0           [P3, F3, Fz, C4, Fp1, T5, O1, O2, F8, T4]  256.0         160   \n",
       "4   [P3, C3, F3, C4, P4, Cz, Pz, Fp2, T5, O1, O2, ...  256.0         256   \n",
       "\n",
       "       model_name subjects  \n",
       "19  deep_conv_net      [4]  \n",
       "12  deep_conv_net      [4]  \n",
       "14  deep_conv_net      [4]  \n",
       "20  deep_conv_net      [4]  \n",
       "15  deep_conv_net      [4]  \n",
       "10  deep_conv_net      [4]  \n",
       "6   deep_conv_net      [4]  \n",
       "7   deep_conv_net      [4]  \n",
       "9   deep_conv_net      [4]  \n",
       "24  deep_conv_net      [4]  \n",
       "16  deep_conv_net      [4]  \n",
       "21  deep_conv_net      [4]  \n",
       "17  deep_conv_net      [4]  \n",
       "5   deep_conv_net      [4]  \n",
       "3   deep_conv_net      [4]  \n",
       "23  deep_conv_net      [4]  \n",
       "22  deep_conv_net      [4]  \n",
       "8   deep_conv_net      [4]  \n",
       "2   deep_conv_net      [4]  \n",
       "18  deep_conv_net      [4]  \n",
       "11  deep_conv_net      [4]  \n",
       "13  deep_conv_net      [4]  \n",
       "1   deep_conv_net      [4]  \n",
       "0   deep_conv_net      [4]  \n",
       "4   deep_conv_net      [4]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_optimizer.get_study_metrics(study).sort_values(by=\"scores\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8181818127632141</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test_accuracy = \u001b[1;36m0.8181818127632141\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666865348816</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val_accuracy = \u001b[1;36m0.6666666865348816\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">channels_selected = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'F3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'P4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Pz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F7'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F8'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'A2'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "channels_selected = \u001b[1m[\u001b[0m\u001b[32m'F3'\u001b[0m \u001b[32m'P4'\u001b[0m \u001b[32m'Pz'\u001b[0m \u001b[32m'F7'\u001b[0m \u001b[32m'F8'\u001b[0m \u001b[32m'A2'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint({ k: v for k, v in study.best_trial.params.items() if not k.startswith(\"channels\") })\n",
    "rprint(\"test_accuracy =\", study.best_trial.user_attrs[\"trial_data\"][\"test_accuracy\"])\n",
    "rprint(\"val_accuracy =\", np.max(study.best_trial.user_attrs[\"trial_data\"][\"val_accuracy\"]))\n",
    "rprint(\"channels_selected =\", study.best_trial.user_attrs[\"trial_data\"][\"channels_selected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fatigue_mi_studies = glob.glob(\"./temp/FatigueMI/**/**/model/*_study.npy\") + glob.glob(\"./temp/FatigueMI/**/**/model/shallow_conv_net_study_best_trial.npy\")\n",
    "temp_fatigue_mi_studies_dict = {}\n",
    "temp_fatigue_mi_studies_file_names_dict = {}\n",
    "\n",
    "for study_file in temp_fatigue_mi_studies:\n",
    "    study = np.load(study_file, allow_pickle=True).item()\n",
    "    subject_number = int(study_file.split(\"[\")[1].split(']')[0])\n",
    "    model_name = study_file.split(\"/\")[-1].replace(\"_study.npy\", \"\").replace(\"shallow_conv_net_study_best_trial.npy\", \"shallow_conv_net\")\n",
    "    temp_fatigue_mi_studies_dict[f\"{subject_number}_{model_name}\"] = study\n",
    "    temp_fatigue_mi_studies_file_names_dict[f\"{subject_number}_{model_name}\"] = study_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>1.209507</td>\n",
       "      <td>1.407622</td>\n",
       "      <td>0.198116</td>\n",
       "      <td>1.633958</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.157701</td>\n",
       "      <td>0.673368</td>\n",
       "      <td>0.198031</td>\n",
       "      <td>[P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200980</td>\n",
       "      <td>84.76915</td>\n",
       "      <td>82.498848</td>\n",
       "      <td>2.270302</td>\n",
       "      <td>90.271187</td>\n",
       "      <td>0.111561</td>\n",
       "      <td>[F3, Fz, F4, Fp2, T3, T5, F7, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.192810</td>\n",
       "      <td>14.35515</td>\n",
       "      <td>14.367508</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>18.714355</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>[F3, F4, Cz, Pz, Fp1, Fp2, T5, O1, A2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.160131</td>\n",
       "      <td>0.638915</td>\n",
       "      <td>0.867556</td>\n",
       "      <td>0.228641</td>\n",
       "      <td>1.025751</td>\n",
       "      <td>0.077761</td>\n",
       "      <td>[P3, C3, C4, P4, Cz, Pz, Fp1, Fp2, T3, O1, O2,...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.636553</td>\n",
       "      <td>0.60518</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.151685</td>\n",
       "      <td>[P3, C3, F4, C4, P4, Fp2, F7, A2, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.192810</td>\n",
       "      <td>55.781464</td>\n",
       "      <td>51.300117</td>\n",
       "      <td>4.481346</td>\n",
       "      <td>57.484512</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>[Fz, F4, T5, F7, F8, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.755424</td>\n",
       "      <td>1.030562</td>\n",
       "      <td>0.275138</td>\n",
       "      <td>1.222213</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>[P3, C3, F3, Fz, P4, Cz, T3, T5, O1, F7, F8, A...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.614674</td>\n",
       "      <td>0.683233</td>\n",
       "      <td>0.068558</td>\n",
       "      <td>0.750804</td>\n",
       "      <td>0.111461</td>\n",
       "      <td>[F3, P4, Cz, Pz, T3, T5, A2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.330065</td>\n",
       "      <td>1.290258</td>\n",
       "      <td>1.403062</td>\n",
       "      <td>0.112804</td>\n",
       "      <td>1.581581</td>\n",
       "      <td>0.151635</td>\n",
       "      <td>[Fz, F4, P4, Cz, Fp2, O1, O2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.160131</td>\n",
       "      <td>13.190247</td>\n",
       "      <td>12.870646</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>15.704945</td>\n",
       "      <td>0.077511</td>\n",
       "      <td>[P3, C4, Pz, O1, O2, F7, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.135621</td>\n",
       "      <td>0.593381</td>\n",
       "      <td>0.727684</td>\n",
       "      <td>0.134303</td>\n",
       "      <td>1.073522</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[F3, Fz, T3, O1, F7, A2, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.851231</td>\n",
       "      <td>0.709207</td>\n",
       "      <td>0.142025</td>\n",
       "      <td>4.306934</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[C3, F3, Fp1, O2, F7, F8, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.906884</td>\n",
       "      <td>1.087204</td>\n",
       "      <td>0.18032</td>\n",
       "      <td>1.251641</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>[C3, F3, Fz, F4, C4, O2, F7, F8, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>160</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>73.944504</td>\n",
       "      <td>71.202934</td>\n",
       "      <td>2.74157</td>\n",
       "      <td>108.264206</td>\n",
       "      <td>0.111561</td>\n",
       "      <td>[C3, F3, Fz, F4, Cz, T5, A2, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>46.113434</td>\n",
       "      <td>45.148029</td>\n",
       "      <td>0.965405</td>\n",
       "      <td>48.664871</td>\n",
       "      <td>0.151685</td>\n",
       "      <td>[F3, Pz, Fp1, Fp2, T3, O1, O2, F7, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.168301</td>\n",
       "      <td>0.524894</td>\n",
       "      <td>0.662485</td>\n",
       "      <td>0.137591</td>\n",
       "      <td>0.796263</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>[P3, C3, F3, C4, P4, Cz, Fp2, T5, O1, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.374183</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.988514</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>1.262938</td>\n",
       "      <td>0.151635</td>\n",
       "      <td>[C4, Cz, Fp2, T5, F7, A2, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.505456</td>\n",
       "      <td>1.5205</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>2.079391</td>\n",
       "      <td>1.028328</td>\n",
       "      <td>[P3, C3, F3, F4, P4, Cz, Fp2, T3, F7, F8, T4]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>32.817829</td>\n",
       "      <td>32.02821</td>\n",
       "      <td>0.789619</td>\n",
       "      <td>36.572292</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>[C3, F3, F4, C4, Pz, Fp1, T3, T5, O2, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>192</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.553756</td>\n",
       "      <td>0.69879</td>\n",
       "      <td>0.145035</td>\n",
       "      <td>0.629561</td>\n",
       "      <td>0.111761</td>\n",
       "      <td>[P3, F3, Fz, F4, P4, Pz, Fp1, Fp2, O1, F7, A2,...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.522768</td>\n",
       "      <td>1.17613</td>\n",
       "      <td>0.653362</td>\n",
       "      <td>2.52356</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, Cz, T3, T5, O1, F8, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.233660</td>\n",
       "      <td>0.831503</td>\n",
       "      <td>0.940101</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.985933</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>[P3, F3, Fz, Cz, Pz, Fp1, F7, A2, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>15.949655</td>\n",
       "      <td>15.449356</td>\n",
       "      <td>0.500299</td>\n",
       "      <td>21.038826</td>\n",
       "      <td>0.077961</td>\n",
       "      <td>[P3, C3, F3, Fz, C4, P4, Cz, Fp1, T3, T5, O1, ...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.118139</td>\n",
       "      <td>0.673557</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.021242</td>\n",
       "      <td>0.638411</td>\n",
       "      <td>0.681752</td>\n",
       "      <td>0.043341</td>\n",
       "      <td>0.696188</td>\n",
       "      <td>0.151535</td>\n",
       "      <td>[P3, C3, F3, O2, A2, T4]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.289216</td>\n",
       "      <td>5.269419</td>\n",
       "      <td>5.777128</td>\n",
       "      <td>0.507709</td>\n",
       "      <td>6.127879</td>\n",
       "      <td>0.111561</td>\n",
       "      <td>[F4, P4, Cz, Fp2, T3, O1, F7, A2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.186274</td>\n",
       "      <td>0.879401</td>\n",
       "      <td>0.99146</td>\n",
       "      <td>0.112059</td>\n",
       "      <td>1.045302</td>\n",
       "      <td>0.111711</td>\n",
       "      <td>[C3, Fz, C4, P4, Pz, Fp1, T3, T5, O2, F7, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>16.501001</td>\n",
       "      <td>16.50983</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>16.57094</td>\n",
       "      <td>0.111511</td>\n",
       "      <td>[P3, Fz, Fp1, T3, O2, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.305321</td>\n",
       "      <td>0.739283</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, Pz, Fp2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>[C3, F3, C4, Cz, Fp2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.333305</td>\n",
       "      <td>1.344085</td>\n",
       "      <td>0.01078</td>\n",
       "      <td>1.526931</td>\n",
       "      <td>1.000350</td>\n",
       "      <td>[P3, F3, Fz, F4, Fp2, T3, O1]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>96</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>29.650284</td>\n",
       "      <td>28.06493</td>\n",
       "      <td>1.585354</td>\n",
       "      <td>40.578953</td>\n",
       "      <td>0.049733</td>\n",
       "      <td>[C3, Fz, Pz, Fp2, T3, A2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.599365</td>\n",
       "      <td>0.71679</td>\n",
       "      <td>0.117425</td>\n",
       "      <td>0.704128</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>[F4, P4, Cz, Pz, Fp1, T3, T5, O1, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.746527</td>\n",
       "      <td>0.32044</td>\n",
       "      <td>0.510645</td>\n",
       "      <td>0.111411</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.207516</td>\n",
       "      <td>0.37229</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.44241</td>\n",
       "      <td>0.880478</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>[C3, F3, P4, Cz, Pz, T3, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.080062</td>\n",
       "      <td>0.289237</td>\n",
       "      <td>0.209175</td>\n",
       "      <td>0.342057</td>\n",
       "      <td>0.418946</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, P4, Pz, Fp1, T5, O2, A2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.254666</td>\n",
       "      <td>0.701216</td>\n",
       "      <td>0.44655</td>\n",
       "      <td>0.707933</td>\n",
       "      <td>1.481357</td>\n",
       "      <td>[C3, C4, Pz, T5, F7, A2, T6]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.277274</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.853020</td>\n",
       "      <td>[P3, C3, Fz, F4, C4, P4, F7, F8]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>[P3, F3, C4, P4, Pz, O2, F7, F8, A2, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.839668</td>\n",
       "      <td>[P3, C3, F3, Fz, C4, Cz, T3, T5, A2, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>[Fz, C4, Fp2, T5, O2, F7, F8, A2, T6, T4]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.024735</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, P4, Fp1, Fp2, T3, T5,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.492594</td>\n",
       "      <td>0.83605</td>\n",
       "      <td>0.343456</td>\n",
       "      <td>0.780494</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>[P3, C3, Fz, P4, Cz, Fp1, T5, F7, T4]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>0.580237</td>\n",
       "      <td>0.42945</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.791186</td>\n",
       "      <td>[P3, C3, F4, C4, Pz, Fp1, O1, F8, A2, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.259804</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.901306</td>\n",
       "      <td>[P3, C3, F4, C4, P4, Pz, Fp2, T3, O2]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.189622</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.414381</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, T5, O2, F7, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.878924</td>\n",
       "      <td>[P3, C3, Fz, C4, Fp1, Fp2, T3, O1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>[C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff train_loss   val_loss  \\\n",
       "19   0.838235  0.818182  0.722222            0.116013   1.209507   1.407622   \n",
       "7    0.573529  0.545455  0.555556            0.017974   0.812133   0.654432   \n",
       "18   0.867647  0.545455  0.666667            0.200980   84.76915  82.498848   \n",
       "15   0.970588  0.545455  0.777778            0.192810   14.35515  14.367508   \n",
       "8    0.882353  0.636364  0.722222            0.160131   0.638915   0.867556   \n",
       "14   0.661765  0.590909  0.611111            0.050654   0.636553    0.60518   \n",
       "0    0.970588  0.454545  0.777778            0.192810  55.781464  51.300117   \n",
       "3    0.970588  0.681818  0.722222            0.248366   0.755424   1.030562   \n",
       "1    0.720588  0.363636  0.666667            0.053922   0.614674   0.683233   \n",
       "13   0.941176  0.545455  0.611111            0.330065   1.290258   1.403062   \n",
       "0    0.882353  0.636364  0.722222            0.160131  13.190247  12.870646   \n",
       "8    0.691176  0.500000  0.555556            0.135621   0.593381   0.727684   \n",
       "7    0.558824  0.500000  0.555556            0.003268   0.851231   0.709207   \n",
       "8    0.970588  0.454545  0.833333            0.137255   0.906884   1.087204   \n",
       "1    1.000000  0.500000  0.666667            0.333333  73.944504  71.202934   \n",
       "0    1.000000  0.500000  0.611111            0.388889  46.113434  45.148029   \n",
       "16   0.779412  0.545455  0.611111            0.168301   0.524894   0.662485   \n",
       "2    0.985294  0.545455  0.611111            0.374183   0.817715   0.988514   \n",
       "6    0.735294  0.500000  0.833333            0.098039   1.505456     1.5205   \n",
       "2    1.000000  0.545455  0.722222            0.277778  32.817829   32.02821   \n",
       "1    0.735294  0.727273  0.666667            0.068627   0.553756    0.69879   \n",
       "5    1.000000  0.727273  0.888889            0.111111   0.522768    1.17613   \n",
       "10   0.955882  0.636364  0.722222            0.233660   0.831503   0.940101   \n",
       "1    1.000000  0.545455  0.722222            0.277778  15.949655  15.449356   \n",
       "2    0.705882  0.681818  0.666667            0.039216   0.572419   0.690558   \n",
       "24   0.632353  0.500000  0.611111            0.021242   0.638411   0.681752   \n",
       "10   0.955882  0.545455  0.666667            0.289216   5.269419   5.777128   \n",
       "4    0.852941  0.727273  0.666667            0.186274   0.879401    0.99146   \n",
       "12   1.000000  0.545455  0.666667            0.333333  16.501001   16.50983   \n",
       "15   0.955882  0.818182  0.833333            0.122549   0.432221   0.737542   \n",
       "23   0.852941  0.727273  0.888889            0.035948   0.388678   0.429204   \n",
       "3    0.676471  0.454545  0.500000            0.176471   1.333305   1.344085   \n",
       "2    1.000000  0.454545  0.777778            0.222222  29.650284   28.06493   \n",
       "18   0.691176  0.500000  0.666667            0.024510   0.599365    0.71679   \n",
       "19   0.823529  0.818182  0.666667            0.156863   0.426087   0.746527   \n",
       "13   0.985294  0.727273  0.777778            0.207516    0.37229     0.8147   \n",
       "0    1.000000  0.909091  0.944444            0.055556   0.080062   0.289237   \n",
       "0    1.000000  0.772727  0.833333            0.166667   0.254666   0.701216   \n",
       "0    0.941176  0.727273  0.666667            0.274510   0.501189   0.778463   \n",
       "0    0.941176  0.636364  0.888889            0.052288       None       None   \n",
       "0    1.000000  0.727273  0.777778            0.222222       None       None   \n",
       "0    0.985294  0.863636  0.833333            0.151961       None       None   \n",
       "0    0.750000  0.681818  0.777778            0.027778       None       None   \n",
       "0    0.970588  0.590909  0.722222            0.248366   0.492594    0.83605   \n",
       "0    1.000000  0.636364  0.833333            0.166667   0.150787   0.580237   \n",
       "0    0.926471  0.636364  0.666667            0.259804       None       None   \n",
       "0    1.000000  0.772727  0.888889            0.111111   0.189622   0.604003   \n",
       "0    1.000000  0.636364  0.722222            0.277778       None       None   \n",
       "0    1.000000  0.863636  0.888889            0.111111       None       None   \n",
       "\n",
       "   train_val_loss_diff   test_loss    scores  \\\n",
       "19            0.198116    1.633958  0.077361   \n",
       "7             0.157701    0.673368  0.198031   \n",
       "18            2.270302   90.271187  0.111561   \n",
       "15            0.012358   18.714355  0.049883   \n",
       "8             0.228641    1.025751  0.077761   \n",
       "14            0.031373    0.682946  0.151685   \n",
       "0             4.481346   57.484512  0.049683   \n",
       "3             0.275138    1.222213  0.077861   \n",
       "1             0.068558    0.750804  0.111461   \n",
       "13            0.112804    1.581581  0.151635   \n",
       "0               0.3196   15.704945  0.077511   \n",
       "8             0.134303    1.073522  0.197881   \n",
       "7             0.142025    4.306934  0.197881   \n",
       "8              0.18032    1.251641  0.028278   \n",
       "1              2.74157  108.264206  0.111561   \n",
       "0             0.965405   48.664871  0.151685   \n",
       "16            0.137591    0.796263  0.151735   \n",
       "2               0.1708    1.262938  0.151635   \n",
       "6             0.015043    2.079391  1.028328   \n",
       "2             0.789619   36.572292  0.077661   \n",
       "1             0.145035    0.629561  0.111761   \n",
       "5             0.653362     2.52356  0.012896   \n",
       "10            0.108597    0.985933  0.077661   \n",
       "1             0.500299   21.038826  0.077961   \n",
       "2             0.118139    0.673557  0.111661   \n",
       "24            0.043341    0.696188  0.151535   \n",
       "10            0.507709    6.127879  0.111561   \n",
       "4             0.112059    1.045302  0.111711   \n",
       "12            0.008829    16.57094  0.111511   \n",
       "15            0.305321    0.739283  0.028128   \n",
       "23            0.040526    0.646307  0.262646   \n",
       "3              0.01078    1.526931  1.000350   \n",
       "2             1.585354   40.578953  0.049733   \n",
       "18            0.117425    0.704128  0.111611   \n",
       "19             0.32044    0.510645  0.111411   \n",
       "13             0.44241    0.880478  0.049783   \n",
       "0             0.209175    0.342057  0.418946   \n",
       "0              0.44655    0.707933  1.481357   \n",
       "0             0.277274    0.757358  0.853020   \n",
       "0                 None        None  0.111611   \n",
       "0                 None        None  0.839668   \n",
       "0                 None        None  0.167167   \n",
       "0                 None        None  1.024735   \n",
       "0             0.343456    0.780494  0.956129   \n",
       "0              0.42945    0.998291  0.791186   \n",
       "0                 None        None  0.901306   \n",
       "0             0.414381    0.733969  0.665729   \n",
       "0                 None        None  0.878924   \n",
       "0                 None        None  0.520520   \n",
       "\n",
       "                                    channels_selected  sfreq batch_size  \\\n",
       "19                                   [C3, Fz, T6, T4]  256.0        192   \n",
       "7           [P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]  128.0        256   \n",
       "18              [F3, Fz, F4, Fp2, T3, T5, F7, A2, T4]  256.0        224   \n",
       "15         [F3, F4, Cz, Pz, Fp1, Fp2, T5, O1, A2, T6]  256.0        128   \n",
       "8   [P3, C3, C4, P4, Cz, Pz, Fp1, Fp2, T3, O1, O2,...  300.0         32   \n",
       "14              [P3, C3, F4, C4, P4, Fp2, F7, A2, T4]  300.0         96   \n",
       "0                            [Fz, F4, T5, F7, F8, T4]  256.0         32   \n",
       "3   [P3, C3, F3, Fz, P4, Cz, T3, T5, O1, F7, F8, A...  256.0        256   \n",
       "1                        [F3, P4, Cz, Pz, T3, T5, A2]  128.0        160   \n",
       "13                  [Fz, F4, P4, Cz, Fp2, O1, O2, T4]  256.0        192   \n",
       "0                        [P3, C4, Pz, O1, O2, F7, T6]  128.0        224   \n",
       "8                        [F3, Fz, T3, O1, F7, A2, T6]  300.0        224   \n",
       "7                       [C3, F3, Fp1, O2, F7, F8, T6]  300.0         96   \n",
       "8            [C3, F3, Fz, F4, C4, O2, F7, F8, T6, T4]  300.0        160   \n",
       "1                [C3, F3, Fz, F4, Cz, T5, A2, T6, T4]  300.0        224   \n",
       "0              [F3, Pz, Fp1, Fp2, T3, O1, O2, F7, A2]  300.0        128   \n",
       "16          [P3, C3, F3, C4, P4, Cz, Fp2, T5, O1, T6]  300.0         32   \n",
       "2                   [C4, Cz, Fp2, T5, F7, A2, T6, T4]  300.0        224   \n",
       "6       [P3, C3, F3, F4, P4, Cz, Fp2, T3, F7, F8, T4]  128.0        128   \n",
       "2           [C3, F3, F4, C4, Pz, Fp1, T3, T5, O2, A2]  300.0        192   \n",
       "1   [P3, F3, Fz, F4, P4, Pz, Fp1, Fp2, O1, F7, A2,...  300.0        224   \n",
       "5        [P3, C3, F3, Fz, F4, Cz, T3, T5, O1, F8, A2]  256.0         32   \n",
       "10          [P3, F3, Fz, Cz, Pz, Fp1, F7, A2, T6, T4]  256.0         32   \n",
       "1   [P3, C3, F3, Fz, C4, P4, Cz, Fp1, T3, T5, O1, ...  300.0        224   \n",
       "2       [P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]  300.0         64   \n",
       "24                           [P3, C3, F3, O2, A2, T4]  128.0         32   \n",
       "10              [F4, P4, Cz, Fp2, T3, O1, F7, A2, T6]  256.0        256   \n",
       "4   [C3, Fz, C4, P4, Pz, Fp1, T3, T5, O2, F7, A2, T4]  256.0         64   \n",
       "12                  [P3, Fz, Fp1, T3, O2, F7, F8, A2]  300.0        224   \n",
       "15                      [P3, C3, F3, C4, Cz, Pz, Fp2]  128.0         32   \n",
       "23                          [C3, F3, C4, Cz, Fp2, T6]  128.0        128   \n",
       "3                       [P3, F3, Fz, F4, Fp2, T3, O1]  256.0         96   \n",
       "2                       [C3, Fz, Pz, Fp2, T3, A2, T6]  128.0         32   \n",
       "18          [F4, P4, Cz, Pz, Fp1, T3, T5, O1, T6, T4]  256.0        192   \n",
       "19                           [F3, P4, Pz, F7, F8, A2]  300.0         32   \n",
       "13                   [C3, F3, P4, Cz, Pz, T3, T6, T4]  256.0        192   \n",
       "0   [P3, C3, F3, Fz, F4, C4, P4, Pz, Fp1, T5, O2, A2]    NaN       None   \n",
       "0                        [C3, C4, Pz, T5, F7, A2, T6]    NaN       None   \n",
       "0                    [P3, C3, Fz, F4, C4, P4, F7, F8]    NaN       None   \n",
       "0            [P3, F3, C4, P4, Pz, O2, F7, F8, A2, T6]   None       None   \n",
       "0            [P3, C3, F3, Fz, C4, Cz, T3, T5, A2, T6]   None       None   \n",
       "0           [Fz, C4, Fp2, T5, O2, F7, F8, A2, T6, T4]   None       None   \n",
       "0   [P3, C3, F3, Fz, F4, C4, P4, Fp1, Fp2, T3, T5,...   None       None   \n",
       "0               [P3, C3, Fz, P4, Cz, Fp1, T5, F7, T4]   None       None   \n",
       "0           [P3, C3, F4, C4, Pz, Fp1, O1, F8, A2, T6]   None       None   \n",
       "0               [P3, C3, F4, C4, P4, Pz, Fp2, T3, O2]   None       None   \n",
       "0                [P3, C3, F3, C4, Cz, T5, O2, F7, T6]   None       None   \n",
       "0                  [P3, C3, Fz, C4, Fp1, Fp2, T3, O1]   None       None   \n",
       "0   [C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...   None       None   \n",
       "\n",
       "          model_name subjects  \n",
       "19           eeg_net      [9]  \n",
       "7      deep_conv_net      [9]  \n",
       "18      lstm_cnn_net      [9]  \n",
       "15      lstm_cnn_net     [10]  \n",
       "8            eeg_net     [10]  \n",
       "14     deep_conv_net     [10]  \n",
       "0       lstm_cnn_net     [11]  \n",
       "3            eeg_net     [11]  \n",
       "1      deep_conv_net     [11]  \n",
       "13           eeg_net      [2]  \n",
       "0       lstm_cnn_net      [2]  \n",
       "8      deep_conv_net      [2]  \n",
       "7      deep_conv_net      [7]  \n",
       "8            eeg_net      [7]  \n",
       "1       lstm_cnn_net      [7]  \n",
       "0       lstm_cnn_net      [1]  \n",
       "16     deep_conv_net      [1]  \n",
       "2            eeg_net      [1]  \n",
       "6            eeg_net      [3]  \n",
       "2       lstm_cnn_net      [3]  \n",
       "1      deep_conv_net      [3]  \n",
       "5   shallow_conv_net      [6]  \n",
       "10           eeg_net      [6]  \n",
       "1       lstm_cnn_net      [6]  \n",
       "2      deep_conv_net      [6]  \n",
       "24     deep_conv_net      [5]  \n",
       "10      lstm_cnn_net      [5]  \n",
       "4            eeg_net      [5]  \n",
       "12      lstm_cnn_net     [12]  \n",
       "15           eeg_net     [12]  \n",
       "23     deep_conv_net     [12]  \n",
       "3            eeg_net      [8]  \n",
       "2       lstm_cnn_net      [8]  \n",
       "18     deep_conv_net      [8]  \n",
       "19     deep_conv_net      [4]  \n",
       "13           eeg_net      [4]  \n",
       "0   shallow_conv_net      [9]  \n",
       "0   shallow_conv_net     [10]  \n",
       "0   shallow_conv_net     [11]  \n",
       "0   shallow_conv_net      [2]  \n",
       "0   shallow_conv_net      [7]  \n",
       "0   shallow_conv_net      [1]  \n",
       "0   shallow_conv_net      [3]  \n",
       "0   shallow_conv_net     [14]  \n",
       "0   shallow_conv_net     [13]  \n",
       "0   shallow_conv_net      [5]  \n",
       "0   shallow_conv_net     [12]  \n",
       "0   shallow_conv_net      [8]  \n",
       "0   shallow_conv_net      [4]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_study_trials_concat_df = pd.DataFrame()\n",
    "\n",
    "for subject_model in temp_fatigue_mi_studies_dict:\n",
    "    study = temp_fatigue_mi_studies_dict[subject_model]\n",
    "    study_trials_df = model_optimizer.get_study_metrics(study, **{ \"default_model_name\": \"shallow_conv_net\", \"subjects\": [subject_model.split(\"_\")[0]] })\n",
    "    # Filter: Top 10 best scores -> Max training accuracy -> Minimum difference between training and validation accuracy -> Max test accuracy = best model\n",
    "    filtered_study_trials_df = study_trials_df.copy()\n",
    "    filtered_study_trials_df = filtered_study_trials_df.nsmallest(1, 'scores')\n",
    "    # filtered_study_trials_df = filtered_study_trials_df.nsmallest(5, 'train_val_acc_diff')\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['train_acc'] == max(filtered_study_trials_df['train_acc'])]\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['train_val_acc_diff'] == min(filtered_study_trials_df['train_val_acc_diff'])]\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['test_acc'] == max(filtered_study_trials_df['test_acc'])]\n",
    "    filtered_study_trials_concat_df = pd.concat([filtered_study_trials_concat_df, filtered_study_trials_df])\n",
    "display(filtered_study_trials_concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.746527</td>\n",
       "      <td>0.32044</td>\n",
       "      <td>0.510645</td>\n",
       "      <td>0.111411</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.553756</td>\n",
       "      <td>0.69879</td>\n",
       "      <td>0.145035</td>\n",
       "      <td>0.629561</td>\n",
       "      <td>0.111761</td>\n",
       "      <td>[P3, F3, Fz, F4, P4, Pz, Fp1, Fp2, O1, F7, A2,...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>[C3, F3, C4, Cz, Fp2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.118139</td>\n",
       "      <td>0.673557</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.636553</td>\n",
       "      <td>0.60518</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.151685</td>\n",
       "      <td>[P3, C3, F4, C4, P4, Fp2, F7, A2, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.157701</td>\n",
       "      <td>0.673368</td>\n",
       "      <td>0.198031</td>\n",
       "      <td>[P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.168301</td>\n",
       "      <td>0.524894</td>\n",
       "      <td>0.662485</td>\n",
       "      <td>0.137591</td>\n",
       "      <td>0.796263</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>[P3, C3, F3, C4, P4, Cz, Fp2, T5, O1, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.135621</td>\n",
       "      <td>0.593381</td>\n",
       "      <td>0.727684</td>\n",
       "      <td>0.134303</td>\n",
       "      <td>1.073522</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[F3, Fz, T3, O1, F7, A2, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.851231</td>\n",
       "      <td>0.709207</td>\n",
       "      <td>0.142025</td>\n",
       "      <td>4.306934</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>[C3, F3, Fp1, O2, F7, F8, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.021242</td>\n",
       "      <td>0.638411</td>\n",
       "      <td>0.681752</td>\n",
       "      <td>0.043341</td>\n",
       "      <td>0.696188</td>\n",
       "      <td>0.151535</td>\n",
       "      <td>[P3, C3, F3, O2, A2, T4]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.599365</td>\n",
       "      <td>0.71679</td>\n",
       "      <td>0.117425</td>\n",
       "      <td>0.704128</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>[F4, P4, Cz, Pz, Fp1, T3, T5, O1, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.614674</td>\n",
       "      <td>0.683233</td>\n",
       "      <td>0.068558</td>\n",
       "      <td>0.750804</td>\n",
       "      <td>0.111461</td>\n",
       "      <td>[F3, P4, Cz, Pz, T3, T5, A2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff train_loss  val_loss  \\\n",
       "19   0.823529  0.818182  0.666667            0.156863   0.426087  0.746527   \n",
       "1    0.735294  0.727273  0.666667            0.068627   0.553756   0.69879   \n",
       "23   0.852941  0.727273  0.888889            0.035948   0.388678  0.429204   \n",
       "2    0.705882  0.681818  0.666667            0.039216   0.572419  0.690558   \n",
       "14   0.661765  0.590909  0.611111            0.050654   0.636553   0.60518   \n",
       "7    0.573529  0.545455  0.555556            0.017974   0.812133  0.654432   \n",
       "16   0.779412  0.545455  0.611111            0.168301   0.524894  0.662485   \n",
       "8    0.691176  0.500000  0.555556            0.135621   0.593381  0.727684   \n",
       "7    0.558824  0.500000  0.555556            0.003268   0.851231  0.709207   \n",
       "24   0.632353  0.500000  0.611111            0.021242   0.638411  0.681752   \n",
       "18   0.691176  0.500000  0.666667            0.024510   0.599365   0.71679   \n",
       "1    0.720588  0.363636  0.666667            0.053922   0.614674  0.683233   \n",
       "\n",
       "   train_val_loss_diff test_loss    scores  \\\n",
       "19             0.32044  0.510645  0.111411   \n",
       "1             0.145035  0.629561  0.111761   \n",
       "23            0.040526  0.646307  0.262646   \n",
       "2             0.118139  0.673557  0.111661   \n",
       "14            0.031373  0.682946  0.151685   \n",
       "7             0.157701  0.673368  0.198031   \n",
       "16            0.137591  0.796263  0.151735   \n",
       "8             0.134303  1.073522  0.197881   \n",
       "7             0.142025  4.306934  0.197881   \n",
       "24            0.043341  0.696188  0.151535   \n",
       "18            0.117425  0.704128  0.111611   \n",
       "1             0.068558  0.750804  0.111461   \n",
       "\n",
       "                                    channels_selected  sfreq batch_size  \\\n",
       "19                           [F3, P4, Pz, F7, F8, A2]  300.0         32   \n",
       "1   [P3, F3, Fz, F4, P4, Pz, Fp1, Fp2, O1, F7, A2,...  300.0        224   \n",
       "23                          [C3, F3, C4, Cz, Fp2, T6]  128.0        128   \n",
       "2       [P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]  300.0         64   \n",
       "14              [P3, C3, F4, C4, P4, Fp2, F7, A2, T4]  300.0         96   \n",
       "7           [P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]  128.0        256   \n",
       "16          [P3, C3, F3, C4, P4, Cz, Fp2, T5, O1, T6]  300.0         32   \n",
       "8                        [F3, Fz, T3, O1, F7, A2, T6]  300.0        224   \n",
       "7                       [C3, F3, Fp1, O2, F7, F8, T6]  300.0         96   \n",
       "24                           [P3, C3, F3, O2, A2, T4]  128.0         32   \n",
       "18          [F4, P4, Cz, Pz, Fp1, T3, T5, O1, T6, T4]  256.0        192   \n",
       "1                        [F3, P4, Cz, Pz, T3, T5, A2]  128.0        160   \n",
       "\n",
       "       model_name subjects  \n",
       "19  deep_conv_net      [4]  \n",
       "1   deep_conv_net      [3]  \n",
       "23  deep_conv_net     [12]  \n",
       "2   deep_conv_net      [6]  \n",
       "14  deep_conv_net     [10]  \n",
       "7   deep_conv_net      [9]  \n",
       "16  deep_conv_net      [1]  \n",
       "8   deep_conv_net      [2]  \n",
       "7   deep_conv_net      [7]  \n",
       "24  deep_conv_net      [5]  \n",
       "18  deep_conv_net      [8]  \n",
       "1   deep_conv_net     [11]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_study_trials_concat_df.query(\"model_name == 'deep_conv_net'\").sort_values(by=\"test_acc\", ascending=False) #[['test_acc', 'subjects']] #.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEGNet:           4, 9, 6, 10, 12    5, 11\n",
    "# DeepConvNet:      4, 9, 6, 10, 12    3,\n",
    "# ShallowConvNet:   4, 9, 6, 10, 12    1, 11\n",
    "\n",
    "\"\"\"\n",
    "- Re-run:\n",
    "-- DeepConvNet on subject 11\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
