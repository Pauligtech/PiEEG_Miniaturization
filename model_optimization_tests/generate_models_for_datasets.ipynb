{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 21:53:09.723617: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-12 21:53:09.723662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-12 21:53:09.724862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-12 21:53:09.732517: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 21:53:10.592405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "from model_optim.model_optimizer import ModelOptimizer\n",
    "\n",
    "# Dataset\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "from custom_datasets.norm_cho import NormCho2017\n",
    "from custom_datasets.opt_game_mi import OptGameMI\n",
    "from custom_datasets.opt_std_mi import OptStdMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [\n",
    "    # \"shallow_conv_net\",\n",
    "    \"lstm_net\",\n",
    "    \"deep_conv_net\",\n",
    "    \"eeg_net\",\n",
    "    \"lstm_cnn_net\",\n",
    "    \"lstm_cnn_net_v2\"\n",
    "]\n",
    "MODELS_HYPERPARAMS_DICT = {\n",
    "    \"shallow_conv_net\": {\n",
    "        \"max_epochs\": 5\n",
    "    },\n",
    "    \"eeg_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"deep_conv_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net_v2\": {},\n",
    "}\n",
    "\n",
    "DATASETS_LIST = [\n",
    "    FatigueMI,\n",
    "    # NormCho2017,\n",
    "    # OptGameMI,\n",
    "    # OptStdMI,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_optim.utils import data_generator\n",
    "\n",
    "# data_generator(\n",
    "#     dataset=NormCho2017(),\n",
    "#     subjects=[1],\n",
    "#     channel_idx=[],\n",
    "#     sfreq=128,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files = glob.glob(\"./temp_v2/*/*/model/study_best_trial.npy\")\n",
    "subject_files_data = {}\n",
    "for subject_file in subject_files:\n",
    "    subject_files_data[subject_file] = np.load(subject_file, allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/63a8c87ffc02471893db5ac9a0781946/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9090909361839294</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/63a8c87ffc02471893db5ac9a0781946/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.9090909361839294\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/c2cc69dca74d4bfa81722cd634e6403e/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727273106575012</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/c2cc69dca74d4bfa81722cd634e6403e/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7727273106575012\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/e0643f9a780146a4adc15ddd4a9ff053/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/e0643f9a780146a4adc15ddd4a9ff053/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7272727489471436\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/aabe056cd1954a6f92ab47d84c86b1b8/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/aabe056cd1954a6f92ab47d84c86b1b8/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7272727489471436\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/292cbc92b8cf46da9986fe7d8447819f/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/292cbc92b8cf46da9986fe7d8447819f/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/9c1b753483db409a90eab7b7149b8af8/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/9c1b753483db409a90eab7b7149b8af8/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/39d01251ff494106bf04f8a2cffcdd74/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/39d01251ff494106bf04f8a2cffcdd74/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/a3304348c7094d02a024828ede942cda/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909091234207153</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/a3304348c7094d02a024828ede942cda/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.5909091234207153\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/1b189965ada44ff99e73fa145cd3901d/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/1b189965ada44ff99e73fa145cd3901d/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/d199c9c2ac924b238693f158eb88f675/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/d199c9c2ac924b238693f158eb88f675/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/96dc576945fb4f2db582d66ae1d2c8ce/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727273106575012</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/96dc576945fb4f2db582d66ae1d2c8ce/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7727273106575012\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/9fd82ec44ef3496da6307b57ecf4532f/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/9fd82ec44ef3496da6307b57ecf4532f/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/3623cb4ba1ad4a908c9098f5297a6778/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/3623cb4ba1ad4a908c9098f5297a6778/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for subject_file_data_key, subject_file_data in subject_files_data.items():\n",
    "    rprint(subject_file_data_key, subject_file_data.user_attrs['trial_data']['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1076fe9c28a2490d9aeba8fce5674d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 116.7297 - accuracy: 0.5735\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61111, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 116.7297 - accuracy: 0.5735 - val_loss: 105.7196 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 105.7729 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 105.7729 - accuracy: 0.5441 - val_loss: 98.4783 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 98.6259 - accuracy: 0.5882\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 98.6259 - accuracy: 0.5882 - val_loss: 92.7606 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 92.5205 - accuracy: 0.7500\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 92.5205 - accuracy: 0.7500 - val_loss: 87.8193 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 87.6408 - accuracy: 0.7206\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 87.6408 - accuracy: 0.7206 - val_loss: 83.5042 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 83.0813 - accuracy: 0.8971\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 83.0813 - accuracy: 0.8971 - val_loss: 79.5946 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 79.2469 - accuracy: 0.8382\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 79.2469 - accuracy: 0.8382 - val_loss: 76.0186 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 75.6847 - accuracy: 0.8382\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 75.6847 - accuracy: 0.8382 - val_loss: 72.7301 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 72.3812 - accuracy: 0.8382\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 72.3812 - accuracy: 0.8382 - val_loss: 69.6773 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 69.3361 - accuracy: 0.8676\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 69.3361 - accuracy: 0.8676 - val_loss: 66.8373 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 105.7335 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 81.3604 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 3s 549ms/step - loss: 81.3604 - accuracy: 0.4853 - val_loss: 73.8234 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 73.5159 - accuracy: 0.8594\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 73.3280 - accuracy: 0.8529 - val_loss: 68.6083 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 68.1697 - accuracy: 0.8438\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 68.0394 - accuracy: 0.8382 - val_loss: 64.4172 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 63.8299 - accuracy: 0.9531\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 63.7134 - accuracy: 0.9559 - val_loss: 60.6570 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 60.1473 - accuracy: 0.8438\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 60.0720 - accuracy: 0.8235 - val_loss: 57.5772 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 57.0076 - accuracy: 0.9062\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 56.9246 - accuracy: 0.8971 - val_loss: 54.6376 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 54.0726 - accuracy: 0.9375\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 53.9977 - accuracy: 0.9118 - val_loss: 51.9207 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 51.4714 - accuracy: 0.8438\n",
      "Epoch 00008: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 51.3963 - accuracy: 0.8382 - val_loss: 49.4124 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 48.8723 - accuracy: 0.9531\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 48.7961 - accuracy: 0.9559 - val_loss: 46.9306 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 46.4309 - accuracy: 0.9219\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 46.3485 - accuracy: 0.9265 - val_loss: 44.4971 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00008 with val_accuracy: 0.50000\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 49.4667 - accuracy: 0.3636\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.0030 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.0030 - accuracy: 0.5000 - val_loss: 13.1458 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.2683 - accuracy: 0.5588\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 13.2683 - accuracy: 0.5588 - val_loss: 12.6262 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.6578 - accuracy: 0.5294\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 12.6578 - accuracy: 0.5294 - val_loss: 12.1750 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.1935 - accuracy: 0.5294\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12.1935 - accuracy: 0.5294 - val_loss: 11.8396 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.8283 - accuracy: 0.5588\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11.8283 - accuracy: 0.5588 - val_loss: 11.5254 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.2175 - accuracy: 0.6471\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 11.2175 - accuracy: 0.6471 - val_loss: 11.2079 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.1605 - accuracy: 0.5882\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11.1605 - accuracy: 0.5882 - val_loss: 10.9017 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8559 - accuracy: 0.5147\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.8559 - accuracy: 0.5147 - val_loss: 10.6207 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.4628 - accuracy: 0.5147\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 10.4628 - accuracy: 0.5147 - val_loss: 10.3815 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.2669 - accuracy: 0.5441\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 10.2669 - accuracy: 0.5441 - val_loss: 10.1050 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.44444\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 13.0811 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 15.8570 - accuracy: 0.5735\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "3/3 [==============================] - 2s 252ms/step - loss: 15.8570 - accuracy: 0.5735 - val_loss: 13.6816 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0134 - accuracy: 0.5938\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 13.8048 - accuracy: 0.5147 - val_loss: 12.4224 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.4266 - accuracy: 0.6562\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 12.2911 - accuracy: 0.6471 - val_loss: 11.4637 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.3249 - accuracy: 0.4062\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 11.9473 - accuracy: 0.4412 - val_loss: 10.7169 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 11.0850 - accuracy: 0.4688\n",
      "Epoch 00005: val_accuracy improved from 0.50000 to 0.66667, storing weights.\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 10.9797 - accuracy: 0.5147 - val_loss: 10.0683 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 10.3833 - accuracy: 0.5312\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 10.1833 - accuracy: 0.5735 - val_loss: 9.4606 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.4023 - accuracy: 0.5938\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 9.4198 - accuracy: 0.5147 - val_loss: 8.9154 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.8093 - accuracy: 0.7812\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 8.8462 - accuracy: 0.6765 - val_loss: 8.4131 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.4988 - accuracy: 0.5625\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.4476 - accuracy: 0.5735 - val_loss: 7.9565 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.2905 - accuracy: 0.5625\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 8.1392 - accuracy: 0.6029 - val_loss: 7.5313 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00005 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10.0619 - accuracy: 0.7273\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.3280 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.3280 - accuracy: 0.4853 - val_loss: 19.4365 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.5198 - accuracy: 0.5735\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 19.5198 - accuracy: 0.5735 - val_loss: 18.3493 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.4499 - accuracy: 0.5882\n",
      "Epoch 00003: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 18.4499 - accuracy: 0.5882 - val_loss: 17.5120 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.4964 - accuracy: 0.6176\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 17.4964 - accuracy: 0.6176 - val_loss: 16.7752 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.7406 - accuracy: 0.6618\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.7406 - accuracy: 0.6618 - val_loss: 16.1244 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.9719 - accuracy: 0.6765\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 15.9719 - accuracy: 0.6765 - val_loss: 15.5350 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.5377 - accuracy: 0.5588\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.5377 - accuracy: 0.5588 - val_loss: 14.9966 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.9665 - accuracy: 0.6471\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14.9665 - accuracy: 0.6471 - val_loss: 14.4974 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.5016 - accuracy: 0.6471\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14.5016 - accuracy: 0.6471 - val_loss: 14.0298 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9054 - accuracy: 0.6765\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.9054 - accuracy: 0.6765 - val_loss: 13.5807 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00003 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 17.5467 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.0704 - accuracy: 0.5882\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61111, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.0704 - accuracy: 0.5882 - val_loss: 14.0173 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.7618 - accuracy: 0.8088\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 13.7618 - accuracy: 0.8088 - val_loss: 13.2547 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.9213 - accuracy: 0.8824\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 12.9213 - accuracy: 0.8824 - val_loss: 12.6432 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.1834 - accuracy: 0.9265\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 12.1834 - accuracy: 0.9265 - val_loss: 12.0723 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.4914 - accuracy: 0.9853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 11.4914 - accuracy: 0.9853 - val_loss: 11.5128 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9728 - accuracy: 0.9853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.9728 - accuracy: 0.9853 - val_loss: 11.0248 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.5100 - accuracy: 0.9412\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 10.5100 - accuracy: 0.9412 - val_loss: 10.5781 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0153 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.0153 - accuracy: 1.0000 - val_loss: 10.1795 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5918 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.5918 - accuracy: 1.0000 - val_loss: 9.7749 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.1765 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.1765 - accuracy: 1.0000 - val_loss: 9.4119 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Using epoch 00010 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.4790 - accuracy: 0.6364\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.4046 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.4046 - accuracy: 0.5147 - val_loss: 19.0073 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.0803 - accuracy: 0.6912\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 19.0803 - accuracy: 0.6912 - val_loss: 18.3200 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.1435 - accuracy: 0.6912\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 18.1435 - accuracy: 0.6912 - val_loss: 17.3679 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.7956 - accuracy: 0.9265\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.7956 - accuracy: 0.9265 - val_loss: 16.6340 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.9508 - accuracy: 0.9853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 15.9508 - accuracy: 0.9853 - val_loss: 15.9541 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.2371 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 15.2371 - accuracy: 1.0000 - val_loss: 15.3000 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.5774 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.5774 - accuracy: 1.0000 - val_loss: 14.6746 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9587 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 13.9587 - accuracy: 1.0000 - val_loss: 14.0876 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.3911 - accuracy: 0.9853\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 13.3911 - accuracy: 0.9853 - val_loss: 13.5968 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.8360 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 12.8360 - accuracy: 1.0000 - val_loss: 13.0505 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Using epoch 00007 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 14.6969 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 114.7098 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 114.7098 - accuracy: 0.5000 - val_loss: 103.1464 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 102.7109 - accuracy: 0.9265\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 102.7109 - accuracy: 0.9265 - val_loss: 94.6120 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 94.0165 - accuracy: 0.9853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 94.0165 - accuracy: 0.9853 - val_loss: 87.8544 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 87.2168 - accuracy: 0.9706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 87.2168 - accuracy: 0.9706 - val_loss: 82.2646 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 81.5679 - accuracy: 1.0000\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 81.5679 - accuracy: 1.0000 - val_loss: 77.3604 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 76.6843 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 76.6843 - accuracy: 1.0000 - val_loss: 73.0562 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 72.3701 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 72.3701 - accuracy: 1.0000 - val_loss: 69.1785 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 68.4850 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 68.4850 - accuracy: 1.0000 - val_loss: 65.6373 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 64.9560 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 64.9560 - accuracy: 1.0000 - val_loss: 62.3986 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 61.7131 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 61.7131 - accuracy: 1.0000 - val_loss: 59.3861 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 103.1638 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 43.7222 - accuracy: 0.5588\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 43.7222 - accuracy: 0.5588 - val_loss: 41.6013 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 41.5413 - accuracy: 0.6029\n",
      "Epoch 00002: val_accuracy improved from 0.38889 to 0.44444, storing weights.\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 41.5413 - accuracy: 0.6029 - val_loss: 40.0121 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 39.8909 - accuracy: 0.6912\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 39.8909 - accuracy: 0.6912 - val_loss: 38.6677 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 38.6230 - accuracy: 0.6324\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 38.6230 - accuracy: 0.6324 - val_loss: 37.5830 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 37.4257 - accuracy: 0.6618\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 37.4257 - accuracy: 0.6618 - val_loss: 36.5098 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 36.2405 - accuracy: 0.7500\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 36.2405 - accuracy: 0.7500 - val_loss: 35.5462 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 35.3434 - accuracy: 0.7206\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 35.3434 - accuracy: 0.7206 - val_loss: 34.6613 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 34.4186 - accuracy: 0.7500\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 34.4186 - accuracy: 0.7500 - val_loss: 33.8492 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 33.4876 - accuracy: 0.8824\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 33.4876 - accuracy: 0.8824 - val_loss: 33.0690 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 32.7053 - accuracy: 0.8235\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 32.7053 - accuracy: 0.8235 - val_loss: 32.3152 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00003 with val_accuracy: 0.50000\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 38.6490 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 144.7408 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 144.7408 - accuracy: 0.5441 - val_loss: 133.8307 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 133.9583 - accuracy: 0.5588\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 133.9583 - accuracy: 0.5588 - val_loss: 126.5015 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 126.7079 - accuracy: 0.5294\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 126.7079 - accuracy: 0.5294 - val_loss: 120.5566 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 120.6352 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 120.6352 - accuracy: 0.5735 - val_loss: 115.4727 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 115.5656 - accuracy: 0.5000\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 115.5656 - accuracy: 0.5000 - val_loss: 110.9490 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 111.0247 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 111.0247 - accuracy: 0.5294 - val_loss: 106.8523 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 106.8571 - accuracy: 0.6176\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 106.8571 - accuracy: 0.6176 - val_loss: 103.0656 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 103.0029 - accuracy: 0.6618\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 103.0029 - accuracy: 0.6618 - val_loss: 99.5365 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 99.5355 - accuracy: 0.6176\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 99.5355 - accuracy: 0.6176 - val_loss: 96.2555 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 96.1207 - accuracy: 0.7500\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 96.1207 - accuracy: 0.7500 - val_loss: 93.0920 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 133.8594 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.4680 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.4680 - accuracy: 0.5147 - val_loss: 22.5309 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.6143 - accuracy: 0.6765\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22.6143 - accuracy: 0.6765 - val_loss: 21.4916 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.3457 - accuracy: 0.7353\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 21.3457 - accuracy: 0.7353 - val_loss: 20.6108 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.5079 - accuracy: 0.7353\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.5079 - accuracy: 0.7353 - val_loss: 19.8667 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.7405 - accuracy: 0.6765\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.7405 - accuracy: 0.6765 - val_loss: 19.2059 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.9286 - accuracy: 0.7941\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.9286 - accuracy: 0.7941 - val_loss: 18.6113 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.2884 - accuracy: 0.7647\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.2884 - accuracy: 0.7647 - val_loss: 18.0719 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.5816 - accuracy: 0.8824\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 17.5816 - accuracy: 0.8824 - val_loss: 17.5560 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.2555 - accuracy: 0.7794\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.2555 - accuracy: 0.7794 - val_loss: 17.0536 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.7660 - accuracy: 0.7500\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.7660 - accuracy: 0.7500 - val_loss: 16.6253 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22.6139 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1619 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.1619 - accuracy: 0.4853 - val_loss: 7.6742 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2706 - accuracy: 0.8382\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.2706 - accuracy: 0.8382 - val_loss: 7.2724 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9242 - accuracy: 0.8235\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.9242 - accuracy: 0.8235 - val_loss: 7.2402 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.7091 - accuracy: 0.9118\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.7091 - accuracy: 0.9118 - val_loss: 6.9458 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3287 - accuracy: 0.9265\n",
      "Epoch 00005: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.3287 - accuracy: 0.9265 - val_loss: 6.8101 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.1329 - accuracy: 0.9412\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 6.1329 - accuracy: 0.9412 - val_loss: 6.6324 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8828 - accuracy: 0.9853\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.8828 - accuracy: 0.9853 - val_loss: 6.4978 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8425 - accuracy: 0.9412\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.8425 - accuracy: 0.9412 - val_loss: 6.1210 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7512 - accuracy: 0.8824\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.7512 - accuracy: 0.8824 - val_loss: 6.2437 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6905 - accuracy: 0.8529\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6905 - accuracy: 0.8529 - val_loss: 6.2016 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00005 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 6.8689 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 26.1029 - accuracy: 0.6029\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.1029 - accuracy: 0.6029 - val_loss: 24.5126 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.1598 - accuracy: 0.7353\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 24.1598 - accuracy: 0.7353 - val_loss: 23.4471 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.7092 - accuracy: 0.8824\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 22.7092 - accuracy: 0.8824 - val_loss: 22.1913 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.5574 - accuracy: 0.9265\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 21.5574 - accuracy: 0.9265 - val_loss: 21.1390 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.4797 - accuracy: 0.9559\n",
      "Epoch 00005: val_accuracy improved from 0.50000 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 20.4797 - accuracy: 0.9559 - val_loss: 20.1776 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.5600 - accuracy: 0.9706\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.5600 - accuracy: 0.9706 - val_loss: 19.3786 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.7169 - accuracy: 0.9853\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 18.7169 - accuracy: 0.9853 - val_loss: 18.6181 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.9394 - accuracy: 0.9853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 17.9394 - accuracy: 0.9853 - val_loss: 17.9218 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.1757 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 17.1757 - accuracy: 1.0000 - val_loss: 17.1749 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.5010 - accuracy: 0.9853\n",
      "Epoch 00010: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.5010 - accuracy: 0.9853 - val_loss: 16.5098 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Using epoch 00010 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.5709 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.7686 - accuracy: 0.4706\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.7686 - accuracy: 0.4706 - val_loss: 18.2633 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.4239 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.4239 - accuracy: 0.5441 - val_loss: 17.4645 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.5670 - accuracy: 0.6176\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 17.5670 - accuracy: 0.6176 - val_loss: 16.8248 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.7452 - accuracy: 0.6765\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.7452 - accuracy: 0.6765 - val_loss: 16.2520 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.1559 - accuracy: 0.7941\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.1559 - accuracy: 0.7941 - val_loss: 15.7701 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.4267 - accuracy: 0.8529\n",
      "Epoch 00006: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.4267 - accuracy: 0.8529 - val_loss: 15.2829 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.0698 - accuracy: 0.7353\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.0698 - accuracy: 0.7353 - val_loss: 14.8432 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.4283 - accuracy: 0.9412\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14.4283 - accuracy: 0.9412 - val_loss: 14.4331 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.0902 - accuracy: 0.8676\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.0902 - accuracy: 0.8676 - val_loss: 14.0586 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.6139 - accuracy: 0.9265\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.6139 - accuracy: 0.9265 - val_loss: 13.6929 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00006 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3941 - accuracy: 0.4091\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 32.7901 - accuracy: 0.4412\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61111, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.7901 - accuracy: 0.4412 - val_loss: 30.1991 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 29.8688 - accuracy: 0.8088\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 29.8688 - accuracy: 0.8088 - val_loss: 27.9480 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.5122 - accuracy: 0.8529\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.5122 - accuracy: 0.8529 - val_loss: 26.1519 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 25.6637 - accuracy: 0.8676\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 25.6637 - accuracy: 0.8676 - val_loss: 24.5474 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.0417 - accuracy: 0.9412\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 24.0417 - accuracy: 0.9412 - val_loss: 23.1669 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.6022 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 22.6022 - accuracy: 1.0000 - val_loss: 21.8832 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.3350 - accuracy: 0.9706\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.3350 - accuracy: 0.9706 - val_loss: 20.7743 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.1864 - accuracy: 0.9853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 20.1864 - accuracy: 0.9853 - val_loss: 19.7700 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.1798 - accuracy: 0.9559\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 19.1798 - accuracy: 0.9559 - val_loss: 18.8559 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.2015 - accuracy: 0.9853\n",
      "Epoch 00010: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 18.2015 - accuracy: 0.9853 - val_loss: 17.8662 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Using epoch 00010 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 18.0617 - accuracy: 0.4091\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 25.4673 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 25.4673 - accuracy: 0.5441 - val_loss: 23.9082 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.0929 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 24.0929 - accuracy: 0.5147 - val_loss: 23.0335 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.1864 - accuracy: 0.5294\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 23.1864 - accuracy: 0.5294 - val_loss: 22.3444 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.1636 - accuracy: 0.6765\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 22.1636 - accuracy: 0.6765 - val_loss: 21.6253 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.6433 - accuracy: 0.6029\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 21.6433 - accuracy: 0.6029 - val_loss: 21.1319 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.8610 - accuracy: 0.7059\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 20.8610 - accuracy: 0.7059 - val_loss: 20.5918 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.2235 - accuracy: 0.6912\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 20.2235 - accuracy: 0.6912 - val_loss: 20.0427 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.6838 - accuracy: 0.7794\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.6838 - accuracy: 0.7794 - val_loss: 19.5092 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.1767 - accuracy: 0.7353\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 19.1767 - accuracy: 0.7353 - val_loss: 19.0110 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.7150 - accuracy: 0.7059\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 18.7150 - accuracy: 0.7059 - val_loss: 18.4610 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 23.8359 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.9404 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.9404 - accuracy: 0.5000 - val_loss: 23.1536 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.2691 - accuracy: 0.6324\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.2691 - accuracy: 0.6324 - val_loss: 21.9959 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.8875 - accuracy: 0.6324\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 21.8875 - accuracy: 0.6324 - val_loss: 20.9844 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.8872 - accuracy: 0.7353\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.8872 - accuracy: 0.7353 - val_loss: 20.1272 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.8635 - accuracy: 0.8382\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 19.8635 - accuracy: 0.8382 - val_loss: 19.3605 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.1203 - accuracy: 0.7941\n",
      "Epoch 00006: val_accuracy improved from 0.55556 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 19.1203 - accuracy: 0.7941 - val_loss: 18.6616 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.3793 - accuracy: 0.8235\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.3793 - accuracy: 0.8235 - val_loss: 18.0257 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.8011 - accuracy: 0.7941\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.8011 - accuracy: 0.7941 - val_loss: 17.4451 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.1328 - accuracy: 0.8824\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.1328 - accuracy: 0.8824 - val_loss: 16.8812 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.6510 - accuracy: 0.7941\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.6510 - accuracy: 0.7941 - val_loss: 16.3850 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00006 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 18.7117 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 148.0062 - accuracy: 0.4118\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 148.0062 - accuracy: 0.4118 - val_loss: 134.9853 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 134.9645 - accuracy: 0.6765\n",
      "Epoch 00002: val_accuracy improved from 0.38889 to 0.44444, storing weights.\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 134.9645 - accuracy: 0.6765 - val_loss: 126.2867 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 125.8770 - accuracy: 0.8971\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 125.8770 - accuracy: 0.8971 - val_loss: 119.2848 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 118.7758 - accuracy: 0.8824\n",
      "Epoch 00004: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 118.7758 - accuracy: 0.8824 - val_loss: 113.3254 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 112.7797 - accuracy: 0.9559\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 112.7797 - accuracy: 0.9559 - val_loss: 108.0684 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 107.4600 - accuracy: 0.9559\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 107.4600 - accuracy: 0.9559 - val_loss: 103.3180 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 102.7106 - accuracy: 0.9853\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 102.7106 - accuracy: 0.9853 - val_loss: 98.9503 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 98.3470 - accuracy: 0.9706\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 98.3470 - accuracy: 0.9706 - val_loss: 94.9288 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 94.3083 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 94.3083 - accuracy: 1.0000 - val_loss: 91.1522 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 90.5439 - accuracy: 0.9853\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 90.5439 - accuracy: 0.9853 - val_loss: 87.6131 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00004 with val_accuracy: 0.50000\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 113.3297 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 29.9457 - accuracy: 0.4118\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.9457 - accuracy: 0.4118 - val_loss: 27.4944 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.3567 - accuracy: 0.7647\n",
      "Epoch 00002: val_accuracy improved from 0.38889 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 27.3567 - accuracy: 0.7647 - val_loss: 25.8779 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 25.6647 - accuracy: 0.8088\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 25.6647 - accuracy: 0.8088 - val_loss: 24.5630 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.2288 - accuracy: 0.8676\n",
      "Epoch 00004: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 24.2288 - accuracy: 0.8676 - val_loss: 23.4441 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.1452 - accuracy: 0.7941\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.1452 - accuracy: 0.7941 - val_loss: 22.5131 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.0457 - accuracy: 0.8971\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.0457 - accuracy: 0.8971 - val_loss: 21.5940 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.0820 - accuracy: 0.9559\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.0820 - accuracy: 0.9559 - val_loss: 20.7547 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.2591 - accuracy: 0.9118\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 20.2591 - accuracy: 0.9118 - val_loss: 19.9876 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.5600 - accuracy: 0.8971\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 19.5600 - accuracy: 0.8971 - val_loss: 19.3229 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.8102 - accuracy: 0.9559\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.8102 - accuracy: 0.9559 - val_loss: 18.6931 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00004 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.5052 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 29.4940 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 29.4940 - accuracy: 0.5147 - val_loss: 26.8809 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 26.5561 - accuracy: 0.7794\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 26.5561 - accuracy: 0.7794 - val_loss: 25.0806 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.6757 - accuracy: 0.7794\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 24.6757 - accuracy: 0.7794 - val_loss: 23.7557 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.1221 - accuracy: 0.8971\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.1221 - accuracy: 0.8971 - val_loss: 22.5457 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.8650 - accuracy: 0.9559\n",
      "Epoch 00005: val_accuracy improved from 0.44444 to 0.50000, storing weights.\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 21.8650 - accuracy: 0.9559 - val_loss: 21.3805 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.7967 - accuracy: 0.8824\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 20.7967 - accuracy: 0.8824 - val_loss: 20.4120 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.7556 - accuracy: 0.9559\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 19.7556 - accuracy: 0.9559 - val_loss: 19.4632 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.8228 - accuracy: 0.9706\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 18.8228 - accuracy: 0.9706 - val_loss: 18.6691 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.9151 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 17.9151 - accuracy: 1.0000 - val_loss: 17.8623 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.1200 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 17.1200 - accuracy: 1.0000 - val_loss: 17.0926 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Using epoch 00005 with val_accuracy: 0.50000\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 21.3820 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.5870 - accuracy: 0.4265\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.5870 - accuracy: 0.4265 - val_loss: 16.2671 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.8323 - accuracy: 0.8088\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 15.8323 - accuracy: 0.8088 - val_loss: 15.3607 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.7829 - accuracy: 0.9265\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 14.7829 - accuracy: 0.9265 - val_loss: 14.5644 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9278 - accuracy: 0.9706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 13.9278 - accuracy: 0.9706 - val_loss: 13.8699 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1650 - accuracy: 0.9706\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 13.1650 - accuracy: 0.9706 - val_loss: 13.2055 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4885 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 12.4885 - accuracy: 1.0000 - val_loss: 12.5941 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.8748 - accuracy: 0.9853\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 11.8748 - accuracy: 0.9853 - val_loss: 12.0625 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.3474 - accuracy: 0.9853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 11.3474 - accuracy: 0.9853 - val_loss: 11.5480 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8419 - accuracy: 0.9853\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10.8419 - accuracy: 0.9853 - val_loss: 11.0570 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.3186 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10.3186 - accuracy: 1.0000 - val_loss: 10.5917 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3440 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.1644 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.1644 - accuracy: 0.5441 - val_loss: 22.5576 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.4857 - accuracy: 0.6324\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.4857 - accuracy: 0.6324 - val_loss: 21.4075 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.2146 - accuracy: 0.7647\n",
      "Epoch 00003: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 21.2146 - accuracy: 0.7647 - val_loss: 20.4469 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.2521 - accuracy: 0.7059\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 20.2521 - accuracy: 0.7059 - val_loss: 19.6110 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.4388 - accuracy: 0.6618\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 19.4388 - accuracy: 0.6618 - val_loss: 18.8770 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.5570 - accuracy: 0.7941\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 18.5570 - accuracy: 0.7941 - val_loss: 18.2115 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.7995 - accuracy: 0.8824\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 17.7995 - accuracy: 0.8824 - val_loss: 17.5919 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.0906 - accuracy: 0.9118\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 17.0906 - accuracy: 0.9118 - val_loss: 16.9967 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.6730 - accuracy: 0.7500\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.6730 - accuracy: 0.7500 - val_loss: 16.4524 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.9891 - accuracy: 0.8235\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 15.9891 - accuracy: 0.8235 - val_loss: 15.9266 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00003 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 20.4066 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 29.3365 - accuracy: 0.5735\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.3365 - accuracy: 0.5735 - val_loss: 27.2584 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.4784 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.4784 - accuracy: 0.5441 - val_loss: 26.0214 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 26.1578 - accuracy: 0.5735\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 26.1578 - accuracy: 0.5735 - val_loss: 25.0336 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 25.2317 - accuracy: 0.4706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.2317 - accuracy: 0.4706 - val_loss: 24.2407 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.4366 - accuracy: 0.5441\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 24.4366 - accuracy: 0.5441 - val_loss: 23.5202 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.7906 - accuracy: 0.5588\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.7906 - accuracy: 0.5588 - val_loss: 22.8404 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.8623 - accuracy: 0.6029\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.8623 - accuracy: 0.6029 - val_loss: 22.1952 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.3195 - accuracy: 0.6029\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 22.3195 - accuracy: 0.6029 - val_loss: 21.6099 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.4799 - accuracy: 0.6912\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.4799 - accuracy: 0.6912 - val_loss: 21.0557 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.8938 - accuracy: 0.6765\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.8938 - accuracy: 0.6765 - val_loss: 20.5217 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.1633 - accuracy: 0.5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in [FatigueMI]:\n",
    "    for model in [\"lstm_cnn_net\"]:\n",
    "        model_optimizer = ModelOptimizer(\n",
    "            dataset=dataset(),\n",
    "            model_name=model\n",
    "        )\n",
    "        for subject in [12]:\n",
    "            max_epochs = MODELS_HYPERPARAMS_DICT[model][\"max_epochs\"]\n",
    "            study = model_optimizer.search_best_model(\n",
    "                subjects = [subject],\n",
    "                max_iter = 25,\n",
    "                max_epochs = max_epochs,\n",
    "                max_stag_count = 10,\n",
    "                rounds = 1,\n",
    "                replace_previous_study_for_subjects = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>16.501001</td>\n",
       "      <td>16.509830</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>16.570940</td>\n",
       "      <td>0.111511</td>\n",
       "      <td>[P3, Fz, Fp1, T3, O2, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>16.650978</td>\n",
       "      <td>16.384975</td>\n",
       "      <td>0.266003</td>\n",
       "      <td>18.711729</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>[P3, C3, Fz, Pz, Fp1, T3, O2, F7, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.176478</td>\n",
       "      <td>9.411931</td>\n",
       "      <td>0.235453</td>\n",
       "      <td>9.479000</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>[P3, C3, Pz, Fp1, Fp2, T3, O1, O2, F8, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>18.201464</td>\n",
       "      <td>17.866186</td>\n",
       "      <td>0.335278</td>\n",
       "      <td>18.061745</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>[P3, Fz, P4, Pz, Fp1, T3, O1, O2, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.289216</td>\n",
       "      <td>18.810242</td>\n",
       "      <td>18.693073</td>\n",
       "      <td>0.117168</td>\n",
       "      <td>23.505180</td>\n",
       "      <td>0.111711</td>\n",
       "      <td>[P3, F3, P4, Cz, Pz, Fp1, Fp2, T3, T5, O2, F7,...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>12.835961</td>\n",
       "      <td>13.050479</td>\n",
       "      <td>0.214518</td>\n",
       "      <td>14.696945</td>\n",
       "      <td>0.151535</td>\n",
       "      <td>[Fz, Fp1, F7, F8, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.374183</td>\n",
       "      <td>5.690474</td>\n",
       "      <td>6.120966</td>\n",
       "      <td>0.430493</td>\n",
       "      <td>6.868915</td>\n",
       "      <td>0.151635</td>\n",
       "      <td>[P3, C3, Fz, Fp1, T3, F7, F8, A2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.330065</td>\n",
       "      <td>13.613918</td>\n",
       "      <td>13.692876</td>\n",
       "      <td>0.078958</td>\n",
       "      <td>15.394052</td>\n",
       "      <td>0.151785</td>\n",
       "      <td>[P3, C3, Fz, Fp1, Fp2, T3, O2, F7, F8, A2, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.356209</td>\n",
       "      <td>15.989138</td>\n",
       "      <td>15.926647</td>\n",
       "      <td>0.062490</td>\n",
       "      <td>20.406557</td>\n",
       "      <td>0.198031</td>\n",
       "      <td>[P3, C3, Fz, Pz, Fp1, T3, O2, F7, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.135621</td>\n",
       "      <td>20.893789</td>\n",
       "      <td>20.521727</td>\n",
       "      <td>0.372063</td>\n",
       "      <td>27.163294</td>\n",
       "      <td>0.198031</td>\n",
       "      <td>[P3, C3, Fz, Pz, Fp1, T3, O2, F7, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>90.543869</td>\n",
       "      <td>87.613129</td>\n",
       "      <td>2.930740</td>\n",
       "      <td>113.329659</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>[P3, Fp1, Fp2, T3, O1, O2, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17.120031</td>\n",
       "      <td>17.092579</td>\n",
       "      <td>0.027452</td>\n",
       "      <td>21.381966</td>\n",
       "      <td>0.250450</td>\n",
       "      <td>[P3, C3, Fz, Fp1, T3, O1, O2, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>46.348530</td>\n",
       "      <td>44.497124</td>\n",
       "      <td>1.851406</td>\n",
       "      <td>49.466732</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>[C4, Pz, Fp2, T3, T5, O1, O2, F7, F8, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>32.705269</td>\n",
       "      <td>32.315151</td>\n",
       "      <td>0.390118</td>\n",
       "      <td>38.649002</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>[C3, C4, P4, Cz, Pz, Fp1, Fp2, T5, O2, A2, T6,...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.202614</td>\n",
       "      <td>10.266920</td>\n",
       "      <td>10.105042</td>\n",
       "      <td>0.161878</td>\n",
       "      <td>13.081115</td>\n",
       "      <td>0.308992</td>\n",
       "      <td>[P3, F4, Fp1, T3, O1, O2, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>8.139249</td>\n",
       "      <td>7.531272</td>\n",
       "      <td>0.607977</td>\n",
       "      <td>10.061922</td>\n",
       "      <td>0.361611</td>\n",
       "      <td>[C3, F3, F4, Cz, Fp2, T3, T5, O1, F7, F8]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.285948</td>\n",
       "      <td>69.336067</td>\n",
       "      <td>66.837341</td>\n",
       "      <td>2.498726</td>\n",
       "      <td>105.733490</td>\n",
       "      <td>0.401635</td>\n",
       "      <td>[P3, F4, C4, Pz, Fp2, O1, O2, F8]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>13.905450</td>\n",
       "      <td>13.580666</td>\n",
       "      <td>0.324784</td>\n",
       "      <td>17.546730</td>\n",
       "      <td>0.401735</td>\n",
       "      <td>[P3, F3, Fz, F4, C4, T5, F8, A2, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>61.713100</td>\n",
       "      <td>59.386101</td>\n",
       "      <td>2.327000</td>\n",
       "      <td>103.163849</td>\n",
       "      <td>0.447881</td>\n",
       "      <td>[C3, F4, Pz, O1, F7, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>10.318560</td>\n",
       "      <td>10.591687</td>\n",
       "      <td>0.273128</td>\n",
       "      <td>16.343996</td>\n",
       "      <td>0.447931</td>\n",
       "      <td>[P3, Pz, Fp1, T3, O1, O2, F7, F8]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.223856</td>\n",
       "      <td>18.715000</td>\n",
       "      <td>18.460951</td>\n",
       "      <td>0.254049</td>\n",
       "      <td>23.835949</td>\n",
       "      <td>0.447981</td>\n",
       "      <td>[P3, C3, Fz, Fp1, Fp2, T3, O2, F8, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>96.120659</td>\n",
       "      <td>93.092049</td>\n",
       "      <td>3.028610</td>\n",
       "      <td>133.859390</td>\n",
       "      <td>0.447981</td>\n",
       "      <td>[F3, F4, C4, P4, Cz, Pz, O1, A2, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.326797</td>\n",
       "      <td>16.766022</td>\n",
       "      <td>16.625278</td>\n",
       "      <td>0.140743</td>\n",
       "      <td>22.613884</td>\n",
       "      <td>0.448181</td>\n",
       "      <td>[P3, C3, F3, Fz, P4, Cz, Pz, Fp1, Fp2, T3, O2,...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff  train_loss   val_loss  \\\n",
       "12   1.000000  0.545455  0.666667            0.333333   16.501001  16.509830   \n",
       "16   0.882353  0.545455  0.666667            0.215686   16.650978  16.384975   \n",
       "5    1.000000  0.636364  0.666667            0.333333    9.176478   9.411931   \n",
       "14   1.000000  0.409091  0.666667            0.333333   18.201464  17.866186   \n",
       "18   0.955882  0.454545  0.666667            0.289216   18.810242  18.693073   \n",
       "6    1.000000  0.454545  0.611111            0.388889   12.835961  13.050479   \n",
       "11   0.985294  0.454545  0.611111            0.374183    5.690474   6.120966   \n",
       "13   0.941176  0.409091  0.611111            0.330065   13.613918  13.692876   \n",
       "21   0.911765  0.500000  0.555556            0.356209   15.989138  15.926647   \n",
       "22   0.691176  0.500000  0.555556            0.135621   20.893789  20.521727   \n",
       "17   1.000000  0.454545  0.500000            0.500000   90.543869  87.613129   \n",
       "19   1.000000  0.500000  0.500000            0.500000   17.120031  17.092579   \n",
       "1    0.955882  0.363636  0.500000            0.455882   46.348530  44.497124   \n",
       "8    0.882353  0.454545  0.500000            0.382353   32.705269  32.315151   \n",
       "2    0.647059  0.500000  0.444444            0.202614   10.266920  10.105042   \n",
       "3    0.676471  0.727273  0.666667            0.009804    8.139249   7.531272   \n",
       "0    0.897059  0.454545  0.611111            0.285948   69.336067  66.837341   \n",
       "4    0.676471  0.500000  0.611111            0.065359   13.905450  13.580666   \n",
       "7    1.000000  0.545455  0.555556            0.444444   61.713100  59.386101   \n",
       "20   1.000000  0.500000  0.555556            0.444444   10.318560  10.591687   \n",
       "15   0.779412  0.545455  0.555556            0.223856   18.715000  18.460951   \n",
       "9    0.750000  0.500000  0.555556            0.194444   96.120659  93.092049   \n",
       "10   0.882353  0.500000  0.555556            0.326797   16.766022  16.625278   \n",
       "\n",
       "    train_val_loss_diff   test_loss    scores  \\\n",
       "12             0.008829   16.570940  0.111511   \n",
       "16             0.266003   18.711729  0.111611   \n",
       "5              0.235453    9.479000  0.111611   \n",
       "14             0.335278   18.061745  0.111661   \n",
       "18             0.117168   23.505180  0.111711   \n",
       "6              0.214518   14.696945  0.151535   \n",
       "11             0.430493    6.868915  0.151635   \n",
       "13             0.078958   15.394052  0.151785   \n",
       "21             0.062490   20.406557  0.198031   \n",
       "22             0.372063   27.163294  0.198031   \n",
       "17             2.930740  113.329659  0.250400   \n",
       "19             0.027452   21.381966  0.250450   \n",
       "1              1.851406   49.466732  0.250500   \n",
       "8              0.390118   38.649002  0.250600   \n",
       "2              0.161878   13.081115  0.308992   \n",
       "3              0.607977   10.061922  0.361611   \n",
       "0              2.498726  105.733490  0.401635   \n",
       "4              0.324784   17.546730  0.401735   \n",
       "7              2.327000  103.163849  0.447881   \n",
       "20             0.273128   16.343996  0.447931   \n",
       "15             0.254049   23.835949  0.447981   \n",
       "9              3.028610  133.859390  0.447981   \n",
       "10             0.140743   22.613884  0.448181   \n",
       "\n",
       "                                    channels_selected  sfreq  batch_size  \n",
       "12                  [P3, Fz, Fp1, T3, O2, F7, F8, A2]  300.0         224  \n",
       "16          [P3, C3, Fz, Pz, Fp1, T3, O2, F7, F8, T6]  128.0         224  \n",
       "5          [P3, C3, Pz, Fp1, Fp2, T3, O1, O2, F8, T6]  300.0         224  \n",
       "14      [P3, Fz, P4, Pz, Fp1, T3, O1, O2, F7, F8, A2]  300.0         224  \n",
       "18  [P3, F3, P4, Cz, Pz, Fp1, Fp2, T3, T5, O2, F7,...  300.0         192  \n",
       "6                           [Fz, Fp1, F7, F8, A2, T4]  256.0         192  \n",
       "11                  [P3, C3, Fz, Fp1, T3, F7, F8, A2]  128.0         256  \n",
       "13     [P3, C3, Fz, Fp1, Fp2, T3, O2, F7, F8, A2, T6]  300.0         224  \n",
       "21          [P3, C3, Fz, Pz, Fp1, T3, O2, F7, F8, T6]  128.0         224  \n",
       "22          [P3, C3, Fz, Pz, Fp1, T3, O2, F7, F8, T6]  128.0         192  \n",
       "17                 [P3, Fp1, Fp2, T3, O1, O2, F8, A2]  300.0         256  \n",
       "19              [P3, C3, Fz, Fp1, T3, O1, O2, F8, A2]  300.0         128  \n",
       "1           [C4, Pz, Fp2, T3, T5, O1, O2, F7, F8, T6]  256.0          64  \n",
       "8   [C3, C4, P4, Cz, Pz, Fp1, Fp2, T5, O2, A2, T6,...  256.0         160  \n",
       "2                       [P3, F4, Fp1, T3, O1, O2, T4]  300.0         128  \n",
       "3           [C3, F3, F4, Cz, Fp2, T3, T5, O1, F7, F8]  300.0          32  \n",
       "0                   [P3, F4, C4, Pz, Fp2, O1, O2, F8]  256.0         160  \n",
       "4            [P3, F3, Fz, F4, C4, T5, F8, A2, T6, T4]  256.0         160  \n",
       "7                        [C3, F4, Pz, O1, F7, T6, T4]  300.0         160  \n",
       "20                  [P3, Pz, Fp1, T3, O1, O2, F7, F8]  128.0         224  \n",
       "15             [P3, C3, Fz, Fp1, Fp2, T3, O2, F8, T6]  300.0          96  \n",
       "9                [F3, F4, C4, P4, Cz, Pz, O1, A2, T4]  300.0         192  \n",
       "10  [P3, C3, F3, Fz, P4, Cz, Pz, Fp1, Fp2, T3, O2,...  128.0         256  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_optimizer.get_study_metrics(study).sort_values(by=\"scores\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_units'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_kernel_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_strides'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_maxpool_strides'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'lstm_1_units'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'l2_reg_1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3383681530636568</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'l2_reg_2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.16073380063395976</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'l2_reg_3'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.23971068335483192</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'dropout_rate_1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'dropout_rate_2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m224\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'conv1d_1_units'\u001b[0m: \u001b[1;36m70\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'conv1d_1_kernel_size'\u001b[0m: \u001b[1;36m78\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'conv1d_1_strides'\u001b[0m: \u001b[1;36m3\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'conv1d_1_maxpool_strides'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'lstm_1_units'\u001b[0m: \u001b[1;36m100\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'l2_reg_1'\u001b[0m: \u001b[1;36m0.3383681530636568\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'l2_reg_2'\u001b[0m: \u001b[1;36m0.16073380063395976\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'l2_reg_3'\u001b[0m: \u001b[1;36m0.23971068335483192\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'dropout_rate_1'\u001b[0m: \u001b[1;36m0.4\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'dropout_rate_2'\u001b[0m: \u001b[1;36m0.6\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test_accuracy = \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666865348816</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val_accuracy = \u001b[1;36m0.6666666865348816\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">channels_selected = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'P3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fp1'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'O2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F7'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F8'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'A2'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "channels_selected = \u001b[1m[\u001b[0m\u001b[32m'P3'\u001b[0m \u001b[32m'Fz'\u001b[0m \u001b[32m'Fp1'\u001b[0m \u001b[32m'T3'\u001b[0m \u001b[32m'O2'\u001b[0m \u001b[32m'F7'\u001b[0m \u001b[32m'F8'\u001b[0m \u001b[32m'A2'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint({ k: v for k, v in study.best_trial.params.items() if not k.startswith(\"channels\") })\n",
    "rprint(\"test_accuracy =\", study.best_trial.user_attrs[\"trial_data\"][\"test_accuracy\"])\n",
    "rprint(\"val_accuracy =\", np.max(study.best_trial.user_attrs[\"trial_data\"][\"val_accuracy\"]))\n",
    "rprint(\"channels_selected =\", study.best_trial.user_attrs[\"trial_data\"][\"channels_selected\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
