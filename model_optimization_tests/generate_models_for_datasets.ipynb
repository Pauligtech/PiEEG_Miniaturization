{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "from model_optim.model_optimizer import ModelOptimizer\n",
    "\n",
    "# Dataset\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "from custom_datasets.norm_cho import NormCho2017\n",
    "from custom_datasets.opt_game_mi import OptGameMI\n",
    "from custom_datasets.opt_std_mi import OptStdMI\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [\n",
    "    \"shallow_conv_net\",\n",
    "    \"lstm_net\",\n",
    "    \"deep_conv_net\",\n",
    "    \"eeg_net\",\n",
    "    \"lstm_cnn_net\",\n",
    "    \"lstm_cnn_net_v2\"\n",
    "]\n",
    "MODELS_HYPERPARAMS_DICT = {\n",
    "    \"shallow_conv_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"eeg_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"deep_conv_net\": {\n",
    "        \"max_epochs\": 25\n",
    "    },\n",
    "    \"lstm_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net_v2\": {},\n",
    "}\n",
    "\n",
    "DATASETS_LIST = [\n",
    "    FatigueMI,\n",
    "    # NormCho2017,\n",
    "    # OptGameMI,\n",
    "    # OptStdMI,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_optim.utils import data_generator\n",
    "\n",
    "# data_generator(\n",
    "#     dataset=NormCho2017(),\n",
    "#     subjects=[1],\n",
    "#     channel_idx=[],\n",
    "#     sfreq=128,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files = glob.glob(\"./temp_v2/*/*/model/shallow_conv_net_study_best_trial.npy\")\n",
    "subject_files_data = {}\n",
    "for subject_file in subject_files:\n",
    "    subject_files_data[subject_file] = np.load(subject_file, allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[9]/63a8c87ffc02471893db5ac9a0781946/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9090909361839294</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[4]/3623cb4ba1ad4a908c9098f5297a6778/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[1]/292cbc92b8cf46da9986fe7d8447819f/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[10]/c2cc69dca74d4bfa81722cd634e6403e/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727273106575012</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[12]/96dc576945fb4f2db582d66ae1d2c8ce/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727273106575012</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[7]/aabe056cd1954a6f92ab47d84c86b1b8/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[11]/e0643f9a780146a4adc15ddd4a9ff053/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[3]/9c1b753483db409a90eab7b7149b8af8/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[13]/1b189965ada44ff99e73fa145cd3901d/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[5]/d199c9c2ac924b238693f158eb88f675/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[8]/9fd82ec44ef3496da6307b57ecf4532f/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[2]/6405d11e654b42aca9df48458c67ecde/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[14]/a3304348c7094d02a024828ede942cda/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909091234207153</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[6]/39d01251ff494106bf04f8a2cffcdd74/model/shallow_conv_net_study_best_trial.npy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/63a8c87ffc02471893db5ac9a0781946/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.9090909361839294\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/3623cb4ba1ad4a908c9098f5297a6778/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/292cbc92b8cf46da9986fe7d8447819f/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/c2cc69dca74d4bfa81722cd634e6403e/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.7727273106575012\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/96dc576945fb4f2db582d66ae1d2c8ce/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.7727273106575012\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/aabe056cd1954a6f92ab47d84c86b1b8/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.7272727489471436\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/e0643f9a780146a4adc15ddd4a9ff053/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.7272727489471436\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/9c1b753483db409a90eab7b7149b8af8/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/1b189965ada44ff99e73fa145cd3901d/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/d199c9c2ac924b238693f158eb88f675/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/9fd82ec44ef3496da6307b57ecf4532f/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/6405d11e654b42aca9df48458c67ecde/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/a3304348c7094d02a024828ede942cda/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.5909091234207153\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/39d01251ff494106bf04f8a2cffcdd74/model/shallow_conv_net_study_best_trial.npy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort subject_files_data by subject_file_data.user_attrs['trial_data']['test_accuracy']\n",
    "sorted_subject_files_data = dict(sorted(subject_files_data.items(), key=lambda item: item[1].user_attrs['trial_data']['test_accuracy'], reverse=True))\n",
    "sorted_subject_files_data_test_acc = {k: v.user_attrs['trial_data']['test_accuracy'] for k, v in sorted_subject_files_data.items()}\n",
    "rpprint(sorted_subject_files_data_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n"
     ]
    }
   ],
   "source": [
    "model_optimizer = ModelOptimizer(\n",
    "    dataset=FatigueMI(),\n",
    "    model_name=\"shallow_conv_net\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n",
      "Found previous study in ./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb93fd4f9a/model/deep_conv_net_study_best_trial.npy, removing...\n",
      "Found previous study in ./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb93fd4f9a/model/deep_conv_net_study.npy, removing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6843d152a7a4ce483a815f49c86727b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 23:15:51.166238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-02 23:15:51.166604: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.2426 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2426 - accuracy: 0.5441 - val_loss: 1.2549 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4628 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.4628 - accuracy: 0.4853 - val_loss: 4.5488 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2707 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.2707 - accuracy: 0.5147 - val_loss: 0.6854 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.5588\n",
      "Epoch 00004: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6965 - accuracy: 0.5588 - val_loss: 0.6546 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9967 - accuracy: 0.5294\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9967 - accuracy: 0.5294 - val_loss: 1.8201 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2142 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.2142 - accuracy: 0.4853 - val_loss: 0.8422 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0413 - accuracy: 0.5147\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.0413 - accuracy: 0.5147 - val_loss: 1.5324 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2294 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.2294 - accuracy: 0.4853 - val_loss: 0.7444 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6523 - accuracy: 0.5147\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.6523 - accuracy: 0.5147 - val_loss: 1.2064 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4796 - accuracy: 0.4853\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.4796 - accuracy: 0.4853 - val_loss: 0.8300 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8036 - accuracy: 0.5147\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.8036 - accuracy: 0.5147 - val_loss: 0.9858 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1422 - accuracy: 0.4853\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.1422 - accuracy: 0.4853 - val_loss: 0.8849 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6811 - accuracy: 0.5147\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6811 - accuracy: 0.5147 - val_loss: 0.7529 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7067 - accuracy: 0.4853\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.7067 - accuracy: 0.4853 - val_loss: 0.9589 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3814 - accuracy: 0.5441\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3814 - accuracy: 0.5441 - val_loss: 1.0075 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1382 - accuracy: 0.5735\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1382 - accuracy: 0.5735 - val_loss: 1.0605 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8288 - accuracy: 0.5882\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8288 - accuracy: 0.5882 - val_loss: 1.1208 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7828 - accuracy: 0.6176\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7828 - accuracy: 0.6176 - val_loss: 1.1725 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.6471\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6929 - accuracy: 0.6471 - val_loss: 1.2380 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.7353\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6080 - accuracy: 0.7353 - val_loss: 1.3071 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.7206\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5711 - accuracy: 0.7206 - val_loss: 1.3725 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.7647\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5565 - accuracy: 0.7647 - val_loss: 1.4396 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.6912\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6288 - accuracy: 0.6912 - val_loss: 1.4915 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6235 - accuracy: 0.5882\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6235 - accuracy: 0.5882 - val_loss: 1.5481 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.7353\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5464 - accuracy: 0.7353 - val_loss: 1.6103 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Using epoch 00004 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6999 - accuracy: 0.4091\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 1s - loss: 0.9461 - accuracy: 0.5625\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 1s 98ms/step - loss: 1.1409 - accuracy: 0.5147 - val_loss: 2.6557 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.7451 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.0045 - accuracy: 0.4559 - val_loss: 0.7136 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7202 - accuracy: 0.5625\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0247 - accuracy: 0.4706 - val_loss: 0.7421 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7702 - accuracy: 0.5625\n",
      "Epoch 00004: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9926 - accuracy: 0.4706 - val_loss: 0.7097 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5538 - accuracy: 0.6562\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5987 - accuracy: 0.6618 - val_loss: 0.7031 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5963 - accuracy: 0.6875\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5806 - accuracy: 0.6618 - val_loss: 0.7733 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6438 - accuracy: 0.5312\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5507 - accuracy: 0.6029 - val_loss: 1.1312 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2312 - accuracy: 0.5938\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8802 - accuracy: 0.6176 - val_loss: 1.0201 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5966 - accuracy: 0.6562\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5968 - accuracy: 0.6618 - val_loss: 0.7634 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8311 - accuracy: 0.4688\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6689 - accuracy: 0.5735 - val_loss: 0.8527 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5428 - accuracy: 0.6875\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5370 - accuracy: 0.7353 - val_loss: 0.7249 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0026 - accuracy: 0.5000\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8330 - accuracy: 0.5588 - val_loss: 0.7507 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4603 - accuracy: 0.8125\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4456 - accuracy: 0.7794 - val_loss: 0.7519 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6270 - accuracy: 0.5938\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5848 - accuracy: 0.6471 - val_loss: 1.1065 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.6765\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6119 - accuracy: 0.6765 - val_loss: 1.1445 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3943 - accuracy: 0.7812\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4598 - accuracy: 0.7206 - val_loss: 1.1062 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5446 - accuracy: 0.6875\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4821 - accuracy: 0.7353 - val_loss: 1.1397 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5105 - accuracy: 0.6875\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4776 - accuracy: 0.7353 - val_loss: 1.0627 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5333 - accuracy: 0.6875\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4663 - accuracy: 0.7500 - val_loss: 1.0476 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4262 - accuracy: 0.7812\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4330 - accuracy: 0.7500 - val_loss: 1.0630 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4911 - accuracy: 0.7812\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4517 - accuracy: 0.7794 - val_loss: 1.0662 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4709 - accuracy: 0.7812\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4467 - accuracy: 0.7500 - val_loss: 1.0532 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4653 - accuracy: 0.7500\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4164 - accuracy: 0.7647 - val_loss: 0.9514 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4363 - accuracy: 0.8125\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4286 - accuracy: 0.8088 - val_loss: 0.9122 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4039 - accuracy: 0.8750\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3950 - accuracy: 0.8824 - val_loss: 0.9177 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Using epoch 00004 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7371 - accuracy: 0.3636\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0619 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 1.0619 - accuracy: 0.5294 - val_loss: 0.7837 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9365 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy improved from 0.38889 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9365 - accuracy: 0.5441 - val_loss: 1.3534 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7754 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.7754 - accuracy: 0.4853 - val_loss: 0.7793 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2149 - accuracy: 0.5147\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2149 - accuracy: 0.5147 - val_loss: 1.0121 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3042 - accuracy: 0.4853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3042 - accuracy: 0.4853 - val_loss: 0.7367 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9192 - accuracy: 0.5000 - val_loss: 0.8483 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9350 - accuracy: 0.5147\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9350 - accuracy: 0.5147 - val_loss: 0.7426 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9190 - accuracy: 0.5588\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9190 - accuracy: 0.5588 - val_loss: 0.7723 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8974 - accuracy: 0.5147\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8974 - accuracy: 0.5147 - val_loss: 0.7350 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.5588\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8123 - accuracy: 0.5588 - val_loss: 0.7563 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.5000\n",
      "Epoch 00011: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8774 - accuracy: 0.5000 - val_loss: 0.7535 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8435 - accuracy: 0.5588\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8435 - accuracy: 0.5588 - val_loss: 0.7376 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.5000\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8419 - accuracy: 0.5000 - val_loss: 0.7657 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7930 - accuracy: 0.5000\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7930 - accuracy: 0.5000 - val_loss: 0.7191 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8557 - accuracy: 0.5588\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8557 - accuracy: 0.5588 - val_loss: 0.7742 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.5588\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7219 - accuracy: 0.5588 - val_loss: 0.7061 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7725 - accuracy: 0.5000\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7725 - accuracy: 0.5000 - val_loss: 0.8012 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7541 - accuracy: 0.6324\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7541 - accuracy: 0.6324 - val_loss: 0.7032 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7649 - accuracy: 0.5294\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7649 - accuracy: 0.5294 - val_loss: 0.8290 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7764 - accuracy: 0.5441\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7764 - accuracy: 0.5441 - val_loss: 0.7189 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.5294\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8192 - accuracy: 0.5294 - val_loss: 0.8562 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.6471\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6891 - accuracy: 0.6471 - val_loss: 0.7495 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7386 - accuracy: 0.6324\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7386 - accuracy: 0.6324 - val_loss: 0.8835 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7077 - accuracy: 0.6471\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7077 - accuracy: 0.6471 - val_loss: 0.8090 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6176\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6159 - accuracy: 0.6176 - val_loss: 0.8769 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00011 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7129 - accuracy: 0.3636\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2693 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 1.2693 - accuracy: 0.4853 - val_loss: 1.0286 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5831 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5831 - accuracy: 0.4853 - val_loss: 3.0164 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6158 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.6158 - accuracy: 0.5147 - val_loss: 0.9446 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.6618\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6535 - accuracy: 0.6618 - val_loss: 0.6982 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9663 - accuracy: 0.5441\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9663 - accuracy: 0.5441 - val_loss: 1.0813 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6012 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6012 - accuracy: 0.4853 - val_loss: 0.7242 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9736 - accuracy: 0.5735\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9736 - accuracy: 0.5735 - val_loss: 0.9583 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8077 - accuracy: 0.5294\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8077 - accuracy: 0.5294 - val_loss: 0.7292 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.6618\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - accuracy: 0.6618 - val_loss: 0.7253 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.6765\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5826 - accuracy: 0.6765 - val_loss: 0.7322 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.6618\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5414 - accuracy: 0.6618 - val_loss: 0.7205 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.7206\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5006 - accuracy: 0.7206 - val_loss: 0.7550 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.7941\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4828 - accuracy: 0.7941 - val_loss: 0.7510 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.6912\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5190 - accuracy: 0.6912 - val_loss: 0.7743 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.7794\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4796 - accuracy: 0.7794 - val_loss: 0.7886 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.7941\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4827 - accuracy: 0.7941 - val_loss: 0.8009 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.7794\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4685 - accuracy: 0.7794 - val_loss: 0.8122 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5132 - accuracy: 0.7500 - val_loss: 0.8238 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.7353\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4779 - accuracy: 0.7353 - val_loss: 0.8357 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.7206\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4884 - accuracy: 0.7206 - val_loss: 0.8435 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7647\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4905 - accuracy: 0.7647 - val_loss: 0.8494 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.7941\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4637 - accuracy: 0.7941 - val_loss: 0.8556 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.6912\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5023 - accuracy: 0.6912 - val_loss: 0.8628 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.7206\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4926 - accuracy: 0.7206 - val_loss: 0.8698 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4650 - accuracy: 0.7500 - val_loss: 0.8756 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3483 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1923 - accuracy: 0.4412\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 1.1923 - accuracy: 0.4412 - val_loss: 0.8497 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8439 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8439 - accuracy: 0.5000 - val_loss: 2.6501 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2617 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.2617 - accuracy: 0.5147 - val_loss: 1.6042 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3544 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3544 - accuracy: 0.4853 - val_loss: 0.7554 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7703 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7703 - accuracy: 0.5147 - val_loss: 1.6157 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3416 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3416 - accuracy: 0.4853 - val_loss: 0.8910 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.6471\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7327 - accuracy: 0.6471 - val_loss: 0.8702 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7206\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6290 - accuracy: 0.7206 - val_loss: 0.7565 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5988 - accuracy: 0.6618\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5988 - accuracy: 0.6618 - val_loss: 0.7472 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7647\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5041 - accuracy: 0.7647 - val_loss: 0.7586 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.6029\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5808 - accuracy: 0.6029 - val_loss: 0.7632 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.7500\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4988 - accuracy: 0.7500 - val_loss: 0.7941 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.8088\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - accuracy: 0.8088 - val_loss: 0.7959 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.7941\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4876 - accuracy: 0.7941 - val_loss: 0.8066 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.8382\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4630 - accuracy: 0.8382 - val_loss: 0.8477 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.7500\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4738 - accuracy: 0.7500 - val_loss: 0.8562 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.8088\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4455 - accuracy: 0.8088 - val_loss: 0.9112 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.7500\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4500 - accuracy: 0.7500 - val_loss: 0.8680 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.7647\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4559 - accuracy: 0.7647 - val_loss: 0.9913 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8088\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4292 - accuracy: 0.8088 - val_loss: 1.0018 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.7794\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4283 - accuracy: 0.7794 - val_loss: 1.0120 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.7647\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4336 - accuracy: 0.7647 - val_loss: 1.0229 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8088\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4298 - accuracy: 0.8088 - val_loss: 1.0279 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.7647\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4377 - accuracy: 0.7647 - val_loss: 1.0309 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.8088\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - accuracy: 0.8088 - val_loss: 1.0457 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8681 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6612 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 1.6612 - accuracy: 0.5441 - val_loss: 0.8968 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1542 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1542 - accuracy: 0.4853 - val_loss: 0.9803 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2023 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2023 - accuracy: 0.5147 - val_loss: 1.0468 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.5294\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8454 - accuracy: 0.5294 - val_loss: 0.7576 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9108 - accuracy: 0.5441\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9108 - accuracy: 0.5441 - val_loss: 1.1219 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9676 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9676 - accuracy: 0.5294 - val_loss: 0.8031 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8389 - accuracy: 0.5735\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8389 - accuracy: 0.5735 - val_loss: 0.9652 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.5735\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7040 - accuracy: 0.5735 - val_loss: 0.7838 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.5735\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6656 - accuracy: 0.5735 - val_loss: 0.7892 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.6618\n",
      "Epoch 00010: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6585 - accuracy: 0.6618 - val_loss: 0.6879 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7212 - accuracy: 0.6324\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7212 - accuracy: 0.6324 - val_loss: 0.7188 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7093 - accuracy: 0.6324\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7093 - accuracy: 0.6324 - val_loss: 0.6600 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.6912\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6429 - accuracy: 0.6912 - val_loss: 0.6658 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.6912\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6456 - accuracy: 0.6912 - val_loss: 0.6978 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6488 - accuracy: 0.6471\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6488 - accuracy: 0.6471 - val_loss: 0.6565 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.6765\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6690 - accuracy: 0.6765 - val_loss: 0.7168 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.7353\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5291 - accuracy: 0.7353 - val_loss: 0.7117 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.7206\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5453 - accuracy: 0.7206 - val_loss: 0.7893 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.7059\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5216 - accuracy: 0.7059 - val_loss: 0.8284 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.7059\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5338 - accuracy: 0.7059 - val_loss: 0.8852 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.7059\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4889 - accuracy: 0.7059 - val_loss: 0.9104 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.7500\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4941 - accuracy: 0.7500 - val_loss: 0.9554 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.7500\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5118 - accuracy: 0.7500 - val_loss: 1.0286 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.7500\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4762 - accuracy: 0.7500 - val_loss: 1.0937 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.6912\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4921 - accuracy: 0.6912 - val_loss: 1.0409 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00010 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1577 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3868 - accuracy: 0.5294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 1.3868 - accuracy: 0.5294 - val_loss: 1.1276 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7945 - accuracy: 0.4559\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7945 - accuracy: 0.4559 - val_loss: 0.7225 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9208 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.9208 - accuracy: 0.5147 - val_loss: 1.2455 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3410 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3410 - accuracy: 0.4853 - val_loss: 0.9242 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.5735\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8270 - accuracy: 0.5735 - val_loss: 0.9224 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8419 - accuracy: 0.5147 - val_loss: 0.7309 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.6176\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7601 - accuracy: 0.6176 - val_loss: 0.7804 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.5882\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7512 - accuracy: 0.5882 - val_loss: 0.7128 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6633 - accuracy: 0.6029 - val_loss: 0.7142 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.6618\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5654 - accuracy: 0.6618 - val_loss: 0.7218 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.5735\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6869 - accuracy: 0.5735 - val_loss: 0.7241 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5630 - accuracy: 0.6912\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5630 - accuracy: 0.6912 - val_loss: 0.7519 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.6912\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6479 - accuracy: 0.6912 - val_loss: 0.7126 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.5882\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6044 - accuracy: 0.5882 - val_loss: 0.7525 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.6471\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6124 - accuracy: 0.6471 - val_loss: 0.7324 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.6176\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5761 - accuracy: 0.6176 - val_loss: 0.7566 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.6912\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5381 - accuracy: 0.6912 - val_loss: 0.7749 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.6765\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5575 - accuracy: 0.6765 - val_loss: 0.7504 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.6471\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6055 - accuracy: 0.6471 - val_loss: 0.8629 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.6618\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6021 - accuracy: 0.6618 - val_loss: 0.7701 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.6618\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6105 - accuracy: 0.6618 - val_loss: 0.8604 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6618\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6071 - accuracy: 0.6618 - val_loss: 0.8102 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7059\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5215 - accuracy: 0.7059 - val_loss: 0.8216 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.6912\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5408 - accuracy: 0.6912 - val_loss: 0.8242 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8529\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4525 - accuracy: 0.8529 - val_loss: 0.8283 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3506 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1556 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 1.1556 - accuracy: 0.5000 - val_loss: 1.4835 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2505 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2505 - accuracy: 0.4853 - val_loss: 4.6344 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5766 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.5766 - accuracy: 0.5147 - val_loss: 1.2669 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.6029\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7060 - accuracy: 0.6029 - val_loss: 0.7305 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4274 - accuracy: 0.5294\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4274 - accuracy: 0.5294 - val_loss: 2.1746 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7625 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.7625 - accuracy: 0.4853 - val_loss: 0.8365 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3472 - accuracy: 0.5588\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3472 - accuracy: 0.5588 - val_loss: 1.6959 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7730 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7730 - accuracy: 0.4853 - val_loss: 0.7497 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0979 - accuracy: 0.5441\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0979 - accuracy: 0.5441 - val_loss: 1.1819 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9217 - accuracy: 0.5147\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9217 - accuracy: 0.5147 - val_loss: 0.7276 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8978 - accuracy: 0.5588\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8978 - accuracy: 0.5588 - val_loss: 0.8224 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7841 - accuracy: 0.6471\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7841 - accuracy: 0.6471 - val_loss: 0.7970 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.5735\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7731 - accuracy: 0.5735 - val_loss: 0.7080 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7444 - accuracy: 0.6029\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7444 - accuracy: 0.6029 - val_loss: 0.9252 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.6471\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7323 - accuracy: 0.6471 - val_loss: 0.7148 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.6471\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6928 - accuracy: 0.6471 - val_loss: 1.1549 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.6029\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7438 - accuracy: 0.6029 - val_loss: 0.7754 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.6176\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6525 - accuracy: 0.6176 - val_loss: 1.2178 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.6324\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5836 - accuracy: 0.6324 - val_loss: 0.9044 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7647\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5123 - accuracy: 0.7647 - val_loss: 1.2234 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.6765\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - accuracy: 0.6765 - val_loss: 0.8862 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5975 - accuracy: 0.7206\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5975 - accuracy: 0.7206 - val_loss: 1.2736 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.6618\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5386 - accuracy: 0.6618 - val_loss: 0.8599 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.6324\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5888 - accuracy: 0.6324 - val_loss: 0.9358 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.6471\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6328 - accuracy: 0.6471 - val_loss: 1.0195 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00006 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6746 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3066 - accuracy: 0.5735\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 1.3066 - accuracy: 0.5735 - val_loss: 0.7939 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7316 - accuracy: 0.5294\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7316 - accuracy: 0.5294 - val_loss: 2.5168 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8150 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.8150 - accuracy: 0.5147 - val_loss: 1.5019 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4104 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4104 - accuracy: 0.4853 - val_loss: 0.7658 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7716 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7716 - accuracy: 0.5147 - val_loss: 1.5421 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9486 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9486 - accuracy: 0.5147 - val_loss: 0.9693 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.6618\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7082 - accuracy: 0.6618 - val_loss: 0.7714 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.6618\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5710 - accuracy: 0.6618 - val_loss: 0.7441 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.6471\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5802 - accuracy: 0.6471 - val_loss: 0.7271 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7500\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5259 - accuracy: 0.7500 - val_loss: 0.7556 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.7206\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4968 - accuracy: 0.7206 - val_loss: 0.7389 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.7647\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4989 - accuracy: 0.7647 - val_loss: 0.8161 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.7059\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - accuracy: 0.7059 - val_loss: 0.7472 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.7206\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5065 - accuracy: 0.7206 - val_loss: 0.9291 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.6618\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5349 - accuracy: 0.6618 - val_loss: 0.7385 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.6765\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5202 - accuracy: 0.6765 - val_loss: 1.0754 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.6912\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5195 - accuracy: 0.6912 - val_loss: 0.7457 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.6912\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4875 - accuracy: 0.6912 - val_loss: 1.1991 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7353\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5001 - accuracy: 0.7353 - val_loss: 0.7746 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.7059\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6222 - accuracy: 0.7059 - val_loss: 0.7968 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.7794\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4326 - accuracy: 0.7794 - val_loss: 0.8257 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.8088\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4234 - accuracy: 0.8088 - val_loss: 0.8545 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.7941\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - accuracy: 0.7941 - val_loss: 0.8829 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4106 - accuracy: 0.8088\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4106 - accuracy: 0.8088 - val_loss: 0.9065 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.8235\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4046 - accuracy: 0.8235 - val_loss: 0.9368 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00001 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8122 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 1s - loss: 2.0154 - accuracy: 0.3125\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 1s 94ms/step - loss: 2.3548 - accuracy: 0.4118 - val_loss: 2.2521 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1740 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.7561 - accuracy: 0.4559 - val_loss: 0.6598 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7677 - accuracy: 0.5312\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.2608 - accuracy: 0.4706 - val_loss: 0.6715 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7232 - accuracy: 0.5625\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0400 - accuracy: 0.5000 - val_loss: 0.7059 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8561 - accuracy: 0.6250\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7473 - accuracy: 0.6618 - val_loss: 0.9689 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.1169 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.5835 - accuracy: 0.4412 - val_loss: 0.7688 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5085 - accuracy: 0.7188\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5929 - accuracy: 0.6912 - val_loss: 1.5879 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9920 - accuracy: 0.5938\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0437 - accuracy: 0.6324 - val_loss: 0.8671 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8337 - accuracy: 0.6250\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7545 - accuracy: 0.6618 - val_loss: 0.8805 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2015 - accuracy: 0.4688\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.7862 - accuracy: 0.4412 - val_loss: 1.6340 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5979 - accuracy: 0.7500\n",
      "Epoch 00011: val_accuracy improved from 0.55556 to 0.66667, storing weights.\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6642 - accuracy: 0.7059 - val_loss: 0.6267 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3735 - accuracy: 0.4062\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.8831 - accuracy: 0.5588 - val_loss: 1.5433 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5049 - accuracy: 0.7188\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4671 - accuracy: 0.7647 - val_loss: 1.5214 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4997 - accuracy: 0.7500\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4822 - accuracy: 0.7647 - val_loss: 1.8230 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6248 - accuracy: 0.6875\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5097 - accuracy: 0.7500 - val_loss: 1.2922 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4151 - accuracy: 0.8750\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3737 - accuracy: 0.8676 - val_loss: 1.5824 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3721 - accuracy: 0.8438\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5109 - accuracy: 0.7794 - val_loss: 1.6741 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3939 - accuracy: 0.8125\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4933 - accuracy: 0.8088 - val_loss: 2.3202 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5126 - accuracy: 0.7812\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6445 - accuracy: 0.7059 - val_loss: 1.4677 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6760 - accuracy: 0.7812\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5971 - accuracy: 0.7794 - val_loss: 2.9208 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0444 - accuracy: 0.6250\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7653 - accuracy: 0.7206 - val_loss: 2.0280 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2837 - accuracy: 0.8438\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2577 - accuracy: 0.8676 - val_loss: 2.0477 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2882 - accuracy: 0.8438\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2983 - accuracy: 0.8529 - val_loss: 2.1117 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3812 - accuracy: 0.7812\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3718 - accuracy: 0.8235 - val_loss: 2.0996 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3905 - accuracy: 0.8750\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3299 - accuracy: 0.8529 - val_loss: 2.2902 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00011 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7297 - accuracy: 0.5909\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/3 [=========>....................] - ETA: 1s - loss: 0.7604 - accuracy: 0.6562\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "3/3 [==============================] - 1s 91ms/step - loss: 1.1932 - accuracy: 0.5441 - val_loss: 0.7335 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5736 - accuracy: 0.4688\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.2049 - accuracy: 0.4559 - val_loss: 1.0608 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3766 - accuracy: 0.5938\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3355 - accuracy: 0.6029 - val_loss: 0.7254 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7942 - accuracy: 0.6875\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8233 - accuracy: 0.6618 - val_loss: 0.7058 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2609 - accuracy: 0.5938\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0650 - accuracy: 0.6176 - val_loss: 0.7709 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6548 - accuracy: 0.6250\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2111 - accuracy: 0.5000 - val_loss: 0.7900 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6698 - accuracy: 0.6250\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7248 - accuracy: 0.6618 - val_loss: 1.6165 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2329 - accuracy: 0.5938\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2130 - accuracy: 0.5735 - val_loss: 0.7619 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8487 - accuracy: 0.5938\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7983 - accuracy: 0.6176 - val_loss: 0.8643 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7163 - accuracy: 0.5938\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1150 - accuracy: 0.5294 - val_loss: 1.2652 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5904 - accuracy: 0.7188\n",
      "Epoch 00011: val_accuracy improved from 0.55556 to 0.72222, storing weights.\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7088 - accuracy: 0.6765 - val_loss: 0.5579 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5986 - accuracy: 0.4062\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.0104 - accuracy: 0.5588 - val_loss: 1.2077 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5240 - accuracy: 0.7188\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5871 - accuracy: 0.6912 - val_loss: 0.8209 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8663 - accuracy: 0.5625\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0397 - accuracy: 0.5588 - val_loss: 1.3321 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5155 - accuracy: 0.6875\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4478 - accuracy: 0.7206 - val_loss: 1.1110 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4186 - accuracy: 0.8438\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4298 - accuracy: 0.8235 - val_loss: 1.2646 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4482 - accuracy: 0.7188\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5633 - accuracy: 0.6912 - val_loss: 2.1458 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2052 - accuracy: 0.4375\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.8019 - accuracy: 0.4706 - val_loss: 2.1530 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0298 - accuracy: 0.5625\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9544 - accuracy: 0.6176 - val_loss: 1.2278 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4190 - accuracy: 0.7812\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3749 - accuracy: 0.8088 - val_loss: 2.2864 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7541 - accuracy: 0.5938\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8364 - accuracy: 0.6176 - val_loss: 1.9442 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8237 - accuracy: 0.6250\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6740 - accuracy: 0.6912 - val_loss: 1.6917 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5893 - accuracy: 0.6875\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4638 - accuracy: 0.7794 - val_loss: 1.5778 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5240 - accuracy: 0.7812\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3561 - accuracy: 0.8529 - val_loss: 1.5295 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8438\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3589 - accuracy: 0.8382 - val_loss: 1.5258 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Using epoch 00011 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6505 - accuracy: 0.5909\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3606 - accuracy: 0.3676\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 1.3606 - accuracy: 0.3676 - val_loss: 1.1534 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8955 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8955 - accuracy: 0.5147 - val_loss: 0.6926 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4906 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.4906 - accuracy: 0.5147 - val_loss: 1.2975 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9627 - accuracy: 0.5147\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9627 - accuracy: 0.5147 - val_loss: 0.8679 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8495 - accuracy: 0.5735\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8495 - accuracy: 0.5735 - val_loss: 1.0243 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9152 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9152 - accuracy: 0.5294 - val_loss: 0.7559 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9722 - accuracy: 0.5588\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9722 - accuracy: 0.5588 - val_loss: 0.8521 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7079 - accuracy: 0.6176\n",
      "Epoch 00008: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7079 - accuracy: 0.6176 - val_loss: 0.6739 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7478 - accuracy: 0.6029 - val_loss: 0.6889 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.6324\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7246 - accuracy: 0.6324 - val_loss: 0.6295 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.6176\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6707 - accuracy: 0.6176 - val_loss: 0.6318 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.6176\n",
      "Epoch 00012: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6314 - accuracy: 0.6176 - val_loss: 0.6318 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.7059\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6365 - accuracy: 0.7059 - val_loss: 0.6271 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.6176\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6510 - accuracy: 0.6176 - val_loss: 0.6512 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.6912\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5443 - accuracy: 0.6912 - val_loss: 0.6424 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.6324\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6330 - accuracy: 0.6324 - val_loss: 0.7140 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7647\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5072 - accuracy: 0.7647 - val_loss: 0.6597 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6433 - accuracy: 0.6471\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6433 - accuracy: 0.6471 - val_loss: 0.7590 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.6765\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5973 - accuracy: 0.6765 - val_loss: 0.6656 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7647\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5734 - accuracy: 0.7647 - val_loss: 0.7494 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7059\n",
      "Epoch 00021: val_accuracy improved from 0.66667 to 0.72222, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5641 - accuracy: 0.7059 - val_loss: 0.6558 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.7059\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5381 - accuracy: 0.7059 - val_loss: 0.7849 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6068 - accuracy: 0.6471\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6068 - accuracy: 0.6471 - val_loss: 0.7065 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.7500\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5411 - accuracy: 0.7500 - val_loss: 0.7708 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4889 - accuracy: 0.7500 - val_loss: 0.8291 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00021 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6266 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8178 - accuracy: 0.3824\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.27778, storing weights.\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 1.8178 - accuracy: 0.3824 - val_loss: 0.8443 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0858 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy improved from 0.27778 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0858 - accuracy: 0.5147 - val_loss: 1.7652 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4417 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.4417 - accuracy: 0.4853 - val_loss: 0.8035 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0511 - accuracy: 0.5000\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0511 - accuracy: 0.5000 - val_loss: 1.1443 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1952 - accuracy: 0.4853\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1952 - accuracy: 0.4853 - val_loss: 0.7660 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0776 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0776 - accuracy: 0.5294 - val_loss: 1.0590 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0594 - accuracy: 0.5000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0594 - accuracy: 0.5000 - val_loss: 0.7405 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8048 - accuracy: 0.6029\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8048 - accuracy: 0.6029 - val_loss: 0.8643 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9001 - accuracy: 0.5735\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9001 - accuracy: 0.5735 - val_loss: 0.7340 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8025 - accuracy: 0.6324\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8025 - accuracy: 0.6324 - val_loss: 0.7939 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.6029\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7415 - accuracy: 0.6029 - val_loss: 0.7276 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.5735\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7182 - accuracy: 0.5735 - val_loss: 0.7491 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.6765\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6791 - accuracy: 0.6765 - val_loss: 0.7126 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7129 - accuracy: 0.6176\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7129 - accuracy: 0.6176 - val_loss: 0.7418 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8784 - accuracy: 0.5882\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8784 - accuracy: 0.5882 - val_loss: 0.7232 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7847 - accuracy: 0.6029\n",
      "Epoch 00016: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7847 - accuracy: 0.6029 - val_loss: 0.7126 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6630 - accuracy: 0.6176\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6630 - accuracy: 0.6176 - val_loss: 0.7122 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.6912\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6209 - accuracy: 0.6912 - val_loss: 0.6820 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.6912\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5796 - accuracy: 0.6912 - val_loss: 0.7458 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.5441\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6670 - accuracy: 0.5441 - val_loss: 0.6564 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.6765\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7409 - accuracy: 0.6765 - val_loss: 0.8068 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.6324\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6194 - accuracy: 0.6324 - val_loss: 0.6761 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7647\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6381 - accuracy: 0.7647 - val_loss: 0.8752 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.7353\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5116 - accuracy: 0.7353 - val_loss: 0.8127 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5172 - accuracy: 0.7500 - val_loss: 0.8564 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00016 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7428 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4828 - accuracy: 0.4531\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 1.6115 - accuracy: 0.4412 - val_loss: 1.9318 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.7340 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.61111, storing weights.\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7535 - accuracy: 0.5147 - val_loss: 0.6041 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7769 - accuracy: 0.5781\n",
      "Epoch 00003: val_accuracy improved from 0.61111 to 0.77778, storing weights.\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8200 - accuracy: 0.5735 - val_loss: 0.6062 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9339 - accuracy: 0.5469\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9207 - accuracy: 0.5588 - val_loss: 0.6838 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9238 - accuracy: 0.5469\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9908 - accuracy: 0.5441 - val_loss: 0.6642 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0740 - accuracy: 0.5156\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0623 - accuracy: 0.5147 - val_loss: 0.6721 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7004 - accuracy: 0.6250\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7060 - accuracy: 0.6176 - val_loss: 1.9686 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9954 - accuracy: 0.5156\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.8878 - accuracy: 0.4853 - val_loss: 0.9495 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7099 - accuracy: 0.6094\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7017 - accuracy: 0.6029 - val_loss: 0.6606 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3308 - accuracy: 0.4844\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.3037 - accuracy: 0.4853 - val_loss: 0.8481 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7076 - accuracy: 0.6250\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7514 - accuracy: 0.6029 - val_loss: 0.6515 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4833 - accuracy: 0.4844\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3728 - accuracy: 0.5000 - val_loss: 0.8082 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5043 - accuracy: 0.7344\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4910 - accuracy: 0.7500 - val_loss: 0.8578 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5035 - accuracy: 0.7969\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4945 - accuracy: 0.7941 - val_loss: 0.8864 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5406 - accuracy: 0.7031\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5594 - accuracy: 0.6765 - val_loss: 0.9475 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5916 - accuracy: 0.6875\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5690 - accuracy: 0.7059 - val_loss: 0.9651 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5703 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5559 - accuracy: 0.7647 - val_loss: 1.0152 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4557 - accuracy: 0.8281\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4725 - accuracy: 0.8088 - val_loss: 1.0818 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5504 - accuracy: 0.7344\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5614 - accuracy: 0.7353 - val_loss: 1.0907 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5204 - accuracy: 0.7344\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5099 - accuracy: 0.7500 - val_loss: 1.1429 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5733 - accuracy: 0.7031\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5598 - accuracy: 0.7206 - val_loss: 1.1386 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5580 - accuracy: 0.6719\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5736 - accuracy: 0.6618 - val_loss: 1.0845 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6303 - accuracy: 0.6094\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6331 - accuracy: 0.6029 - val_loss: 1.0803 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5772 - accuracy: 0.6875\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5694 - accuracy: 0.7059 - val_loss: 1.0764 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5560 - accuracy: 0.7344\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5730 - accuracy: 0.7206 - val_loss: 1.0796 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00003 with val_accuracy: 0.77778\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8124 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5020 - accuracy: 0.6029\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 1.5020 - accuracy: 0.6029 - val_loss: 1.0216 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1181 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1181 - accuracy: 0.4853 - val_loss: 0.7172 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3347 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.3347 - accuracy: 0.5147 - val_loss: 1.1840 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.5000\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9226 - accuracy: 0.5000 - val_loss: 0.8911 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9933 - accuracy: 0.5000\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9933 - accuracy: 0.5000 - val_loss: 1.2785 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9350 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9350 - accuracy: 0.5000 - val_loss: 0.9954 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7723 - accuracy: 0.5588\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7723 - accuracy: 0.5588 - val_loss: 1.0133 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.6618\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6980 - accuracy: 0.6618 - val_loss: 0.8527 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6696 - accuracy: 0.6029 - val_loss: 0.8210 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.6176\n",
      "Epoch 00010: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6224 - accuracy: 0.6176 - val_loss: 0.7202 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5521 - accuracy: 0.7059\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5521 - accuracy: 0.7059 - val_loss: 0.7048 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.7500\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5617 - accuracy: 0.7500 - val_loss: 0.6734 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.6765\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6041 - accuracy: 0.6765 - val_loss: 0.6669 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.6765\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5674 - accuracy: 0.6765 - val_loss: 0.6628 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7206\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - accuracy: 0.7206 - val_loss: 0.6468 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.5735\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6805 - accuracy: 0.5735 - val_loss: 0.7044 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.6029\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7073 - accuracy: 0.6029 - val_loss: 0.6399 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.7059\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6854 - accuracy: 0.7059 - val_loss: 0.7094 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.6912\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4937 - accuracy: 0.6912 - val_loss: 0.6963 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.7794\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4880 - accuracy: 0.7794 - val_loss: 0.7559 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8088\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4224 - accuracy: 0.8088 - val_loss: 0.8040 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.7794\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4815 - accuracy: 0.7794 - val_loss: 0.8948 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.8088\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4423 - accuracy: 0.8088 - val_loss: 0.9262 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.7794\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4686 - accuracy: 0.7794 - val_loss: 1.0576 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8676\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3980 - accuracy: 0.8676 - val_loss: 1.0102 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00010 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2904 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4677 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 1.4677 - accuracy: 0.5000 - val_loss: 1.9195 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6200 - accuracy: 0.4853\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.6200 - accuracy: 0.4853 - val_loss: 3.3357 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2514 - accuracy: 0.5147\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.2514 - accuracy: 0.5147 - val_loss: 1.0750 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3888 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3888 - accuracy: 0.4853 - val_loss: 1.5074 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1382 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.1382 - accuracy: 0.5147 - val_loss: 1.1334 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5736 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5736 - accuracy: 0.4853 - val_loss: 1.0552 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0058 - accuracy: 0.5147\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0058 - accuracy: 0.5147 - val_loss: 1.1191 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6584 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6584 - accuracy: 0.4853 - val_loss: 0.8717 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3612 - accuracy: 0.5147\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3612 - accuracy: 0.5147 - val_loss: 0.9957 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6003 - accuracy: 0.4853\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6003 - accuracy: 0.4853 - val_loss: 0.8436 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8232 - accuracy: 0.5147\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.8232 - accuracy: 0.5147 - val_loss: 0.8744 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6195 - accuracy: 0.4853\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6195 - accuracy: 0.4853 - val_loss: 0.9072 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4487 - accuracy: 0.5147\n",
      "Epoch 00013: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4487 - accuracy: 0.5147 - val_loss: 0.6992 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3196 - accuracy: 0.5147\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3196 - accuracy: 0.5147 - val_loss: 1.0837 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1759 - accuracy: 0.5441\n",
      "Epoch 00015: val_accuracy improved from 0.61111 to 0.72222, storing weights.\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1759 - accuracy: 0.5441 - val_loss: 0.6103 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3004 - accuracy: 0.5735\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3004 - accuracy: 0.5735 - val_loss: 1.3544 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2827 - accuracy: 0.5147\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2827 - accuracy: 0.5147 - val_loss: 0.6188 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2698 - accuracy: 0.5441\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2698 - accuracy: 0.5441 - val_loss: 1.4745 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.5882\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9140 - accuracy: 0.5882 - val_loss: 0.7460 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9500 - accuracy: 0.6471\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9500 - accuracy: 0.6471 - val_loss: 1.8585 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.6471\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8471 - accuracy: 0.6471 - val_loss: 0.9423 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.6029\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0692 - accuracy: 0.6029 - val_loss: 2.2454 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9176 - accuracy: 0.6029\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9176 - accuracy: 0.6029 - val_loss: 1.0910 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9632 - accuracy: 0.6765\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9632 - accuracy: 0.6765 - val_loss: 2.4650 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8047 - accuracy: 0.6324\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8047 - accuracy: 0.6324 - val_loss: 1.1738 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00015 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7532 - accuracy: 0.5909\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3631 - accuracy: 0.3824\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 1.3631 - accuracy: 0.3824 - val_loss: 0.9949 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.5882\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7218 - accuracy: 0.5882 - val_loss: 0.8066 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8580 - accuracy: 0.5882\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8580 - accuracy: 0.5882 - val_loss: 1.8981 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0922 - accuracy: 0.4853\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.0922 - accuracy: 0.4853 - val_loss: 0.7959 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9877 - accuracy: 0.5441\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9877 - accuracy: 0.5441 - val_loss: 1.4389 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1598 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1598 - accuracy: 0.5294 - val_loss: 0.8455 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.6029\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7514 - accuracy: 0.6029 - val_loss: 1.0118 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8058 - accuracy: 0.5882\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8058 - accuracy: 0.5882 - val_loss: 0.7159 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.6618\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6638 - accuracy: 0.6618 - val_loss: 0.7507 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.6618\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6783 - accuracy: 0.6618 - val_loss: 0.6393 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.5588\n",
      "Epoch 00011: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7971 - accuracy: 0.5588 - val_loss: 0.6671 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7211 - accuracy: 0.6176\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7211 - accuracy: 0.6176 - val_loss: 0.6512 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.6176\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6276 - accuracy: 0.6176 - val_loss: 0.6356 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.6324\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6670 - accuracy: 0.6324 - val_loss: 0.6898 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4969 - accuracy: 0.7353\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4969 - accuracy: 0.7353 - val_loss: 0.6633 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.7353\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6079 - accuracy: 0.7353 - val_loss: 0.7579 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7206\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5667 - accuracy: 0.7206 - val_loss: 0.7056 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7079 - accuracy: 0.6618\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7079 - accuracy: 0.6618 - val_loss: 0.8376 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.6324\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6073 - accuracy: 0.6324 - val_loss: 0.6917 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6724 - accuracy: 0.6765\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6724 - accuracy: 0.6765 - val_loss: 0.7643 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7059\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5531 - accuracy: 0.7059 - val_loss: 0.6926 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6500 - accuracy: 0.7206\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6500 - accuracy: 0.7206 - val_loss: 0.8516 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6014 - accuracy: 0.7059\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6014 - accuracy: 0.7059 - val_loss: 0.7104 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.6912\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6750 - accuracy: 0.6912 - val_loss: 0.7885 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7353\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5482 - accuracy: 0.7353 - val_loss: 0.8614 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Using epoch 00011 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3073 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4984 - accuracy: 0.4412\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 1.4984 - accuracy: 0.4412 - val_loss: 0.9164 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8985 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8985 - accuracy: 0.5147 - val_loss: 4.1403 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6872 - accuracy: 0.4853\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6872 - accuracy: 0.4853 - val_loss: 0.7294 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy improved from 0.55556 to 0.72222, storing weights.\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7082 - accuracy: 0.5735 - val_loss: 0.5778 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8772 - accuracy: 0.5294\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8772 - accuracy: 0.5294 - val_loss: 2.0493 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8371 - accuracy: 0.4853\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.8371 - accuracy: 0.4853 - val_loss: 0.9890 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4515 - accuracy: 0.5147\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.4515 - accuracy: 0.5147 - val_loss: 1.6872 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9644 - accuracy: 0.4853\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.9644 - accuracy: 0.4853 - val_loss: 0.7415 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8434 - accuracy: 0.5147\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.8434 - accuracy: 0.5147 - val_loss: 1.4299 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2669 - accuracy: 0.4853\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2669 - accuracy: 0.4853 - val_loss: 0.7091 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5432 - accuracy: 0.5294\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5432 - accuracy: 0.5294 - val_loss: 1.0280 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8291 - accuracy: 0.4853\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8291 - accuracy: 0.4853 - val_loss: 0.8604 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5010 - accuracy: 0.5147\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5010 - accuracy: 0.5147 - val_loss: 0.8018 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6821 - accuracy: 0.5294\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.6821 - accuracy: 0.5294 - val_loss: 0.8944 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1262 - accuracy: 0.5441\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1262 - accuracy: 0.5441 - val_loss: 0.9792 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8951 - accuracy: 0.6029\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8951 - accuracy: 0.6029 - val_loss: 1.0764 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.6471\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6935 - accuracy: 0.6471 - val_loss: 1.1740 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.6471\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7458 - accuracy: 0.6471 - val_loss: 1.2772 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7206\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5660 - accuracy: 0.7206 - val_loss: 1.3788 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7353\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5215 - accuracy: 0.7353 - val_loss: 1.4704 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.7206\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5789 - accuracy: 0.7206 - val_loss: 1.5413 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6164 - accuracy: 0.7206\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - accuracy: 0.7206 - val_loss: 1.6101 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.7647\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5066 - accuracy: 0.7647 - val_loss: 1.6943 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.7353\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4761 - accuracy: 0.7353 - val_loss: 1.7553 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7353\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5032 - accuracy: 0.7353 - val_loss: 1.8191 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00004 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6265 - accuracy: 0.6818\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0221 - accuracy: 0.4844\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 1s 150ms/step - loss: 1.9999 - accuracy: 0.4706 - val_loss: 0.7135 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1530 - accuracy: 0.5312\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1718 - accuracy: 0.5294 - val_loss: 0.7333 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7555 - accuracy: 0.5625\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7474 - accuracy: 0.5735 - val_loss: 0.7173 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6725 - accuracy: 0.6562\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6850 - accuracy: 0.6471 - val_loss: 0.7593 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0666 - accuracy: 0.4688\n",
      "Epoch 00005: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0826 - accuracy: 0.4559 - val_loss: 0.6641 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8389 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8310 - accuracy: 0.5000 - val_loss: 0.6778 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7443 - accuracy: 0.5625\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7636 - accuracy: 0.5441 - val_loss: 0.8768 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4141 - accuracy: 0.5156\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.3699 - accuracy: 0.5147 - val_loss: 0.7258 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6705 - accuracy: 0.5781\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6733 - accuracy: 0.5882 - val_loss: 0.7954 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7707 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7583 - accuracy: 0.5147 - val_loss: 0.9022 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7915 - accuracy: 0.5312\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7745 - accuracy: 0.5294 - val_loss: 0.7420 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0965 - accuracy: 0.5000\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0747 - accuracy: 0.5147 - val_loss: 0.8976 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6430 - accuracy: 0.6250\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6692 - accuracy: 0.6176 - val_loss: 0.8526 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7452 - accuracy: 0.5781\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7541 - accuracy: 0.5735 - val_loss: 0.8207 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6337 - accuracy: 0.6719\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6456 - accuracy: 0.6618 - val_loss: 0.8719 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7001 - accuracy: 0.5000\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6987 - accuracy: 0.5147 - val_loss: 0.8928 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6262 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6128 - accuracy: 0.7500 - val_loss: 0.9053 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7699 - accuracy: 0.5000\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7731 - accuracy: 0.5000 - val_loss: 0.9380 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7322 - accuracy: 0.5000\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7147 - accuracy: 0.5147 - val_loss: 0.9529 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7205 - accuracy: 0.6094\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7047 - accuracy: 0.6176 - val_loss: 0.9690 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6454 - accuracy: 0.6719\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6488 - accuracy: 0.6618 - val_loss: 0.9880 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7114 - accuracy: 0.5469\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7276 - accuracy: 0.5294 - val_loss: 1.0048 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6695 - accuracy: 0.6562\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6569 - accuracy: 0.6618 - val_loss: 0.9975 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6220 - accuracy: 0.6094\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6158 - accuracy: 0.6029 - val_loss: 0.9994 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7291 - accuracy: 0.5781\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7112 - accuracy: 0.5882 - val_loss: 0.9958 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Using epoch 00005 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0404 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5200 - accuracy: 0.4062\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 1.5500 - accuracy: 0.3971 - val_loss: 1.9619 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.8511 - accuracy: 0.5156\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.66667, storing weights.\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7548 - accuracy: 0.5147 - val_loss: 0.6360 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9628 - accuracy: 0.4844\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0347 - accuracy: 0.4853 - val_loss: 0.6511 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2230 - accuracy: 0.5312\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1828 - accuracy: 0.5441 - val_loss: 0.8348 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1432 - accuracy: 0.5312\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1795 - accuracy: 0.5294 - val_loss: 0.6668 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0289 - accuracy: 0.5312\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0730 - accuracy: 0.5147 - val_loss: 0.7462 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6434 - accuracy: 0.6094\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6695 - accuracy: 0.5735 - val_loss: 2.0037 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.0217 - accuracy: 0.5156\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.8710 - accuracy: 0.5294 - val_loss: 1.1062 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7867 - accuracy: 0.5781\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7670 - accuracy: 0.5882 - val_loss: 0.8252 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6494 - accuracy: 0.6719\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6775 - accuracy: 0.6618 - val_loss: 0.6963 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3075 - accuracy: 0.5000\n",
      "Epoch 00011: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.3722 - accuracy: 0.4706 - val_loss: 0.6402 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2739 - accuracy: 0.4844\n",
      "Epoch 00012: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1968 - accuracy: 0.4853 - val_loss: 1.3249 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6025 - accuracy: 0.6250\n",
      "Epoch 00013: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5896 - accuracy: 0.6324 - val_loss: 1.3790 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6162 - accuracy: 0.6875\n",
      "Epoch 00014: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6133 - accuracy: 0.6912 - val_loss: 1.4120 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6684 - accuracy: 0.6406\n",
      "Epoch 00015: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6485 - accuracy: 0.6618 - val_loss: 1.4046 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5648 - accuracy: 0.7031\n",
      "Epoch 00016: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5844 - accuracy: 0.6912 - val_loss: 1.4118 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5761 - accuracy: 0.6562\n",
      "Epoch 00017: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5624 - accuracy: 0.6765 - val_loss: 1.4953 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5775 - accuracy: 0.7344\n",
      "Epoch 00018: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5944 - accuracy: 0.7206 - val_loss: 1.5741 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6845 - accuracy: 0.5938\n",
      "Epoch 00019: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6701 - accuracy: 0.6029 - val_loss: 1.5266 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5045 - accuracy: 0.7344\n",
      "Epoch 00020: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5031 - accuracy: 0.7206 - val_loss: 1.6155 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5027 - accuracy: 0.7188\n",
      "Epoch 00021: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5056 - accuracy: 0.7206 - val_loss: 1.6403 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6012 - accuracy: 0.6094\n",
      "Epoch 00022: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6189 - accuracy: 0.5882 - val_loss: 1.5732 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5885 - accuracy: 0.6875\n",
      "Epoch 00023: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5694 - accuracy: 0.7059 - val_loss: 1.5731 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5333 - accuracy: 0.7500\n",
      "Epoch 00024: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5509 - accuracy: 0.7500 - val_loss: 1.5663 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4841 - accuracy: 0.7500\n",
      "Epoch 00025: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4984 - accuracy: 0.7353 - val_loss: 1.5518 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
      "Using epoch 00002 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7714 - accuracy: 0.5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in [FatigueMI]:\n",
    "    for model in [\"deep_conv_net\"]:\n",
    "        model_optimizer = ModelOptimizer(\n",
    "            dataset=dataset(),\n",
    "            model_name=model\n",
    "        )\n",
    "        for subject in [11]:\n",
    "            max_epochs = MODELS_HYPERPARAMS_DICT[model][\"max_epochs\"]\n",
    "            study = model_optimizer.search_best_model(\n",
    "                subjects = [subject],\n",
    "                max_iter = 25,\n",
    "                max_epochs = max_epochs,\n",
    "                max_stag_count = 10,\n",
    "                rounds = 1,\n",
    "                replace_previous_study_for_subjects = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.168301</td>\n",
       "      <td>0.483761</td>\n",
       "      <td>0.680379</td>\n",
       "      <td>0.196618</td>\n",
       "      <td>1.255373</td>\n",
       "      <td>0.151985</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, T5, O2, ...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.575806</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>[P3, Fz, P4, Cz, T3, T5, O2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.057190</td>\n",
       "      <td>0.477276</td>\n",
       "      <td>0.602562</td>\n",
       "      <td>0.125286</td>\n",
       "      <td>2.556679</td>\n",
       "      <td>0.327611</td>\n",
       "      <td>[P3, C3, Fz, F4, Fp1, O1, F8, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>0.516096</td>\n",
       "      <td>0.679674</td>\n",
       "      <td>0.163578</td>\n",
       "      <td>1.063509</td>\n",
       "      <td>0.361561</td>\n",
       "      <td>[F3, Fz, F4, C4, T3, T5, F8, A2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>224</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>0.647678</td>\n",
       "      <td>0.059285</td>\n",
       "      <td>0.793769</td>\n",
       "      <td>0.361611</td>\n",
       "      <td>[P3, C3, Fz, F4, P4, Cz, Fp1, Fp2, T3, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.515996</td>\n",
       "      <td>0.632985</td>\n",
       "      <td>0.116990</td>\n",
       "      <td>2.764858</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>[P3, Fz, F4, Pz, Fp1, T3, T5, O2, F8, A2, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.590550</td>\n",
       "      <td>0.681202</td>\n",
       "      <td>0.090652</td>\n",
       "      <td>1.409137</td>\n",
       "      <td>0.401685</td>\n",
       "      <td>[F3, F4, P4, Pz, Fp2, T3, O1, F8, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0.543822</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>1.162843</td>\n",
       "      <td>0.401785</td>\n",
       "      <td>[P3, F3, C4, P4, Cz, Fp2, T3, O1, O2, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.179739</td>\n",
       "      <td>0.529332</td>\n",
       "      <td>0.704364</td>\n",
       "      <td>0.175032</td>\n",
       "      <td>0.644767</td>\n",
       "      <td>0.447931</td>\n",
       "      <td>[P3, Fz, F4, Fp1, Fp2, T3, O2, F7]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>0.583539</td>\n",
       "      <td>0.700953</td>\n",
       "      <td>0.117414</td>\n",
       "      <td>0.761109</td>\n",
       "      <td>0.448031</td>\n",
       "      <td>[P3, C3, Fz, P4, Cz, T5, F7, A2, T6, T4]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.485691</td>\n",
       "      <td>0.704912</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>1.714506</td>\n",
       "      <td>0.448181</td>\n",
       "      <td>[C3, F3, C4, Cz, Pz, Fp2, T5, O1, O2, F7, F8, ...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>96</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff  train_loss  val_loss  \\\n",
       "0    0.779412  0.545455  0.611111            0.168301    0.483761  0.680379   \n",
       "1    0.779412  0.681818  0.777778            0.001634    0.451416  0.575806   \n",
       "5    0.779412  0.681818  0.722222            0.057190    0.477276  0.602562   \n",
       "4    0.779412  0.545455  0.666667            0.112745    0.516096  0.679674   \n",
       "7    0.705882  0.500000  0.666667            0.039216    0.588393  0.647678   \n",
       "9    0.720588  0.590909  0.666667            0.053922    0.515996  0.632985   \n",
       "2    0.661765  0.545455  0.611111            0.050654    0.590550  0.681202   \n",
       "3    0.720588  0.500000  0.611111            0.109477    0.543822  0.628700   \n",
       "8    0.735294  0.590909  0.555556            0.179739    0.529332  0.704364   \n",
       "6    0.661765  0.500000  0.555556            0.106209    0.583539  0.700953   \n",
       "10   0.764706  0.500000  0.555556            0.209150    0.485691  0.704912   \n",
       "\n",
       "    train_val_loss_diff  test_loss    scores  \\\n",
       "0              0.196618   1.255373  0.151985   \n",
       "1              0.124390   0.658583  0.299783   \n",
       "5              0.125286   2.556679  0.327611   \n",
       "4              0.163578   1.063509  0.361561   \n",
       "7              0.059285   0.793769  0.361611   \n",
       "9              0.116990   2.764858  0.361711   \n",
       "2              0.090652   1.409137  0.401685   \n",
       "3              0.084878   1.162843  0.401785   \n",
       "8              0.175032   0.644767  0.447931   \n",
       "6              0.117414   0.761109  0.448031   \n",
       "10             0.219221   1.714506  0.448181   \n",
       "\n",
       "                                    channels_selected  sfreq  batch_size  \\\n",
       "0   [P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, T5, O2, ...  128.0         160   \n",
       "1                    [P3, Fz, P4, Cz, T3, T5, O2, T6]  256.0          32   \n",
       "5               [P3, C3, Fz, F4, Fp1, O1, F8, T6, T4]  300.0         128   \n",
       "4                [F3, Fz, F4, C4, T3, T5, F8, A2, T6]  256.0         224   \n",
       "7          [P3, C3, Fz, F4, P4, Cz, Fp1, Fp2, T3, T6]  128.0         256   \n",
       "9   [P3, Fz, F4, Pz, Fp1, T3, T5, O2, F8, A2, T6, T4]  300.0         256   \n",
       "2               [F3, F4, P4, Pz, Fp2, T3, O1, F8, A2]  256.0         160   \n",
       "3       [P3, F3, C4, P4, Cz, Fp2, T3, O1, O2, F8, T6]  128.0         192   \n",
       "8                  [P3, Fz, F4, Fp1, Fp2, T3, O2, F7]  128.0         192   \n",
       "6            [P3, C3, Fz, P4, Cz, T5, F7, A2, T6, T4]  128.0          64   \n",
       "10  [C3, F3, C4, Cz, Pz, Fp2, T5, O1, O2, F7, F8, ...  128.0          96   \n",
       "\n",
       "       model_name subjects  \n",
       "0   deep_conv_net     [11]  \n",
       "1   deep_conv_net     [11]  \n",
       "5   deep_conv_net     [11]  \n",
       "4   deep_conv_net     [11]  \n",
       "7   deep_conv_net     [11]  \n",
       "9   deep_conv_net     [11]  \n",
       "2   deep_conv_net     [11]  \n",
       "3   deep_conv_net     [11]  \n",
       "8   deep_conv_net     [11]  \n",
       "6   deep_conv_net     [11]  \n",
       "10  deep_conv_net     [11]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_optimizer.get_study_metrics(study).sort_values(by=\"scores\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[1;36m128\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m160\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test_accuracy = \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6111111044883728</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val_accuracy = \u001b[1;36m0.6111111044883728\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">channels_selected = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'P3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'C3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'C4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Cz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Pz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fp2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T5'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'O2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F8'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'A2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T6'</span>\n",
       " <span style=\"color: #008000; text-decoration-color: #008000\">'T4'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "channels_selected = \u001b[1m[\u001b[0m\u001b[32m'P3'\u001b[0m \u001b[32m'C3'\u001b[0m \u001b[32m'F3'\u001b[0m \u001b[32m'Fz'\u001b[0m \u001b[32m'F4'\u001b[0m \u001b[32m'C4'\u001b[0m \u001b[32m'Cz'\u001b[0m \u001b[32m'Pz'\u001b[0m \u001b[32m'Fp2'\u001b[0m \u001b[32m'T5'\u001b[0m \u001b[32m'O2'\u001b[0m \u001b[32m'F8'\u001b[0m \u001b[32m'A2'\u001b[0m \u001b[32m'T6'\u001b[0m\n",
       " \u001b[32m'T4'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint({ k: v for k, v in study.best_trial.params.items() if not k.startswith(\"channels\") })\n",
    "rprint(\"test_accuracy =\", study.best_trial.user_attrs[\"trial_data\"][\"test_accuracy\"])\n",
    "rprint(\"val_accuracy =\", np.max(study.best_trial.user_attrs[\"trial_data\"][\"val_accuracy\"]))\n",
    "rprint(\"channels_selected =\", study.best_trial.user_attrs[\"trial_data\"][\"channels_selected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fatigue_mi_studies = glob.glob(\"./temp/FatigueMI/**/**/model/*_study.npy\") + glob.glob(\"./temp/FatigueMI/**/**/model/shallow_conv_net_study_best_trial.npy\")\n",
    "temp_fatigue_mi_studies_dict = {}\n",
    "temp_fatigue_mi_studies_file_names_dict = {}\n",
    "\n",
    "for study_file in temp_fatigue_mi_studies:\n",
    "    study = np.load(study_file, allow_pickle=True).item()\n",
    "    subject_number = int(study_file.split(\"[\")[1].split(']')[0])\n",
    "    model_name = study_file.split(\"/\")[-1].replace(\"_study.npy\", \"\").replace(\"shallow_conv_net_study_best_trial.npy\", \"shallow_conv_net\")\n",
    "    temp_fatigue_mi_studies_dict[f\"{subject_number}_{model_name}\"] = study\n",
    "    temp_fatigue_mi_studies_file_names_dict[f\"{subject_number}_{model_name}\"] = study_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>1.209507</td>\n",
       "      <td>1.407622</td>\n",
       "      <td>0.198116</td>\n",
       "      <td>1.633958</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>1.353778</td>\n",
       "      <td>1.540807</td>\n",
       "      <td>0.187029</td>\n",
       "      <td>1.678117</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.157701</td>\n",
       "      <td>0.673368</td>\n",
       "      <td>0.198031</td>\n",
       "      <td>[P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.595995</td>\n",
       "      <td>0.62438</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.578216</td>\n",
       "      <td>0.327611</td>\n",
       "      <td>[P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200980</td>\n",
       "      <td>84.76915</td>\n",
       "      <td>82.498848</td>\n",
       "      <td>2.270302</td>\n",
       "      <td>90.271187</td>\n",
       "      <td>0.111561</td>\n",
       "      <td>[F3, Fz, F4, Fp2, T3, T5, F7, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>224</td>\n",
       "      <td>lstm_cnn_net</td>\n",
       "      <td>[9]</td>\n",
       "      <td>./temp/FatigueMI/[9]/4f2b98dbeb684bfa8f887b396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>0.580237</td>\n",
       "      <td>0.42945</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.791186</td>\n",
       "      <td>[P3, C3, F4, C4, Pz, Fp1, O1, F8, A2, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[13]</td>\n",
       "      <td>./temp/FatigueMI/[13]/1b189965ada44ff99e73fa14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.259804</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.901306</td>\n",
       "      <td>[P3, C3, F4, C4, P4, Pz, Fp2, T3, O2]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[5]</td>\n",
       "      <td>./temp/FatigueMI/[5]/d199c9c2ac924b238693f158e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.189622</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.414381</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, T5, O2, F7, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[12]</td>\n",
       "      <td>./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.878924</td>\n",
       "      <td>[P3, C3, Fz, C4, Fp1, Fp2, T3, O1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[8]</td>\n",
       "      <td>./temp/FatigueMI/[8]/9fd82ec44ef3496da6307b57e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>[C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>[4]</td>\n",
       "      <td>./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_number  train_acc  test_acc   val_acc  train_val_acc_diff  \\\n",
       "19            19   0.838235  0.818182  0.722222            0.116013   \n",
       "22            22   0.794118  0.818182  0.722222            0.071895   \n",
       "7              7   0.573529  0.545455  0.555556            0.017974   \n",
       "13            13   0.691176  0.863636  0.722222            0.031046   \n",
       "18            18   0.867647  0.545455  0.666667            0.200980   \n",
       "..           ...        ...       ...       ...                 ...   \n",
       "0              0   1.000000  0.636364  0.833333            0.166667   \n",
       "0              0   0.926471  0.636364  0.666667            0.259804   \n",
       "0              0   1.000000  0.772727  0.888889            0.111111   \n",
       "0              0   1.000000  0.636364  0.722222            0.277778   \n",
       "0              0   1.000000  0.863636  0.888889            0.111111   \n",
       "\n",
       "   train_loss   val_loss train_val_loss_diff  test_loss    scores  \\\n",
       "19   1.209507   1.407622            0.198116   1.633958  0.077361   \n",
       "22   1.353778   1.540807            0.187029   1.678117  0.077361   \n",
       "7    0.812133   0.654432            0.157701   0.673368  0.198031   \n",
       "13   0.595995    0.62438            0.028385   0.578216  0.327611   \n",
       "18   84.76915  82.498848            2.270302  90.271187  0.111561   \n",
       "..        ...        ...                 ...        ...       ...   \n",
       "0    0.150787   0.580237             0.42945   0.998291  0.791186   \n",
       "0        None       None                None       None  0.901306   \n",
       "0    0.189622   0.604003            0.414381   0.733969  0.665729   \n",
       "0        None       None                None       None  0.878924   \n",
       "0        None       None                None       None  0.520520   \n",
       "\n",
       "                                    channels_selected  sfreq batch_size  \\\n",
       "19                                   [C3, Fz, T6, T4]  256.0        192   \n",
       "22                                   [C3, Fz, T6, T4]  256.0        160   \n",
       "7           [P3, C3, C4, Pz, Fp1, T3, O1, O2, F8, T6]  128.0        256   \n",
       "13              [P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]  128.0        192   \n",
       "18              [F3, Fz, F4, Fp2, T3, T5, F7, A2, T4]  256.0        224   \n",
       "..                                                ...    ...        ...   \n",
       "0           [P3, C3, F4, C4, Pz, Fp1, O1, F8, A2, T6]   None       None   \n",
       "0               [P3, C3, F4, C4, P4, Pz, Fp2, T3, O2]   None       None   \n",
       "0                [P3, C3, F3, C4, Cz, T5, O2, F7, T6]   None       None   \n",
       "0                  [P3, C3, Fz, C4, Fp1, Fp2, T3, O1]   None       None   \n",
       "0   [C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...   None       None   \n",
       "\n",
       "          model_name subjects  \\\n",
       "19           eeg_net      [9]   \n",
       "22           eeg_net      [9]   \n",
       "7      deep_conv_net      [9]   \n",
       "13     deep_conv_net      [9]   \n",
       "18      lstm_cnn_net      [9]   \n",
       "..               ...      ...   \n",
       "0   shallow_conv_net     [13]   \n",
       "0   shallow_conv_net      [5]   \n",
       "0   shallow_conv_net     [12]   \n",
       "0   shallow_conv_net      [8]   \n",
       "0   shallow_conv_net      [4]   \n",
       "\n",
       "                                            file_path  \n",
       "19  ./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...  \n",
       "22  ./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...  \n",
       "7   ./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...  \n",
       "13  ./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...  \n",
       "18  ./temp/FatigueMI/[9]/4f2b98dbeb684bfa8f887b396...  \n",
       "..                                                ...  \n",
       "0   ./temp/FatigueMI/[13]/1b189965ada44ff99e73fa14...  \n",
       "0   ./temp/FatigueMI/[5]/d199c9c2ac924b238693f158e...  \n",
       "0   ./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...  \n",
       "0   ./temp/FatigueMI/[8]/9fd82ec44ef3496da6307b57e...  \n",
       "0   ./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...  \n",
       "\n",
       "[85 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_study_trials_concat_df = pd.DataFrame()\n",
    "\n",
    "for subject_model in temp_fatigue_mi_studies_dict:\n",
    "    study = temp_fatigue_mi_studies_dict[subject_model]\n",
    "    study_trials_df = model_optimizer.get_study_metrics(study, **{ \n",
    "        \"default_model_name\": \"shallow_conv_net\", \n",
    "        \"subjects\": [subject_model.split(\"_\")[0]],\n",
    "        \"file_path\": temp_fatigue_mi_studies_file_names_dict[subject_model],\n",
    "    })\n",
    "    # Filter: Top 10 best scores -> Max training accuracy -> Minimum difference between training and validation accuracy -> Max test accuracy = best model\n",
    "    filtered_study_trials_df = study_trials_df.copy()\n",
    "    filtered_study_trials_df = filtered_study_trials_df.nsmallest(2, 'scores')\n",
    "    # filtered_study_trials_df = filtered_study_trials_df.nsmallest(5, 'train_val_acc_diff')\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['train_acc'] == max(filtered_study_trials_df['train_acc'])]\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['train_val_acc_diff'] == min(filtered_study_trials_df['train_val_acc_diff'])]\n",
    "    # filtered_study_trials_df = filtered_study_trials_df[filtered_study_trials_df['test_acc'] == max(filtered_study_trials_df['test_acc'])]\n",
    "    # Add column trial_number to filtered_study_trials_df\n",
    "    filtered_study_trials_df.insert(0, 'trial_number', filtered_study_trials_df.index)\n",
    "    filtered_study_trials_concat_df = pd.concat([filtered_study_trials_concat_df, filtered_study_trials_df])\n",
    "display(filtered_study_trials_concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'9'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'11'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'12'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'4'\u001b[0m, \u001b[32m'6'\u001b[0m, \u001b[32m'9'\u001b[0m, \u001b[32m'11'\u001b[0m, \u001b[32m'12'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.575806</td>\n",
       "      <td>0.12439</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>[P3, Fz, P4, Cz, T3, T5, O2, T6]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.755424</td>\n",
       "      <td>1.030562</td>\n",
       "      <td>0.275138</td>\n",
       "      <td>1.222213</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>[P3, C3, F3, Fz, P4, Cz, T3, T5, O1, F7, F8, A...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/6772e2405e6e436faba83820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.277274</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.853020</td>\n",
       "      <td>[P3, C3, Fz, F4, C4, P4, F7, F8]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>[C3, F3, C4, Cz, Fp2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.305321</td>\n",
       "      <td>0.739283</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, Pz, Fp2]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.189622</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.414381</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>[P3, C3, F3, C4, Cz, T5, O2, F7, T6]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.746527</td>\n",
       "      <td>0.32044</td>\n",
       "      <td>0.510645</td>\n",
       "      <td>0.111411</td>\n",
       "      <td>[F3, P4, Pz, F7, F8, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>4</td>\n",
       "      <td>./temp/FatigueMI/[4]/52166a0614d541acb9b9ef965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.233660</td>\n",
       "      <td>0.718789</td>\n",
       "      <td>1.110411</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>1.152245</td>\n",
       "      <td>0.077561</td>\n",
       "      <td>[C3, F3, P4, Cz, Pz, T3, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>4</td>\n",
       "      <td>./temp/FatigueMI/[4]/72578c4a27b64a8e989fd9072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>[C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>4</td>\n",
       "      <td>./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.118139</td>\n",
       "      <td>0.673557</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>6</td>\n",
       "      <td>./temp/FatigueMI/[6]/0614f3b1603b4442a2cc79ade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.233660</td>\n",
       "      <td>0.831503</td>\n",
       "      <td>0.940101</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.985933</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>[P3, F3, Fz, Cz, Pz, Fp1, F7, A2, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>6</td>\n",
       "      <td>./temp/FatigueMI/[6]/969f098d0f9344e5baa14cc42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.522768</td>\n",
       "      <td>1.17613</td>\n",
       "      <td>0.653362</td>\n",
       "      <td>2.52356</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, Cz, T3, T5, O1, F8, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>6</td>\n",
       "      <td>./temp/FatigueMI/[6]/7ec6d62fc9a84597a65261efc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>13</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.595995</td>\n",
       "      <td>0.62438</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.578216</td>\n",
       "      <td>0.327611</td>\n",
       "      <td>[P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>9</td>\n",
       "      <td>./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>1.209507</td>\n",
       "      <td>1.407622</td>\n",
       "      <td>0.198116</td>\n",
       "      <td>1.633958</td>\n",
       "      <td>0.077361</td>\n",
       "      <td>[C3, Fz, T6, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>9</td>\n",
       "      <td>./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.080062</td>\n",
       "      <td>0.289237</td>\n",
       "      <td>0.209175</td>\n",
       "      <td>0.342057</td>\n",
       "      <td>0.418946</td>\n",
       "      <td>[P3, C3, F3, Fz, F4, C4, P4, Pz, Fp1, T5, O2, A2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>9</td>\n",
       "      <td>./temp/FatigueMI/[9]/63a8c87ffc02471893db5ac9a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_number  train_acc  test_acc   val_acc  train_val_acc_diff  \\\n",
       "8              1   0.779412  0.681818  0.777778            0.001634   \n",
       "9              3   0.970588  0.681818  0.722222            0.248366   \n",
       "11             0   0.941176  0.727273  0.666667            0.274510   \n",
       "12            23   0.852941  0.727273  0.888889            0.035948   \n",
       "13            15   0.955882  0.818182  0.833333            0.122549   \n",
       "15             0   1.000000  0.772727  0.888889            0.111111   \n",
       "26            19   0.823529  0.818182  0.666667            0.156863   \n",
       "27            11   0.955882  0.818182  0.722222            0.233660   \n",
       "28             0   1.000000  0.863636  0.888889            0.111111   \n",
       "33             2   0.705882  0.681818  0.666667            0.039216   \n",
       "34            10   0.955882  0.636364  0.722222            0.233660   \n",
       "36             5   1.000000  0.727273  0.888889            0.111111   \n",
       "45            13   0.691176  0.863636  0.722222            0.031046   \n",
       "46            19   0.838235  0.818182  0.722222            0.116013   \n",
       "48             0   1.000000  0.909091  0.944444            0.055556   \n",
       "\n",
       "   train_loss  val_loss train_val_loss_diff test_loss    scores  \\\n",
       "8    0.451416  0.575806             0.12439  0.658583  0.299783   \n",
       "9    0.755424  1.030562            0.275138  1.222213  0.077861   \n",
       "11   0.501189  0.778463            0.277274  0.757358  0.853020   \n",
       "12   0.388678  0.429204            0.040526  0.646307  0.262646   \n",
       "13   0.432221  0.737542            0.305321  0.739283  0.028128   \n",
       "15   0.189622  0.604003            0.414381  0.733969  0.665729   \n",
       "26   0.426087  0.746527             0.32044  0.510645  0.111411   \n",
       "27   0.718789  1.110411            0.391622  1.152245  0.077561   \n",
       "28       None      None                None      None  0.520520   \n",
       "33   0.572419  0.690558            0.118139  0.673557  0.111661   \n",
       "34   0.831503  0.940101            0.108597  0.985933  0.077661   \n",
       "36   0.522768   1.17613            0.653362   2.52356  0.012896   \n",
       "45   0.595995   0.62438            0.028385  0.578216  0.327611   \n",
       "46   1.209507  1.407622            0.198116  1.633958  0.077361   \n",
       "48   0.080062  0.289237            0.209175  0.342057  0.418946   \n",
       "\n",
       "                                    channels_selected  sfreq batch_size  \\\n",
       "8                    [P3, Fz, P4, Cz, T3, T5, O2, T6]  256.0         32   \n",
       "9   [P3, C3, F3, Fz, P4, Cz, T3, T5, O1, F7, F8, A...  256.0        256   \n",
       "11                   [P3, C3, Fz, F4, C4, P4, F7, F8]    NaN       None   \n",
       "12                          [C3, F3, C4, Cz, Fp2, T6]  128.0        128   \n",
       "13                      [P3, C3, F3, C4, Cz, Pz, Fp2]  128.0         32   \n",
       "15               [P3, C3, F3, C4, Cz, T5, O2, F7, T6]   None       None   \n",
       "26                           [F3, P4, Pz, F7, F8, A2]  300.0         32   \n",
       "27                   [C3, F3, P4, Cz, Pz, T3, T6, T4]  256.0        160   \n",
       "28  [C3, F3, F4, P4, Cz, Fp1, Fp2, T5, O2, A2, T6,...   None       None   \n",
       "33      [P3, C3, F3, Fz, F4, C4, Cz, Pz, Fp2, O1, T4]  300.0         64   \n",
       "34          [P3, F3, Fz, Cz, Pz, Fp1, F7, A2, T6, T4]  256.0         32   \n",
       "36       [P3, C3, F3, Fz, F4, Cz, T3, T5, O1, F8, A2]  256.0         32   \n",
       "45              [P3, C3, P4, Pz, Fp1, T3, T5, A2, T6]  128.0        192   \n",
       "46                                   [C3, Fz, T6, T4]  256.0        192   \n",
       "48  [P3, C3, F3, Fz, F4, C4, P4, Pz, Fp1, T5, O2, A2]    NaN       None   \n",
       "\n",
       "          model_name subjects  \\\n",
       "8      deep_conv_net       11   \n",
       "9            eeg_net       11   \n",
       "11  shallow_conv_net       11   \n",
       "12     deep_conv_net       12   \n",
       "13           eeg_net       12   \n",
       "15  shallow_conv_net       12   \n",
       "26     deep_conv_net        4   \n",
       "27           eeg_net        4   \n",
       "28  shallow_conv_net        4   \n",
       "33     deep_conv_net        6   \n",
       "34           eeg_net        6   \n",
       "36  shallow_conv_net        6   \n",
       "45     deep_conv_net        9   \n",
       "46           eeg_net        9   \n",
       "48  shallow_conv_net        9   \n",
       "\n",
       "                                            file_path  \n",
       "8   ./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...  \n",
       "9   ./temp/FatigueMI/[11]/6772e2405e6e436faba83820...  \n",
       "11  ./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...  \n",
       "12  ./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...  \n",
       "13  ./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...  \n",
       "15  ./temp/FatigueMI/[12]/96dc576945fb4f2db582d66a...  \n",
       "26  ./temp/FatigueMI/[4]/52166a0614d541acb9b9ef965...  \n",
       "27  ./temp/FatigueMI/[4]/72578c4a27b64a8e989fd9072...  \n",
       "28  ./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f52...  \n",
       "33  ./temp/FatigueMI/[6]/0614f3b1603b4442a2cc79ade...  \n",
       "34  ./temp/FatigueMI/[6]/969f098d0f9344e5baa14cc42...  \n",
       "36  ./temp/FatigueMI/[6]/7ec6d62fc9a84597a65261efc...  \n",
       "45  ./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5...  \n",
       "46  ./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520...  \n",
       "48  ./temp/FatigueMI/[9]/63a8c87ffc02471893db5ac9a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "subjects_to_retain = [4, 6, 9, 11, 12]\n",
    "subjects_to_retain_str = [f'{subject}' for subject in subjects_to_retain]\n",
    "model_names_to_retain_str = [\"shallow_conv_net\", \"deep_conv_net\", \"eeg_net\"]\n",
    "\n",
    "rprint(subjects_to_retain_str)\n",
    "\n",
    "# Convert subjects written as \"['1']\" to \"[1]\"\n",
    "filtered_study_trials_concat_df['subjects'] = filtered_study_trials_concat_df['subjects'].apply(lambda x: x[1:-1].replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "# Convert subjects to catagorical\n",
    "filtered_study_trials_concat_df['subjects'] = pd.Categorical(filtered_study_trials_concat_df['subjects'].astype(str))\n",
    "# filtered_study_trials_concat_df.query(f\"subjects in {subjects_to_retain_str} and test_acc > 0.67\")\n",
    "\n",
    "# Get the models with the highest test_acc for each type of model_name (eeg_net, deep_conv_net, etc.) and for each subject (4, 6, 9, 10, 11, 12)\n",
    "best_models_df = filtered_study_trials_concat_df.groupby(['subjects', 'model_name']).apply(lambda x: x.nlargest(1, 'test_acc')).reset_index(drop=True)\n",
    "best_models_df = best_models_df.query(f\"subjects in {subjects_to_retain_str}\")\n",
    "best_models_df = best_models_df.query(f\"model_name in {model_names_to_retain_str}\")\n",
    "display(best_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_models_df.to_csv(\"./final/best_models.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
