{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-24 17:47:06.576219: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-24 17:47:06.576317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-24 17:47:06.577275: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-24 17:47:06.586255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 17:47:07.727579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "%load_ext tensorboard\n",
    "    \n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tf\"\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"0\"\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import keras\n",
    "    \n",
    "# region Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Permute, Dropout\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    ")\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "# endregion Keras\n",
    "\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_optim.utils import channels_to_channels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "# RNG = jax.random.PRNGKey(SKLRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Helper funcs\n",
    "def shallow_conv_net_square_layer(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "def shallow_conv_net_log_layer(x):\n",
    "    return tf.math.log(tf.clip_by_value(x, 1e-7, 10000))\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    \"shallow_conv_net_square_layer\": shallow_conv_net_square_layer, \n",
    "    \"shallow_conv_net_log_layer\": shallow_conv_net_log_layer \n",
    "}\n",
    "# endregion Helper funcs\n",
    "\n",
    "# region Models\n",
    "def shallow_conv_net(\n",
    "    nb_classes, channels, samples, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    From: https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
    "    \"\"\"\n",
    "\n",
    "    _POOL_SIZE_D2_ = kwargs.get(\"pool_size_d2\", 35)\n",
    "    _STRIDES_D2_ = kwargs.get(\"strides_d2\", 7)\n",
    "    _CONV_FILTERS_D2_ = kwargs.get(\"conv_filters_d2\", 13)\n",
    "\n",
    "    _POOL_SIZE_ = kwargs.get(\"pool_size\", (1, _POOL_SIZE_D2_))\n",
    "    _STRIDES_ = kwargs.get(\"strides\", (1, _STRIDES_D2_))\n",
    "    _CONV_FILTERS_ = kwargs.get(\"conv_filters\", (1, _CONV_FILTERS_D2_))\n",
    "\n",
    "    _CONV2D_1_UNITS_ = kwargs.get(\"conv2d_1_units\", 40)\n",
    "    _CONV2D_2_UNITS_ = kwargs.get(\"conv2d_2_units\", 40)\n",
    "    _L2_REG_1_ = kwargs.get(\"l2_reg_1\", 0.01)\n",
    "    _L2_REG_2_ = kwargs.get(\"l2_reg_2\", 0.01)\n",
    "    _L2_REG_3_ = kwargs.get(\"l2_reg_3\", 0.01)\n",
    "    _DROPOUT_RATE_ = kwargs.get(\"dropout_rate\", 0.5)\n",
    "\n",
    "    input_main = Input(shape=(channels, samples, 1))\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_1_UNITS_,\n",
    "        _CONV_FILTERS_,\n",
    "        input_shape=(channels, samples, 1),\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_1_),\n",
    "    )(input_main)\n",
    "    # block1       = Conv2D(40, (channels, 1), use_bias=False,\n",
    "    #                       kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_2_UNITS_,\n",
    "        (channels, 1),\n",
    "        use_bias=False,\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_2_),\n",
    "    )(block1)\n",
    "    block1 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1 = Activation(shallow_conv_net_square_layer)(block1)\n",
    "    block1 = AveragePooling2D(pool_size=_POOL_SIZE_, strides=_STRIDES_)(block1)\n",
    "    block1 = Activation(shallow_conv_net_log_layer)(block1)\n",
    "    block1 = Dropout(_DROPOUT_RATE_)(block1)\n",
    "    flatten = Flatten()(block1)\n",
    "    # dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    dense = Dense(\n",
    "        nb_classes,\n",
    "        kernel_constraint=max_norm(0.5),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_3_),\n",
    "    )(flatten)\n",
    "    softmax = Activation(\"softmax\")(dense)\n",
    "\n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "# endregion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_best_trials = glob.glob('./temp_v2/**/model/study_best_trial.npy', recursive=True)\n",
    "subject_best_trials = sorted(subject_best_trials, key=lambda x: os.path.getmtime(x))\n",
    "subject_best_trials = sorted(subject_best_trials, key=lambda x: int(re.compile(r\"\\[.*\\]\").search(x).group(0).strip(\"[]\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[1]/292cbc92b8cf46da9986fe7d8447819f/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[2]/6405d11e654b42aca9df48458c67ecde/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[3]/9c1b753483db409a90eab7b7149b8af8/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[4]/3623cb4ba1ad4a908c9098f5297a6778/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[5]/d199c9c2ac924b238693f158eb88f675/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[6]/39d01251ff494106bf04f8a2cffcdd74/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[7]/aabe056cd1954a6f92ab47d84c86b1b8/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[8]/9fd82ec44ef3496da6307b57ecf4532f/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[9]/63a8c87ffc02471893db5ac9a0781946/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[10]/c2cc69dca74d4bfa81722cd634e6403e/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[11]/e0643f9a780146a4adc15ddd4a9ff053/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[12]/96dc576945fb4f2db582d66ae1d2c8ce/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[13]/1b189965ada44ff99e73fa145cd3901d/model/study_best_trial.npy'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp_v2/[14]/a3304348c7094d02a024828ede942cda/model/study_best_trial.npy'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/292cbc92b8cf46da9986fe7d8447819f/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/6405d11e654b42aca9df48458c67ecde/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/9c1b753483db409a90eab7b7149b8af8/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/3623cb4ba1ad4a908c9098f5297a6778/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/d199c9c2ac924b238693f158eb88f675/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/39d01251ff494106bf04f8a2cffcdd74/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/aabe056cd1954a6f92ab47d84c86b1b8/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/9fd82ec44ef3496da6307b57ecf4532f/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/63a8c87ffc02471893db5ac9a0781946/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/c2cc69dca74d4bfa81722cd634e6403e/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/e0643f9a780146a4adc15ddd4a9ff053/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/96dc576945fb4f2db582d66ae1d2c8ce/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/1b189965ada44ff99e73fa145cd3901d/model/study_best_trial.npy'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'./temp_v2/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/a3304348c7094d02a024828ede942cda/model/study_best_trial.npy'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint(subject_best_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Loading best trial model<span style=\"color: #808000; text-decoration-color: #808000\">...</span> .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Loading best trial model\u001b[33m...\u001b[0m .\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 300.0, returning unmodified.\n",
      "Adding metadata with 3 columns\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 25.5757 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38612/1323652598.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 17:49:21.160704: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_11/prune_low_magnitude_dropout_9/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 49.8898 - accuracy: 0.5441 - val_loss: 45.0152 - val_accuracy: 0.6111\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 44.7718 - accuracy: 0.8235 - val_loss: 42.7455 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4545454680919647</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.8636363744735718\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.4545454680919647\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38612/1323652598.py:80: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model to: .\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpucr5o5ky/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpucr5o5ky/assets\n",
      "2024-03-24 17:49:24.529920: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-24 17:49:24.529965: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-24 17:49:24.530109: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpucr5o5ky\n",
      "2024-03-24 17:49:24.531233: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-24 17:49:24.531243: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpucr5o5ky\n",
      "2024-03-24 17:49:24.536496: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-24 17:49:24.560372: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpucr5o5ky\n",
      "2024-03-24 17:49:24.577060: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 46952 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mpruned_model.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240971.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240971.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">238805.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m238805.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236616.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m236616.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbg7njoja/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbg7njoja/assets\n",
      "2024-03-24 17:49:25.807755: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-24 17:49:25.807798: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-24 17:49:25.807937: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpbg7njoja\n",
      "2024-03-24 17:49:25.809012: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-24 17:49:25.809022: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpbg7njoja\n",
      "2024-03-24 17:49:25.814621: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-24 17:49:25.835953: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpbg7njoja\n",
      "2024-03-24 17:49:25.846211: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 38273 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">quantized_and_pruned_model.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mquantized_and_pruned_model.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240971.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m240971.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66992.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m66992.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45454545454545453</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.45454545454545453\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4545454680919647</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.4545454680919647\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for subject_best_trial in subject_best_trials[0:1]:\n",
    "    \n",
    "    rprint(\"\\n\\n\\nLoading best trial model...\", subject_best_trial)\n",
    "\n",
    "    model = np.load(subject_best_trials[0], allow_pickle=True).item()\n",
    "    model_info = {\n",
    "        \"subject\": model.user_attrs[\"trial_data\"][\"subject\"] if hasattr(model.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(model.user_attrs[\"trial_data\"][\"data_path\"]).group(0).strip(\"[]\")),\n",
    "        \"sfreq\": model.params[\"sfreq\"] if \"sfreq\" in model.params else 128,\n",
    "        \"batch_size\": model.params[\"batch_size\"] if \"batch_size\" in model.params else 128,\n",
    "        \"channels_selected\": model.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "        \"channels_idx_selected\": channels_to_channels_idx(model.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "        \"model\": tf.keras.models.model_from_json(model.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "        \"test_acc\": model.user_attrs[\"trial_data\"][\"test_accuracy\"]\n",
    "    }\n",
    "    if \"weights\" in model.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "    elif \"model_weights\" in model.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "\n",
    "\n",
    "    # region 1) ------------- Build & save baseline model ------------- \n",
    "    rprint(\"Building & saving baseline model...\")\n",
    "    X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "    y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "\n",
    "    model_info[\"model\"].compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    baseline_model_test = model_info[\"model\"].evaluate(X_test, y_test, batch_size=model_info[\"batch_size\"])\n",
    "\n",
    "    baseline_test_acc = baseline_model_test[1]\n",
    "\n",
    "    _, keras_file = None, subject_best_trial.split(\"study_best_trial.npy\")[0] + \"baseline_model.h5\"\n",
    "    tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n",
    "    rprint('Saved baseline model to:', keras_file)\n",
    "    # endregion\n",
    "\n",
    "    # region 2) ------------- Pruning the baseline model -------------\n",
    "    rprint(\"Pruning the baseline model...\")\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    batch_size = model_info[\"batch_size\"]\n",
    "    epochs = 2\n",
    "    end_step = np.ceil(len(X_train) / batch_size).astype(np.int32) * epochs\n",
    "    # end_step = model_info[\"batch_size\"]\n",
    "    # Define model for pruning.\n",
    "    pruning_params = {\n",
    "        #   'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.9,\n",
    "        #                                                           begin_step=0,\n",
    "        #                                                           frequency=100)\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                                final_sparsity=0.90,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step)\n",
    "    }\n",
    "    keras.utils.get_custom_objects().update({\n",
    "        **CUSTOM_OBJECTS\n",
    "    })\n",
    "    baseline_model_copy = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    model_for_pruning = prune_low_magnitude(baseline_model_copy, **pruning_params)\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    logdir = \"logs/pruning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(X_train, y_train, batch_size=model_info[\"batch_size\"], epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "    _, model_for_pruning_accuracy = model_for_pruning.evaluate(X_test, y_test, verbose=0)\n",
    "    rpprint({\n",
    "        'Baseline test accuracy': baseline_test_acc,\n",
    "        'Pruned test accuracy': model_for_pruning_accuracy\n",
    "    })\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    _, pruned_keras_file = None, subject_best_trial.split(\"study_best_trial.npy\")[0] + \"pruned_model.h5\"\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "    rprint('Saved pruned Keras model to:', pruned_keras_file)\n",
    "\n",
    "    # endregion\n",
    "\n",
    "    # region 3) ------------- Converting pruned model to TFLite -------------\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, subject_best_trial.split(\"study_best_trial.npy\")[0] + \"pruned_model.tflite\"\n",
    "\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "\n",
    "    rprint('Saved pruned TFLite model to:', pruned_tflite_file)\n",
    "\n",
    "    def get_gzipped_model_size(file):\n",
    "        # Returns size of gzipped model, in bytes.\n",
    "        import os\n",
    "        import zipfile\n",
    "        _, zipped_file = tempfile.mkstemp('.zip')\n",
    "        with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "            f.write(file)\n",
    "        \n",
    "        return os.path.getsize(zipped_file)\n",
    "\n",
    "    rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "    rprint(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "    rprint(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "\n",
    "    # endregion\n",
    "\n",
    "    # region 4) ------------- Quantizing pruned TFLite model ------------- \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, quantized_and_pruned_tflite_file = None, subject_best_trial.split(\"study_best_trial.npy\")[0] + \"quantized_and_pruned_model.tflite\"\n",
    "\n",
    "    with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "        f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "    rprint('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "    rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "    rprint(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "    # endregion\n",
    "\n",
    "    # region 5) ------------- Evaluation check ------------- \n",
    "    def evaluate_model(interpreter):\n",
    "        input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        # signatures = interpreter.get_signature_list()\n",
    "        # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "        # Run predictions on every image in the \"test\" dataset.\n",
    "        predictions = []\n",
    "        for i, v in enumerate(X_test):\n",
    "            v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "            # if i % 1000 == 0:\n",
    "            #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "            # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "            # # the model's input data format.\n",
    "            # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, v)\n",
    "\n",
    "            # Run inference.\n",
    "            interpreter.invoke()\n",
    "\n",
    "            # Post-processing: remove batch dimension and find the digit with highest\n",
    "            # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "            predictions.append(class_prediction)\n",
    "\n",
    "        print('\\n')\n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        predictions = np.asarray(predictions)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "        return accuracy\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "    rprint('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "    rprint('Pruned TF test accuracy:', model_for_pruning_accuracy)\n",
    "    # endregion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
