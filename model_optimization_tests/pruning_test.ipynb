{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Any, Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    Add,\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    DepthwiseConv2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LayerNormalization,\n",
    "    MaxPooling2D,\n",
    "    Permute,\n",
    ")\n",
    "from keras.models import Model, Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from moabb.pipelines.utils_deep_model import EEGNet, EEGNet_TC\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "import keras\n",
    "# from braindecode import EEGClassifier\n",
    "# from braindecode.models import EEGInception\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "# from skorch.callbacks import EarlyStopping, EpochScoring\n",
    "# from skorch.dataset import ValidSplit\n",
    "\n",
    "from moabb import set_log_level\n",
    "from moabb.pipelines.features import StandardScaler_Epoch\n",
    "from moabb.utils import setup_seed\n",
    "\n",
    "# Datasets\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "from custom_datasets.norm_cho import NormCho2017\n",
    "from moabb.datasets import Cho2017, Zhou2016, Weibo2014\n",
    "\n",
    "# Moabb evaluation methods\n",
    "from moabb.evaluations import CrossSessionEvaluation, WithinSessionEvaluation\n",
    "\n",
    "# Moabb paradigms\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "# Scikitlearn imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from moabb.pipelines.features import Resampler_Epoch, Convert_Epoch_Array, StandardScaler_Epoch\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up reproducibility of Tensorflow\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# DeepConvNet\n",
    "# =================================================================================\n",
    "class KerasDeepConvNet(KerasClassifier):\n",
    "    \"\"\"Keras implementation of the Deep Convolutional Network as described in\n",
    "    [1]_.\n",
    "\n",
    "    This implementation is taken from code by the Army Research Laboratory (ARL)\n",
    "    at https://github.com/vlawhern/arl-eegmodels\n",
    "\n",
    "    We use the original parameter implemented on the paper.\n",
    "\n",
    "    Note that this implementation has not been verified by the original\n",
    "    authors.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J., Glasstetter, M., Eggensperger,\n",
    "           K., Tangermann, M., ... & Ball, T. (2017). Deep learning with convolutional neural networks\n",
    "           for EEG decoding and visualization. Human brain mapping, 38(11), 5391-5420.\n",
    "           https://doi.org/10.1002/hbm.23730\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    .. versionadded:: 0.5.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss,\n",
    "        optimizer=\"Adam\",\n",
    "        epochs=1000,\n",
    "        batch_size=64,\n",
    "        verbose=0,\n",
    "        random_state=None,\n",
    "        validation_split=0.2,\n",
    "        history_plot=False,\n",
    "        path=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.loss = loss\n",
    "        if optimizer == \"Adam\":\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.0009)\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        self.validation_split = validation_split\n",
    "        self.history_plot = history_plot\n",
    "        self.path = path\n",
    "\n",
    "    def _keras_build_fn(self, compile_kwargs: Dict[str, Any]):\n",
    "        input_main = Input(shape=(self.X_shape_[1], self.X_shape_[2], 1))\n",
    "\n",
    "        block1 = Conv2D(\n",
    "            25,\n",
    "            (1, 10),\n",
    "            input_shape=(self.X_shape_[1], self.X_shape_[2], 1),\n",
    "            kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        )(input_main)\n",
    "        block1 = Conv2D(\n",
    "            25,\n",
    "            (self.X_shape_[1], 1),\n",
    "            kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        )(block1)\n",
    "        block1 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "        block1 = Activation(\"elu\")(block1)\n",
    "        block1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(block1)\n",
    "        block1 = Dropout(0.5)(block1)\n",
    "\n",
    "        block2 = Conv2D(50, (1, 10), kernel_constraint=max_norm(2.0, axis=(0, 1, 2)))(\n",
    "            block1\n",
    "        )\n",
    "        block2 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "        block2 = Activation(\"elu\")(block2)\n",
    "        block2 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(block2)\n",
    "        block2 = Dropout(0.5)(block2)\n",
    "\n",
    "        block3 = Conv2D(100, (1, 10), kernel_constraint=max_norm(2.0, axis=(0, 1, 2)))(\n",
    "            block2\n",
    "        )\n",
    "        block3 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "        block3 = Activation(\"elu\")(block3)\n",
    "        block3 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(block3)\n",
    "        block3 = Dropout(0.5)(block3)\n",
    "\n",
    "        block4 = Conv2D(200, (1, 10), kernel_constraint=max_norm(2.0, axis=(0, 1, 2)))(\n",
    "            block3\n",
    "        )\n",
    "        block4 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "        block4 = Activation(\"elu\")(block4)\n",
    "        block4 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(block4)\n",
    "        block4 = Dropout(0.5)(block4)\n",
    "\n",
    "        flatten = Flatten()(block4)\n",
    "\n",
    "        dense = Dense(self.n_classes_, kernel_constraint=max_norm(0.5))(flatten)\n",
    "        softmax = Activation(\"softmax\")(dense)\n",
    "\n",
    "        model = Model(inputs=input_main, outputs=softmax)\n",
    "        \n",
    "        model.compile(loss=compile_kwargs[\"loss\"], optimizer=compile_kwargs[\"optimizer\"])\n",
    "\n",
    "        ## Pruning\n",
    "\n",
    "        # prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "        # pruning_params = {\n",
    "        #     'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
    "        # }\n",
    "\n",
    "        # callbacks = [\n",
    "        # tfmot.sparsity.keras.UpdatePruningStep()\n",
    "        # ]\n",
    "\n",
    "        # pruned_model = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "        # # Use smaller learning rate for fine-tuning\n",
    "        # opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "        # pruned_model.compile(\n",
    "        # loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        # optimizer=opt,\n",
    "        # metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "        \n",
    "\n",
    "keras_deep_conv_net = KerasDeepConvNet(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"Adam\",\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    random_state=None,\n",
    "    validation_split=0.2,\n",
    "    history_plot=False,\n",
    "    path=None,\n",
    ")\n",
    "# keras_deep_conv_net.save(\"keras_deep_conv_net.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;resampler_epoch&#x27;, Resampler_Epoch(sfreq=250)),\n",
       "                (&#x27;convert_epoch_array&#x27;, Convert_Epoch_Array()),\n",
       "                (&#x27;standardscaler_epoch&#x27;, StandardScaler_Epoch()),\n",
       "                (&#x27;kerasdeepconvnet&#x27;,\n",
       "                 KerasDeepConvNet(build_fn=None, callbacks=None, class_weight=None, epochs=25, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=None, model=None, optimizer=&lt;keras.optimizers.adam.Adam object at 0x7f39bde75950&gt;, run_eagerly=False, shuffle=True, validation_batch_size=None, verbose=1, warm_start=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;resampler_epoch&#x27;, Resampler_Epoch(sfreq=250)),\n",
       "                (&#x27;convert_epoch_array&#x27;, Convert_Epoch_Array()),\n",
       "                (&#x27;standardscaler_epoch&#x27;, StandardScaler_Epoch()),\n",
       "                (&#x27;kerasdeepconvnet&#x27;,\n",
       "                 KerasDeepConvNet(build_fn=None, callbacks=None, class_weight=None, epochs=25, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=None, model=None, optimizer=&lt;keras.optimizers.adam.Adam object at 0x7f39bde75950&gt;, run_eagerly=False, shuffle=True, validation_batch_size=None, verbose=1, warm_start=False))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Resampler_Epoch</label><div class=\"sk-toggleable__content\"><pre>Resampler_Epoch(sfreq=250)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Convert_Epoch_Array</label><div class=\"sk-toggleable__content\"><pre>Convert_Epoch_Array()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler_Epoch</label><div class=\"sk-toggleable__content\"><pre>StandardScaler_Epoch()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasDeepConvNet</label><div class=\"sk-toggleable__content\"><pre>KerasDeepConvNet(\n",
       "\tmodel=None\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.adam.Adam object at 0x7f39bde75950&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=25\n",
       "\tclass_weight=None\n",
       "\thistory_plot=False\n",
       "\tpath=None\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('resampler_epoch', Resampler_Epoch(sfreq=250)),\n",
       "                ('convert_epoch_array', Convert_Epoch_Array()),\n",
       "                ('standardscaler_epoch', StandardScaler_Epoch()),\n",
       "                ('kerasdeepconvnet',\n",
       "                 KerasDeepConvNet(build_fn=None, callbacks=None, class_weight=None, epochs=25, loss='sparse_categorical_crossentropy', metrics=None, model=None, optimizer=<keras.optimizers.adam.Adam object at 0x7f39bde75950>, run_eagerly=False, shuffle=True, validation_batch_size=None, verbose=1, warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_keras_pruned = keras.models.load_model(\"keras_deep_conv_net.h5\")\n",
    "model_keras_pruned = keras_deep_conv_net\n",
    "# Now we need to instantiate a new SciKeras object since we only saved the Keras model\n",
    "resampler_epoch = Resampler_Epoch(sfreq=250)\n",
    "convert_epoch_array = Convert_Epoch_Array()\n",
    "standardscaler_epoch = StandardScaler_Epoch()\n",
    "Keras_DeepConvNet_Trained_Pruned = make_pipeline(\n",
    "    resampler_epoch,\n",
    "    convert_epoch_array,\n",
    "    standardscaler_epoch,\n",
    "    model_keras_pruned\n",
    ")\n",
    "\n",
    "Keras_DeepConvNet_Trained_Pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FatigueMI-WithinSession:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "No hdf5_path provided, models will not be saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/paradigms/base.py:354: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  X = mne.concatenate_epochs(X)\n",
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:09:42.327927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [68,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:09:42.328817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [68,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:09:43.555128: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62976000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 1s - loss: 1.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:09:43.835503: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62976000 exceeds 10% of free system memory.\n",
      "2024-02-16 14:09:43.952335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:09:43.952501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 158ms/step - loss: 1.0597 - val_loss: 0.6986\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8086 - val_loss: 0.6982\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:09:44.079338: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62976000 exceeds 10% of free system memory.\n",
      "2024-02-16 14:09:44.121366: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62976000 exceeds 10% of free system memory.\n",
      "2024-02-16 14:09:44.245451: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62976000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8181 - val_loss: 0.6955\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7653 - val_loss: 0.6931\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7367 - val_loss: 0.6913\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7082 - val_loss: 0.6904\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7785 - val_loss: 0.6904\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8751 - val_loss: 0.6902\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8735 - val_loss: 0.6912\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7203 - val_loss: 0.6933\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8007 - val_loss: 0.6951\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7240 - val_loss: 0.6903\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7884 - val_loss: 0.6874\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6818 - val_loss: 0.6837\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7933 - val_loss: 0.6813\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7642 - val_loss: 0.6818\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8771 - val_loss: 0.6810\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7524 - val_loss: 0.6792\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8196 - val_loss: 0.6807\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6708 - val_loss: 0.6803\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8058 - val_loss: 0.6747\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8947 - val_loss: 0.6744\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8013 - val_loss: 0.6654\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7244 - val_loss: 0.6601\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7635 - val_loss: 0.6564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:09:47.952544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [22,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2024-02-16 14:09:47.955338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [22,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 510ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:09:48.681297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [68,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:09:48.681450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [68,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 120ms/step - loss: 1.8275 - val_loss: 0.6883\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:09:49.848981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:09:49.849130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7843 - val_loss: 0.6869\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7354 - val_loss: 0.6960\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7483 - val_loss: 0.7118\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8033 - val_loss: 0.7478\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8629 - val_loss: 0.7896\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7510 - val_loss: 0.8272\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8488 - val_loss: 0.8777\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8971 - val_loss: 0.9073\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8221 - val_loss: 0.9257\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8665 - val_loss: 0.9446\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7519 - val_loss: 0.9544\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8561 - val_loss: 0.9506\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8502 - val_loss: 0.9256\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7254 - val_loss: 0.9128\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7005 - val_loss: 0.8991\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7669 - val_loss: 0.8792\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7592 - val_loss: 0.8634\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8226 - val_loss: 0.8573\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6904 - val_loss: 0.8529\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7373 - val_loss: 0.8473\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8084 - val_loss: 0.8348\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.7416 - val_loss: 0.8380\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7609 - val_loss: 0.8443\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7318 - val_loss: 0.8421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:09:58.185662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [22,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2024-02-16 14:09:58.189065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [22,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 588ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:09:59.066609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [68,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:09:59.068658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [68,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 124ms/step - loss: 1.6603 - val_loss: 0.6974\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:10:00.427462: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:10:00.427614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8457 - val_loss: 0.6989\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7309 - val_loss: 0.6971\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7864 - val_loss: 0.6948\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7620 - val_loss: 0.6932\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8757 - val_loss: 0.6953\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7955 - val_loss: 0.7016\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 5s 4s/step - loss: 0.8718 - val_loss: 0.7052\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8195 - val_loss: 0.7077\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.9097 - val_loss: 0.7110\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7938 - val_loss: 0.7108\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8506 - val_loss: 0.7041\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8204 - val_loss: 0.7025\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 2s 935ms/step - loss: 0.8216 - val_loss: 0.7024\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.8574 - val_loss: 0.7031\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 6s 5s/step - loss: 0.7367 - val_loss: 0.7036\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6958 - val_loss: 0.7034\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.7402 - val_loss: 0.7037\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.7565 - val_loss: 0.7055\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8363 - val_loss: 0.7085\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.6864 - val_loss: 0.7095\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 0.7972 - val_loss: 0.7084\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.8170 - val_loss: 0.7091\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8269 - val_loss: 0.7083\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 1s 711ms/step - loss: 0.8073 - val_loss: 0.7024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:10:47.654390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [22,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2024-02-16 14:10:47.661060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [22,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:10:48.077989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [69,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:10:48.080264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [69,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 127ms/step - loss: 1.2150 - val_loss: 0.6882\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:10:49.440145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:10:49.440892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7678 - val_loss: 0.6948\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7140 - val_loss: 0.7029\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7505 - val_loss: 0.7134\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7646 - val_loss: 0.7294\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.7111 - val_loss: 0.7485\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8982 - val_loss: 0.7652\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.8576 - val_loss: 0.7824\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.8510 - val_loss: 0.7940\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.8572 - val_loss: 0.7884\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 110s 5s/step - loss: 0.7436 - val_loss: 0.7711\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 1s 337ms/step - loss: 0.8535 - val_loss: 0.7701\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6897 - val_loss: 0.7658\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7171 - val_loss: 0.7566\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7928 - val_loss: 0.7425\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8288 - val_loss: 0.7363\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7364 - val_loss: 0.7316\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7580 - val_loss: 0.7212\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6851 - val_loss: 0.7064\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8946 - val_loss: 0.7103\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7201 - val_loss: 0.7044\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7316 - val_loss: 0.7084\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7810 - val_loss: 0.7123\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7603 - val_loss: 0.7107\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8163 - val_loss: 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:12:45.394192: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [21,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2024-02-16 14:12:45.397519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [21,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 350ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:12:45.866577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [69,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-02-16 14:12:45.866733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [69,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 1s - loss: 1.3322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 14:12:47.739050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [18,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2024-02-16 14:12:47.745856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [18,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 908ms/step - loss: 1.3019 - val_loss: 0.6999\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8159 - val_loss: 0.7141\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7946 - val_loss: 0.7371\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8319 - val_loss: 0.7571\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8588 - val_loss: 0.7795\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9026 - val_loss: 0.7939\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6896 - val_loss: 0.7904\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8281 - val_loss: 0.7835\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7553 - val_loss: 0.7711\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7645 - val_loss: 0.7537\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7104 - val_loss: 0.7412\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7270 - val_loss: 0.7332\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7781 - val_loss: 0.7250\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7730 - val_loss: 0.7201\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7639 - val_loss: 0.7228\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6824 - val_loss: 0.7214\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7908 - val_loss: 0.7204\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6991 - val_loss: 0.7213\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6730 - val_loss: 0.7247\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8377 - val_loss: 0.7227\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7836 - val_loss: 0.7240\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7559 - val_loss: 0.7217\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7880 - val_loss: 0.7156\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7721 - val_loss: 0.7115\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7654 - val_loss: 0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araz/anaconda3/envs/moabb_model_optimization/lib/python3.11/site-packages/moabb/pipelines/features.py:163: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  return X.get_data()\n",
      "2024-02-16 14:12:56.564394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [21,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2024-02-16 14:12:56.580523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [21,20,501]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f39bc37bec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FatigueMI-WithinSession: 100%|██████████| 1/1 [03:16<00:00, 196.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# # model_keras_pruned = keras.models.load_model(\"keras_deep_conv_net.h5\")\n",
    "# model_keras_pruned = keras_deep_conv_net\n",
    "# # Now we need to instantiate a new SciKeras object since we only saved the Keras model\n",
    "# Keras_DeepConvNet_Trained_Pruned = KerasClassifier(build_fn = model_keras_pruned._keras_build_fn)\n",
    "\n",
    "# Restrict this example only on the first two subject of BNCI2014_001\n",
    "fat_dataset = FatigueMI()\n",
    "norm_cho_dataset = NormCho2017()\n",
    "cho_dataset = Cho2017()\n",
    "\n",
    "fat_dataset.subject_list = fat_dataset.subject_list[:1]\n",
    "norm_cho_dataset.subject_list = norm_cho_dataset.subject_list[:32]\n",
    "cho_dataset.subject_list = cho_dataset.subject_list[:32]\n",
    "\n",
    "datasets = [\n",
    "    fat_dataset,\n",
    "    # norm_cho_dataset,\n",
    "    # cho_dataset\n",
    "]\n",
    "\n",
    "evaluation_dict = {\n",
    "    \"WithinSession\": WithinSessionEvaluation\n",
    "}\n",
    "paradim_dict = {\n",
    "    \"LeftRightImagery\": LeftRightImagery\n",
    "}\n",
    "pipeline_dict = {\n",
    "    \"Keras_DeepConvNet_Trained_Pruned\": Pipeline(\n",
    "        [\n",
    "            # (\"StandardScaler_Epoch\", StandardScaler_Epoch),\n",
    "            (\"Keras_DeepConvNet_Trained\", Keras_DeepConvNet_Trained_Pruned),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model_text in pipeline_dict.keys():\n",
    "    for evaluation_text in [\"WithinSession\"]: #, \"CrossSession\", \"CrossSubject\"]:\n",
    "        for paradim_text in [\"LeftRightImagery\"]: #, \"FilterBankMotorImagery\"]:\n",
    "            evaluation = evaluation_dict[evaluation_text](\n",
    "                paradigm=paradim_dict[paradim_text](), datasets=datasets, overwrite=True, return_epochs=True,\n",
    "            )\n",
    "            results = evaluation.process({ model_text: pipeline_dict[model_text] })\n",
    "            results_dict[model_text + \"_\" + evaluation_text + \"_\" + paradim_text] = results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span>score       time  samples subject session  channels  n_sessions  \\\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.497851</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39.150051</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108.0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>   \n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│    </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│    </span>dataset                          pipeline  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  FatigueMI  Keras_DeepConvNet_Trained_Pruned  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;32m│     \u001b[0mscore       time  samples subject session  channels  n_sessions  \\\n",
       "\u001b[1;36m0\u001b[0m  \u001b[1;36m0.497851\u001b[0m  \u001b[1;36m39.150051\u001b[0m    \u001b[1;36m108.0\u001b[0m       \u001b[1;36m1\u001b[0m       \u001b[1;36m0\u001b[0m        \u001b[1;36m20\u001b[0m           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[2;32m│    \u001b[0m\n",
       "\u001b[2;32m│    \u001b[0mdataset                          pipeline  \n",
       "\u001b[1;36m0\u001b[0m  FatigueMI  Keras_DeepConvNet_Trained_Pruned  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.pretty import pprint as rpprint\n",
    "\n",
    "rpprint(\n",
    "    results_dict['Keras_DeepConvNet_Trained_Pruned_WithinSession_LeftRightImagery'],\n",
    "    expand_all=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
