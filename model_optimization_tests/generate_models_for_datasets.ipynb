{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 17:13:56.555679: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 17:13:56.555736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 17:13:56.600828: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 17:13:56.743473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 17:13:57.800837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "from model_optim.model_optimizer import ModelOptimizer\n",
    "\n",
    "# Dataset\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "from custom_datasets.norm_cho import NormCho2017\n",
    "from custom_datasets.opt_game_mi import OptGameMI\n",
    "from custom_datasets.opt_std_mi import OptStdMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [\n",
    "    # \"shallow_conv_net\",\n",
    "    \"lstm_net\",\n",
    "    \"deep_conv_net\",\n",
    "    \"eeg_net\",\n",
    "    \"lstm_cnn_net\",\n",
    "    \"lstm_cnn_net_v2\"\n",
    "]\n",
    "MODELS_HYPERPARAMS_DICT = {\n",
    "    \"shallow_conv_net\": {\n",
    "        \"max_epochs\": 5\n",
    "    },\n",
    "    \"eeg_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"deep_conv_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net\": {\n",
    "        \"max_epochs\": 10\n",
    "    },\n",
    "    \"lstm_cnn_net_v2\": {},\n",
    "}\n",
    "\n",
    "DATASETS_LIST = [\n",
    "    FatigueMI,\n",
    "    # NormCho2017,\n",
    "    # OptGameMI,\n",
    "    # OptStdMI,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_optim.utils import data_generator\n",
    "\n",
    "# data_generator(\n",
    "#     dataset=NormCho2017(),\n",
    "#     subjects=[1],\n",
    "#     channel_idx=[],\n",
    "#     sfreq=128,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files = glob.glob(\"./temp_v2/*/*/model/study_best_trial.npy\")\n",
    "subject_files_data = {}\n",
    "for subject_file in subject_files:\n",
    "    subject_files_data[subject_file] = np.load(subject_file, allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/39d01251ff494106bf04f8a2cffcdd74/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/39d01251ff494106bf04f8a2cffcdd74/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/a3304348c7094d02a024828ede942cda/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909091234207153</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/a3304348c7094d02a024828ede942cda/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.5909091234207153\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/d199c9c2ac924b238693f158eb88f675/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/d199c9c2ac924b238693f158eb88f675/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/1b189965ada44ff99e73fa145cd3901d/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/1b189965ada44ff99e73fa145cd3901d/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/3623cb4ba1ad4a908c9098f5297a6778/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/3623cb4ba1ad4a908c9098f5297a6778/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/9c1b753483db409a90eab7b7149b8af8/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/9c1b753483db409a90eab7b7149b8af8/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/63a8c87ffc02471893db5ac9a0781946/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9090909361839294</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/63a8c87ffc02471893db5ac9a0781946/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.9090909361839294\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/292cbc92b8cf46da9986fe7d8447819f/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/292cbc92b8cf46da9986fe7d8447819f/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.8636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/aabe056cd1954a6f92ab47d84c86b1b8/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/aabe056cd1954a6f92ab47d84c86b1b8/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7272727489471436\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/6405d11e654b42aca9df48458c67ecde/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/6405d11e654b42aca9df48458c67ecde/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/9fd82ec44ef3496da6307b57ecf4532f/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/9fd82ec44ef3496da6307b57ecf4532f/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.6363636255264282\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/c2cc69dca74d4bfa81722cd634e6403e/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727273106575012</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/c2cc69dca74d4bfa81722cd634e6403e/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7727273106575012\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/96dc576945fb4f2db582d66ae1d2c8ce/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7727273106575012</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/96dc576945fb4f2db582d66ae1d2c8ce/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7727273106575012\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/temp_v2/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/e0643f9a780146a4adc15ddd4a9ff053/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7272727489471436</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/temp_v2/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/e0643f9a780146a4adc15ddd4a9ff053/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m \u001b[1;36m0.7272727489471436\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for subject_file_data_key, subject_file_data in subject_files_data.items():\n",
    "    rprint(subject_file_data_key, subject_file_data.user_attrs['trial_data']['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sfreq: 300.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d001ce750361476c8264028e1b97df51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 17:12:09.739628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:09.944118: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:09.944204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:09.946751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:09.946828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:09.946927: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:11.605455: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:11.605549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:11.605557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-11 17:12:11.605625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:13:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-11 17:12:11.605894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:13:00.0, compute capability: 8.6\n",
      "2024-04-11 17:12:12.421276: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 17:12:15.285276: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-04-11 17:12:16.373895: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-11 17:12:17.261346: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3f780ee970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-11 17:12:17.261379: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-04-11 17:12:17.266760: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712877137.298618  467842 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 115.6422 - accuracy: 0.5735\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 6s 6s/step - loss: 115.6422 - accuracy: 0.5735 - val_loss: 103.9385 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 103.5586 - accuracy: 0.8676\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 103.5586 - accuracy: 0.8676 - val_loss: 95.9112 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 95.4010 - accuracy: 0.9706\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 95.4010 - accuracy: 0.9706 - val_loss: 89.6296 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 89.0584 - accuracy: 0.9706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 89.0584 - accuracy: 0.9706 - val_loss: 84.3580 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 83.7463 - accuracy: 1.0000\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 83.7463 - accuracy: 1.0000 - val_loss: 79.7571 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 79.1359 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 79.1359 - accuracy: 1.0000 - val_loss: 75.6638 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 75.0246 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 75.0246 - accuracy: 1.0000 - val_loss: 71.9430 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 71.3029 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 71.3029 - accuracy: 1.0000 - val_loss: 68.5403 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 67.8968 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 67.8968 - accuracy: 1.0000 - val_loss: 65.3866 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 64.7423 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 64.7423 - accuracy: 1.0000 - val_loss: 62.4547 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Using epoch 00010 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 62.4520 - accuracy: 0.6818\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 41.4484 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 41.4484 - accuracy: 0.4853 - val_loss: 37.8511 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 38.2468 - accuracy: 0.4412\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.2468 - accuracy: 0.4412 - val_loss: 35.6642 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 35.8540 - accuracy: 0.5294\n",
      "Epoch 00003: val_accuracy improved from 0.38889 to 0.44444, storing weights.\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 35.8540 - accuracy: 0.5294 - val_loss: 33.9177 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 34.2363 - accuracy: 0.5294\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.2363 - accuracy: 0.5294 - val_loss: 32.4867 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 32.7179 - accuracy: 0.5147\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 32.7179 - accuracy: 0.5147 - val_loss: 31.1827 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 31.3785 - accuracy: 0.5441\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 31.3785 - accuracy: 0.5441 - val_loss: 30.0379 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 30.3249 - accuracy: 0.4559\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.3249 - accuracy: 0.4559 - val_loss: 29.0080 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 29.1559 - accuracy: 0.6029\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.1559 - accuracy: 0.6029 - val_loss: 28.0198 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 28.2870 - accuracy: 0.6029\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 28.2870 - accuracy: 0.6029 - val_loss: 27.1118 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.1361 - accuracy: 0.5882\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 27.1361 - accuracy: 0.5882 - val_loss: 26.2414 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Using epoch 00003 with val_accuracy: 0.44444\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 33.8951 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 55.2955 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 55.2955 - accuracy: 0.5147 - val_loss: 50.8027 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 50.4014 - accuracy: 0.8529\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 50.4014 - accuracy: 0.8529 - val_loss: 47.4708 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 46.9422 - accuracy: 0.9265\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.9422 - accuracy: 0.9265 - val_loss: 44.6550 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 44.1154 - accuracy: 0.9706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 44.1154 - accuracy: 0.9706 - val_loss: 42.2656 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 41.7203 - accuracy: 0.9706\n",
      "Epoch 00005: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 41.7203 - accuracy: 0.9706 - val_loss: 40.1460 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 39.5821 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 39.5821 - accuracy: 1.0000 - val_loss: 38.2398 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 37.6924 - accuracy: 0.9853\n",
      "Epoch 00007: val_accuracy improved from 0.66667 to 0.72222, storing weights.\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 37.6924 - accuracy: 0.9853 - val_loss: 36.5094 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 35.9371 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 35.9371 - accuracy: 1.0000 - val_loss: 34.9010 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 34.3274 - accuracy: 0.9853\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 34.3274 - accuracy: 0.9853 - val_loss: 33.4222 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 32.8178 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 32.8178 - accuracy: 1.0000 - val_loss: 32.0282 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Using epoch 00007 with val_accuracy: 0.72222\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 36.5723 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 49.6538 - accuracy: 0.5882\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 49.6538 - accuracy: 0.5882 - val_loss: 45.9195 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 46.0321 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 46.0321 - accuracy: 0.5441 - val_loss: 43.3759 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 43.7287 - accuracy: 0.5294\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 43.7287 - accuracy: 0.5294 - val_loss: 41.3548 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 41.6402 - accuracy: 0.4706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 41.6402 - accuracy: 0.4706 - val_loss: 39.7812 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 39.7206 - accuracy: 0.6176\n",
      "Epoch 00005: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 39.7206 - accuracy: 0.6176 - val_loss: 38.2529 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 38.3810 - accuracy: 0.5735\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.3810 - accuracy: 0.5735 - val_loss: 36.9272 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 37.0243 - accuracy: 0.5294\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.0243 - accuracy: 0.5294 - val_loss: 35.6857 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 35.7389 - accuracy: 0.5882\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 35.7389 - accuracy: 0.5882 - val_loss: 34.5584 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 34.6725 - accuracy: 0.5882\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 34.6725 - accuracy: 0.5882 - val_loss: 33.5078 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 33.5508 - accuracy: 0.5882\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 33.5508 - accuracy: 0.5882 - val_loss: 32.5654 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00005 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 38.1763 - accuracy: 0.6364\n",
      "\n",
      "\n",
      "Using sfreq: 128; sfreq is None: True; self.original_sfreq: 300.0; sfreq=128\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8632 - accuracy: 0.6029\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61111, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.8632 - accuracy: 0.6029 - val_loss: 9.2305 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4744 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4744 - accuracy: 0.5000 - val_loss: 8.9101 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2002 - accuracy: 0.5000\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2002 - accuracy: 0.5000 - val_loss: 8.6587 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7179 - accuracy: 0.5441\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.7179 - accuracy: 0.5441 - val_loss: 8.4447 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6973 - accuracy: 0.4559\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.6973 - accuracy: 0.4559 - val_loss: 8.2514 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3244 - accuracy: 0.5294\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.3244 - accuracy: 0.5294 - val_loss: 8.0749 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.0028 - accuracy: 0.7059\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.0028 - accuracy: 0.7059 - val_loss: 7.9100 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9834 - accuracy: 0.6029\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.9834 - accuracy: 0.6029 - val_loss: 7.7544 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.8086 - accuracy: 0.5147\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.8086 - accuracy: 0.5147 - val_loss: 7.6041 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.8357 - accuracy: 0.4412\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.8357 - accuracy: 0.4412 - val_loss: 7.4648 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.2479 - accuracy: 0.4091\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 38.6418 - accuracy: 0.5588\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38889, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.6418 - accuracy: 0.5588 - val_loss: 35.3545 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 35.3846 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy improved from 0.38889 to 0.44444, storing weights.\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 35.3846 - accuracy: 0.5441 - val_loss: 33.1337 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 32.9959 - accuracy: 0.6912\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 32.9959 - accuracy: 0.6912 - val_loss: 31.3379 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 31.3295 - accuracy: 0.5735\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.3295 - accuracy: 0.5735 - val_loss: 29.8615 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 29.7410 - accuracy: 0.7500\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 29.7410 - accuracy: 0.7500 - val_loss: 28.5573 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 28.5808 - accuracy: 0.5882\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.5808 - accuracy: 0.5882 - val_loss: 27.4360 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.2565 - accuracy: 0.7500\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.2565 - accuracy: 0.7500 - val_loss: 26.3651 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 26.2247 - accuracy: 0.7794\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 26.2247 - accuracy: 0.7794 - val_loss: 25.3818 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 25.3260 - accuracy: 0.6618\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.3260 - accuracy: 0.6618 - val_loss: 24.4801 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.4724 - accuracy: 0.7206\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 24.4724 - accuracy: 0.7206 - val_loss: 23.6421 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Using epoch 00002 with val_accuracy: 0.44444\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 33.0817 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.2349 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66667, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.2349 - accuracy: 0.4853 - val_loss: 24.4764 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.6201 - accuracy: 0.6618\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.6201 - accuracy: 0.6618 - val_loss: 22.8396 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.2230 - accuracy: 0.5735\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.2230 - accuracy: 0.5735 - val_loss: 21.5692 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.7806 - accuracy: 0.5441\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 21.7806 - accuracy: 0.5441 - val_loss: 20.5024 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.6212 - accuracy: 0.5735\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 20.6212 - accuracy: 0.5735 - val_loss: 19.5654 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.6282 - accuracy: 0.5147\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.6282 - accuracy: 0.5147 - val_loss: 18.7097 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.9347 - accuracy: 0.5735\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.9347 - accuracy: 0.5735 - val_loss: 17.9437 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.2549 - accuracy: 0.4559\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.2549 - accuracy: 0.4559 - val_loss: 17.2377 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.5126 - accuracy: 0.4706\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.5126 - accuracy: 0.4706 - val_loss: 16.5750 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.9316 - accuracy: 0.4853\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.9316 - accuracy: 0.4853 - val_loss: 15.9592 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Using epoch 00001 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 24.5741 - accuracy: 0.3636\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 104.8261 - accuracy: 0.5441\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 104.8261 - accuracy: 0.5441 - val_loss: 97.9031 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 98.1932 - accuracy: 0.5441\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 98.1932 - accuracy: 0.5441 - val_loss: 93.3398 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 93.3270 - accuracy: 0.7206\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 93.3270 - accuracy: 0.7206 - val_loss: 89.6537 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 89.8252 - accuracy: 0.6176\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 89.8252 - accuracy: 0.6176 - val_loss: 86.5106 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 86.3466 - accuracy: 0.7206\n",
      "Epoch 00005: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 86.3466 - accuracy: 0.7206 - val_loss: 83.7042 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 83.5134 - accuracy: 0.7500\n",
      "Epoch 00006: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 83.5134 - accuracy: 0.7500 - val_loss: 81.1368 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 80.9233 - accuracy: 0.7941\n",
      "Epoch 00007: val_accuracy improved from 0.61111 to 0.66667, storing weights.\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 80.9233 - accuracy: 0.7941 - val_loss: 78.7599 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 78.4447 - accuracy: 0.8088\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 78.4447 - accuracy: 0.8088 - val_loss: 76.5363 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 76.3417 - accuracy: 0.7500\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.3417 - accuracy: 0.7500 - val_loss: 74.4624 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 74.1944 - accuracy: 0.7794\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 74.1944 - accuracy: 0.7794 - val_loss: 72.4824 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Using epoch 00007 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 78.7889 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: 256; sfreq is None: True; self.original_sfreq: 300.0; sfreq=256\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 26.3054 - accuracy: 0.4265\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44444, storing weights.\n",
      "2/2 [==============================] - 2s 423ms/step - loss: 26.3054 - accuracy: 0.4265 - val_loss: 22.4263 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 22.1923 - accuracy: 0.7656\n",
      "Epoch 00002: val_accuracy improved from 0.44444 to 0.55556, storing weights.\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 22.0869 - accuracy: 0.7794 - val_loss: 19.8568 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 19.3922 - accuracy: 0.9375\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 19.3236 - accuracy: 0.9412 - val_loss: 17.9982 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 17.4411 - accuracy: 0.9688\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 17.3915 - accuracy: 0.9706 - val_loss: 16.6828 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 16.1125 - accuracy: 0.9844\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 16.0729 - accuracy: 0.9853 - val_loss: 15.4619 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 14.8753 - accuracy: 0.9844\n",
      "Epoch 00006: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.8374 - accuracy: 0.9853 - val_loss: 14.4148 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 13.8013 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 13.7823 - accuracy: 0.9853 - val_loss: 13.7895 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 13.1942 - accuracy: 0.9844\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 13.1909 - accuracy: 0.9706 - val_loss: 13.2009 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 12.5872 - accuracy: 0.9688\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 12.5672 - accuracy: 0.9706 - val_loss: 12.5252 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 11.9240 - accuracy: 0.9844\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 11.9324 - accuracy: 0.9706 - val_loss: 12.0237 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00006 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 14.3702 - accuracy: 0.5455\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 50.8216 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "3/3 [==============================] - 2s 210ms/step - loss: 50.8216 - accuracy: 0.4853 - val_loss: 44.1210 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 45.2864 - accuracy: 0.6250\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 43.7510 - accuracy: 0.6029 - val_loss: 40.2300 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 40.5308 - accuracy: 0.5938\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 39.5207 - accuracy: 0.6765 - val_loss: 36.9824 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 37.1010 - accuracy: 0.6250\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 36.3787 - accuracy: 0.6618 - val_loss: 34.3732 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 34.0789 - accuracy: 0.8438\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 33.4924 - accuracy: 0.8529 - val_loss: 31.8148 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 31.3945 - accuracy: 0.8750\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 30.9504 - accuracy: 0.8529 - val_loss: 29.7103 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29.2759 - accuracy: 0.9062\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 28.8428 - accuracy: 0.8971 - val_loss: 27.6009 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27.0955 - accuracy: 0.9375\n",
      "Epoch 00008: val_accuracy improved from 0.55556 to 0.66667, storing weights.\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 26.6929 - accuracy: 0.9118 - val_loss: 25.5839 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25.0512 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 24.6729 - accuracy: 0.9853 - val_loss: 23.6993 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 23.2389 - accuracy: 0.9062\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 22.8795 - accuracy: 0.8824 - val_loss: 21.9673 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00008 with val_accuracy: 0.66667\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 25.6147 - accuracy: 0.4545\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 78.8718 - accuracy: 0.4853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, storing weights.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 78.8718 - accuracy: 0.4853 - val_loss: 74.1669 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 83.2943 - accuracy: 0.5147\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 83.2943 - accuracy: 0.5147 - val_loss: 67.1017 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 69.1963 - accuracy: 0.5588\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 69.1963 - accuracy: 0.5588 - val_loss: 65.1899 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 72.1907 - accuracy: 0.5147\n",
      "Epoch 00004: val_accuracy improved from 0.55556 to 0.61111, storing weights.\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 72.1907 - accuracy: 0.5147 - val_loss: 61.3009 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 61.7861 - accuracy: 0.6912\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 61.7861 - accuracy: 0.6912 - val_loss: 58.8187 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 58.2070 - accuracy: 0.8676\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 58.2070 - accuracy: 0.8676 - val_loss: 56.3490 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 55.3135 - accuracy: 0.8971\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 55.3135 - accuracy: 0.8971 - val_loss: 53.9883 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 52.9520 - accuracy: 0.8971\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 52.9520 - accuracy: 0.8971 - val_loss: 51.8199 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 50.6794 - accuracy: 0.9265\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 50.6794 - accuracy: 0.9265 - val_loss: 49.7467 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 48.7408 - accuracy: 0.9265\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 48.7408 - accuracy: 0.9265 - val_loss: 47.7963 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00004 with val_accuracy: 0.61111\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 61.2479 - accuracy: 0.5000\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 45.2335 - accuracy: 0.4559\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "3/3 [==============================] - 2s 245ms/step - loss: 45.2335 - accuracy: 0.4559 - val_loss: 40.1139 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 39.8026 - accuracy: 0.7812\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 38.8202 - accuracy: 0.8235 - val_loss: 35.7475 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 35.1469 - accuracy: 0.9688\n",
      "Epoch 00003: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 34.4575 - accuracy: 0.9559 - val_loss: 32.3560 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 31.7145 - accuracy: 0.9375\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 31.1587 - accuracy: 0.9265 - val_loss: 29.2618 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28.6755 - accuracy: 0.9688\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 28.1098 - accuracy: 0.9559 - val_loss: 26.5018 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25.8617 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 25.3549 - accuracy: 1.0000 - val_loss: 24.0289 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 23.4555 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 22.9837 - accuracy: 0.9853 - val_loss: 21.7300 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21.1020 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 20.6726 - accuracy: 1.0000 - val_loss: 19.5670 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9619 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 18.5405 - accuracy: 1.0000 - val_loss: 17.5214 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.8893 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 16.5032 - accuracy: 1.0000 - val_loss: 15.6165 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00004 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 29.2058 - accuracy: 0.6364\n",
      "\n",
      "\n",
      "Using sfreq: None; sfreq is None: True; self.original_sfreq: 300.0; sfreq=300.0\n",
      "Adding metadata with 3 columns\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 97.1467 - accuracy: 0.5147\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, storing weights.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 97.1467 - accuracy: 0.5147 - val_loss: 89.3004 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 88.8362 - accuracy: 0.8529\n",
      "Epoch 00002: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 88.8362 - accuracy: 0.8529 - val_loss: 83.4827 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 82.8520 - accuracy: 0.9559\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.55556, storing weights.\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 82.8520 - accuracy: 0.9559 - val_loss: 78.6491 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 77.9598 - accuracy: 0.9706\n",
      "Epoch 00004: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 77.9598 - accuracy: 0.9706 - val_loss: 74.5090 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 73.8232 - accuracy: 0.9706\n",
      "Epoch 00005: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 73.8232 - accuracy: 0.9706 - val_loss: 70.8942 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 70.1641 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 70.1641 - accuracy: 1.0000 - val_loss: 67.6301 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 66.8936 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 66.8936 - accuracy: 1.0000 - val_loss: 64.6543 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 63.9270 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 63.9270 - accuracy: 1.0000 - val_loss: 61.9289 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 61.1911 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.1911 - accuracy: 1.0000 - val_loss: 59.3979 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 58.6575 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 58.6575 - accuracy: 1.0000 - val_loss: 57.0358 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Using epoch 00003 with val_accuracy: 0.55556\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 78.5684 - accuracy: 0.4545\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in [FatigueMI]:\n",
    "    for model in [\"lstm_cnn_net\"]:\n",
    "        model_optimizer = ModelOptimizer(\n",
    "            dataset=dataset(),\n",
    "            model_name=model\n",
    "        )\n",
    "        for subject in [3]:\n",
    "            max_epochs = MODELS_HYPERPARAMS_DICT[model][\"max_epochs\"]\n",
    "            study = model_optimizer.search_best_model(\n",
    "                subjects = [subject],\n",
    "                max_iter = 25,\n",
    "                max_epochs = max_epochs,\n",
    "                max_stag_count = 10,\n",
    "                rounds = 1,\n",
    "                replace_previous_study_for_subjects = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>32.817829</td>\n",
       "      <td>32.028210</td>\n",
       "      <td>0.789619</td>\n",
       "      <td>36.572292</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>[C3, F3, F4, C4, Pz, Fp1, T3, T5, O2, A2]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>22.879484</td>\n",
       "      <td>21.967287</td>\n",
       "      <td>0.912197</td>\n",
       "      <td>25.614653</td>\n",
       "      <td>0.111461</td>\n",
       "      <td>[F3, Fz, Pz, T5, O2, F7, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142157</td>\n",
       "      <td>74.194389</td>\n",
       "      <td>72.482399</td>\n",
       "      <td>1.711990</td>\n",
       "      <td>78.788872</td>\n",
       "      <td>0.111511</td>\n",
       "      <td>[Fz, F4, C4, P4, Cz, Fp1, O2, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>64.742279</td>\n",
       "      <td>62.454739</td>\n",
       "      <td>2.287540</td>\n",
       "      <td>62.451977</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>[P3, F4, C4, P4, Cz, Pz, Fp2, O1, O2, F7]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.374183</td>\n",
       "      <td>11.932382</td>\n",
       "      <td>12.023696</td>\n",
       "      <td>0.091314</td>\n",
       "      <td>14.370240</td>\n",
       "      <td>0.151785</td>\n",
       "      <td>[C3, F3, Fz, F4, P4, Pz, Fp1, Fp2, T5, F7, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>16.503153</td>\n",
       "      <td>15.616490</td>\n",
       "      <td>0.886662</td>\n",
       "      <td>29.205809</td>\n",
       "      <td>0.197931</td>\n",
       "      <td>[C3, F3, Fz, Pz, T3, T5, O2, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>58.657513</td>\n",
       "      <td>57.035782</td>\n",
       "      <td>1.621731</td>\n",
       "      <td>78.568443</td>\n",
       "      <td>0.197931</td>\n",
       "      <td>[C3, F3, F4, Pz, T3, T5, O2, T6]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>33.550774</td>\n",
       "      <td>32.565361</td>\n",
       "      <td>0.985413</td>\n",
       "      <td>38.176292</td>\n",
       "      <td>0.198081</td>\n",
       "      <td>[P3, F3, Fz, C4, P4, Fp1, T3, O2, F7, F8, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.334967</td>\n",
       "      <td>24.472404</td>\n",
       "      <td>23.642111</td>\n",
       "      <td>0.830294</td>\n",
       "      <td>33.081669</td>\n",
       "      <td>0.309042</td>\n",
       "      <td>[F3, C4, P4, Fp2, O1, O2, F7, A2]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.158497</td>\n",
       "      <td>27.136068</td>\n",
       "      <td>26.241413</td>\n",
       "      <td>0.894655</td>\n",
       "      <td>33.895054</td>\n",
       "      <td>0.309092</td>\n",
       "      <td>[P3, Fz, F4, C4, Cz, Pz, T5, O2, F7]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>16.931602</td>\n",
       "      <td>15.959240</td>\n",
       "      <td>0.972363</td>\n",
       "      <td>24.574059</td>\n",
       "      <td>0.361561</td>\n",
       "      <td>[P3, F3, C4, Fp1, T3, T5, O2, A2, T4]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.315359</td>\n",
       "      <td>48.740765</td>\n",
       "      <td>47.796295</td>\n",
       "      <td>0.944469</td>\n",
       "      <td>61.247890</td>\n",
       "      <td>0.401735</td>\n",
       "      <td>[C3, F4, Pz, Fp1, T3, T5, O1, F8, T6, T4]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>7.808639</td>\n",
       "      <td>7.464830</td>\n",
       "      <td>0.343808</td>\n",
       "      <td>9.247889</td>\n",
       "      <td>0.401835</td>\n",
       "      <td>[C3, F3, P4, Cz, Fp1, Fp2, T5, F7, F8, A2, T6,...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  test_acc   val_acc  train_val_acc_diff  train_loss   val_loss  \\\n",
       "2    1.000000  0.545455  0.722222            0.277778   32.817829  32.028210   \n",
       "9    0.985294  0.454545  0.666667            0.318627   22.879484  21.967287   \n",
       "7    0.808824  0.454545  0.666667            0.142157   74.194389  72.482399   \n",
       "0    1.000000  0.681818  0.611111            0.388889   64.742279  62.454739   \n",
       "8    0.985294  0.545455  0.611111            0.374183   11.932382  12.023696   \n",
       "11   1.000000  0.636364  0.555556            0.444444   16.503153  15.616490   \n",
       "12   1.000000  0.454545  0.555556            0.444444   58.657513  57.035782   \n",
       "3    0.617647  0.636364  0.555556            0.062091   33.550774  32.565361   \n",
       "5    0.779412  0.545455  0.444444            0.334967   24.472404  23.642111   \n",
       "1    0.602941  0.500000  0.444444            0.158497   27.136068  26.241413   \n",
       "6    0.661765  0.363636  0.666667            0.004902   16.931602  15.959240   \n",
       "10   0.926471  0.500000  0.611111            0.315359   48.740765  47.796295   \n",
       "4    0.705882  0.409091  0.611111            0.094771    7.808639   7.464830   \n",
       "\n",
       "    train_val_loss_diff  test_loss    scores  \\\n",
       "2              0.789619  36.572292  0.077661   \n",
       "9              0.912197  25.614653  0.111461   \n",
       "7              1.711990  78.788872  0.111511   \n",
       "0              2.287540  62.451977  0.151735   \n",
       "8              0.091314  14.370240  0.151785   \n",
       "11             0.886662  29.205809  0.197931   \n",
       "12             1.621731  78.568443  0.197931   \n",
       "3              0.985413  38.176292  0.198081   \n",
       "5              0.830294  33.081669  0.309042   \n",
       "1              0.894655  33.895054  0.309092   \n",
       "6              0.972363  24.574059  0.361561   \n",
       "10             0.944469  61.247890  0.401735   \n",
       "4              0.343808   9.247889  0.401835   \n",
       "\n",
       "                                    channels_selected  sfreq  batch_size  \n",
       "2           [C3, F3, F4, C4, Pz, Fp1, T3, T5, O2, A2]  300.0         192  \n",
       "9                        [F3, Fz, Pz, T5, O2, F7, T6]  300.0          32  \n",
       "7                   [Fz, F4, C4, P4, Cz, Fp1, O2, A2]  256.0          96  \n",
       "0           [P3, F4, C4, P4, Cz, Pz, Fp2, O1, O2, F7]  128.0         160  \n",
       "8      [C3, F3, Fz, F4, P4, Pz, Fp1, Fp2, T5, F7, A2]  256.0          64  \n",
       "11                   [C3, F3, Fz, Pz, T3, T5, O2, T6]  300.0          32  \n",
       "12                   [C3, F3, F4, Pz, T3, T5, O2, T6]  300.0          96  \n",
       "3       [P3, F3, Fz, C4, P4, Fp1, T3, O2, F7, F8, A2]  256.0         192  \n",
       "5                   [F3, C4, P4, Fp2, O1, O2, F7, A2]  256.0         160  \n",
       "1                [P3, Fz, F4, C4, Cz, Pz, T5, O2, F7]  256.0          96  \n",
       "6               [P3, F3, C4, Fp1, T3, T5, O2, A2, T4]  256.0         224  \n",
       "10          [C3, F4, Pz, Fp1, T3, T5, O1, F8, T6, T4]  300.0         256  \n",
       "4   [C3, F3, P4, Cz, Fp1, Fp2, T5, F7, F8, A2, T6,...  128.0         160  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_optimizer.get_study_metrics(study).sort_values(by=\"scores\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">192</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_units'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_kernel_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_strides'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'conv1d_1_maxpool_strides'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'lstm_1_units'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'l2_reg_1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32177888907936236</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'l2_reg_2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18312650845396214</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'l2_reg_3'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7087872243296487</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'dropout_rate_1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30000000000000004</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'dropout_rate_2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30000000000000004</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m192\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'conv1d_1_units'\u001b[0m: \u001b[1;36m180\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'conv1d_1_kernel_size'\u001b[0m: \u001b[1;36m55\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'conv1d_1_strides'\u001b[0m: \u001b[1;36m26\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'conv1d_1_maxpool_strides'\u001b[0m: \u001b[1;36m3\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'lstm_1_units'\u001b[0m: \u001b[1;36m100\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'l2_reg_1'\u001b[0m: \u001b[1;36m0.32177888907936236\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'l2_reg_2'\u001b[0m: \u001b[1;36m0.18312650845396214\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'l2_reg_3'\u001b[0m: \u001b[1;36m0.7087872243296487\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'dropout_rate_1'\u001b[0m: \u001b[1;36m0.30000000000000004\u001b[0m,\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'dropout_rate_2'\u001b[0m: \u001b[1;36m0.30000000000000004\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test_accuracy = \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val_accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7222222089767456</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val_accuracy = \u001b[1;36m0.7222222089767456\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">channels_selected = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'C3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'F4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'C4'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Pz'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Fp1'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T3'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'T5'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'O2'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'A2'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "channels_selected = \u001b[1m[\u001b[0m\u001b[32m'C3'\u001b[0m \u001b[32m'F3'\u001b[0m \u001b[32m'F4'\u001b[0m \u001b[32m'C4'\u001b[0m \u001b[32m'Pz'\u001b[0m \u001b[32m'Fp1'\u001b[0m \u001b[32m'T3'\u001b[0m \u001b[32m'T5'\u001b[0m \u001b[32m'O2'\u001b[0m \u001b[32m'A2'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint({ k: v for k, v in study.best_trial.params.items() if not k.startswith(\"channels\") })\n",
    "rprint(\"test_accuracy =\", study.best_trial.user_attrs[\"trial_data\"][\"test_accuracy\"])\n",
    "rprint(\"val_accuracy =\", np.max(study.best_trial.user_attrs[\"trial_data\"][\"val_accuracy\"]))\n",
    "rprint(\"channels_selected =\", study.best_trial.user_attrs[\"trial_data\"][\"channels_selected\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
