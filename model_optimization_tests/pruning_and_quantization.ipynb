{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 22:37:42.967001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-19 22:37:42.967053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-19 22:37:42.968080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-19 22:37:42.974540: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 22:37:44.027894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arazzz/anaconda3/envs/moabb_model_optimization_quant/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "%load_ext tensorboard\n",
    "    \n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tf\"\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"0\"\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import keras\n",
    "    \n",
    "# region Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Permute, Dropout\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    ")\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "# endregion Keras\n",
    "\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_optim.utils import channels_to_channels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "# RNG = jax.random.PRNGKey(SKLRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Helper funcs\n",
    "def shallow_conv_net_square_layer(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "def shallow_conv_net_log_layer(x):\n",
    "    return tf.math.log(tf.clip_by_value(x, 1e-7, 10000))\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    \"shallow_conv_net_square_layer\": shallow_conv_net_square_layer, \n",
    "    \"shallow_conv_net_log_layer\": shallow_conv_net_log_layer \n",
    "}\n",
    "# endregion Helper funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_acc_diff</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_loss_diff</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>scores</th>\n",
       "      <th>channels_selected</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>subjects</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.575806</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>['P3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O2' 'T6']</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.755424</td>\n",
       "      <td>1.030562</td>\n",
       "      <td>0.275138</td>\n",
       "      <td>1.222213</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>['P3' 'C3' 'F3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O1' ...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/6772e2405e6e436faba83820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.277274</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.853020</td>\n",
       "      <td>['P3' 'C3' 'Fz' 'F4' 'C4' 'P4' 'F7' 'F8']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>11</td>\n",
       "      <td>./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>['C3' 'F3' 'C4' 'Cz' 'Fp2' 'T6']</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.305321</td>\n",
       "      <td>0.739283</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>['P3' 'C3' 'F3' 'C4' 'Cz' 'Pz' 'Fp2']</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>eeg_net</td>\n",
       "      <td>12</td>\n",
       "      <td>./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_number  train_acc  test_acc   val_acc  train_val_acc_diff  \\\n",
       "0             1   0.779412  0.681818  0.777778            0.001634   \n",
       "1             3   0.970588  0.681818  0.722222            0.248366   \n",
       "2             0   0.941176  0.727273  0.666667            0.274510   \n",
       "3            23   0.852941  0.727273  0.888889            0.035948   \n",
       "4            15   0.955882  0.818182  0.833333            0.122549   \n",
       "\n",
       "   train_loss  val_loss  train_val_loss_diff  test_loss    scores  \\\n",
       "0    0.451416  0.575806             0.124390   0.658583  0.299783   \n",
       "1    0.755424  1.030562             0.275138   1.222213  0.077861   \n",
       "2    0.501189  0.778463             0.277274   0.757358  0.853020   \n",
       "3    0.388678  0.429204             0.040526   0.646307  0.262646   \n",
       "4    0.432221  0.737542             0.305321   0.739283  0.028128   \n",
       "\n",
       "                                   channels_selected  sfreq  batch_size  \\\n",
       "0          ['P3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O2' 'T6']  256.0        32.0   \n",
       "1  ['P3' 'C3' 'F3' 'Fz' 'P4' 'Cz' 'T3' 'T5' 'O1' ...  256.0       256.0   \n",
       "2          ['P3' 'C3' 'Fz' 'F4' 'C4' 'P4' 'F7' 'F8']    NaN         NaN   \n",
       "3                   ['C3' 'F3' 'C4' 'Cz' 'Fp2' 'T6']  128.0       128.0   \n",
       "4              ['P3' 'C3' 'F3' 'C4' 'Cz' 'Pz' 'Fp2']  128.0        32.0   \n",
       "\n",
       "         model_name  subjects  \\\n",
       "0     deep_conv_net        11   \n",
       "1           eeg_net        11   \n",
       "2  shallow_conv_net        11   \n",
       "3     deep_conv_net        12   \n",
       "4           eeg_net        12   \n",
       "\n",
       "                                           file_path  \n",
       "0  ./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb...  \n",
       "1  ./temp/FatigueMI/[11]/6772e2405e6e436faba83820...  \n",
       "2  ./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd...  \n",
       "3  ./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e407...  \n",
       "4  ./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_df = pd.read_csv(\"./final/best_models.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "best_models_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[11]/2e54fc7d125447c096b49ecb93fd4f9a/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[11]/6772e2405e6e436faba8382021d362e4/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[11]/e0643f9a780146a4adc15ddd4a9ff053/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[12]/259f8d3cf7ce4e5283e8e4071f15f07a/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[12]/96dc576945fb4f2db582d66ae1d2c8ce/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[12]/fa0faed8a6ce4a52a2b9ca5d120893ed/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[4]/3623cb4ba1ad4a908c9098f5297a6778/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[4]/52166a0614d541acb9b9ef965eed5de2/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[4]/72578c4a27b64a8e989fd90727f209ad/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[6]/0614f3b1603b4442a2cc79ade04a6a0d/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[6]/7ec6d62fc9a84597a65261efcb6e808a/model/shallow_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[6]/969f098d0f9344e5baa14cc429e2471b/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[9]/0113b240ca004b67b81ca0fd5df6dd6e/model/deep_conv_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[9]/63a8c87ffc02471893db5ac9a0781946/model/shallow_conv_net_study_best_trial.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/FatigueMI/[9]/fd4945e8633f4c0ab473e7520efcfee6/model/eeg_net_study.npy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/2e54fc7d125447c096b49ecb93fd4f9a/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/6772e2405e6e436faba8382021d362e4/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/e0643f9a780146a4adc15ddd4a9ff053/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/259f8d3cf7ce4e5283e8e4071f15f07a/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/96dc576945fb4f2db582d66ae1d2c8ce/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/fa0faed8a6ce4a52a2b9ca5d120893ed/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/3623cb4ba1ad4a908c9098f5297a6778/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/52166a0614d541acb9b9ef965eed5de2/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m19\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/72578c4a27b64a8e989fd90727f209ad/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/0614f3b1603b4442a2cc79ade04a6a0d/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/7ec6d62fc9a84597a65261efcb6e808a/model/shallow_conv_net_study.npy'\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/969f098d0f9344e5baa14cc429e2471b/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/0113b240ca004b67b81ca0fd5df6dd6e/model/deep_conv_net_study.npy'\u001b[0m, \u001b[1;36m13\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/63a8c87ffc02471893db5ac9a0781946/model/shallow_conv_net_study_best_trial.npy'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'./temp/FatigueMI/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/fd4945e8633f4c0ab473e7520efcfee6/model/eeg_net_study.npy'\u001b[0m, \u001b[1;36m19\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject_best_file_paths = best_models_df[['file_path']].to_numpy().flatten().tolist()\n",
    "subject_best_trial_numbers = best_models_df[['trial_number']].to_numpy().flatten().tolist()\n",
    "subject_best_trials = list(zip(subject_best_file_paths, subject_best_trial_numbers))\n",
    "rpprint(subject_best_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_best_trials = glob.glob('./temp_v2/**/model/shallow_conv_net_study_best_trial.npy', recursive=True)\n",
    "# subject_best_trials = sorted(subject_best_trials, key=lambda x: os.path.getmtime(x))\n",
    "# subject_best_trials = sorted(subject_best_trials, key=lambda x: int(re.compile(r\"\\[.*\\]\").search(x).group(0).strip(\"[]\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_trial_from_study(study_idx, subject_best_trials):\n",
    "    study_path = subject_best_trials[study_idx][0]\n",
    "    study = np.load(study_path, allow_pickle=True).item()\n",
    "    trial = study.trials[subject_best_trials[study_idx][1]] if hasattr(study, \"trials\") else study\n",
    "\n",
    "    model_info = {\n",
    "        \"subject\": trial.user_attrs[\"trial_data\"][\"subject\"] if hasattr(trial.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(study_path).group(0).strip(\"[]\")),\n",
    "        \"sfreq\": trial.params[\"sfreq\"] if \"sfreq\" in trial.params and not trial.params[\"sfreq\"] == None else trial.user_attrs['trial_data']['sfreq'] if \"sfreq\" in trial.user_attrs['trial_data'] else 128,\n",
    "        \"batch_size\": trial.params[\"batch_size\"] if \"batch_size\" in trial.params else 128,\n",
    "        \"channels_selected\": trial.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "        \"channels_idx_selected\": channels_to_channels_idx(trial.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "        \"model\": tf.keras.models.model_from_json(trial.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "        \"test_acc\": trial.user_attrs[\"trial_data\"][\"test_accuracy\"],\n",
    "        \"model_name\": trial.user_attrs[\"trial_data\"]['model_name'] if \"model_name\" in trial.user_attrs[\"trial_data\"] else \"shallow_conv_net\",\n",
    "    }\n",
    "    if \"weights\" in trial.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(trial.user_attrs[\"trial_data\"][\"weights\"])\n",
    "    elif \"model_weights\" in trial.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(trial.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "\n",
    "    return model_info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def load_best_trial(subject_best_trial):\n",
    "#     model = np.load(subject_best_trials[0], allow_pickle=True).item()\n",
    "#     model_info = {\n",
    "#         \"subject\": model.user_attrs[\"trial_data\"][\"subject\"] if hasattr(model.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(model.user_attrs[\"trial_data\"][\"data_path\"]).group(0).strip(\"[]\")),\n",
    "#         \"sfreq\": model.params[\"sfreq\"] if \"sfreq\" in model.params else 128,\n",
    "#         \"batch_size\": model.params[\"batch_size\"] if \"batch_size\" in model.params else 128,\n",
    "#         \"channels_selected\": model.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "#         \"channels_idx_selected\": channels_to_channels_idx(model.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "#         \"model\": tf.keras.models.model_from_json(model.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "#         \"test_acc\": model.user_attrs[\"trial_data\"][\"test_accuracy\"],\n",
    "#         \"model_name\": model.user_attrs[\"trial_data\"][\"model_name\"] if hasattr(model.user_attrs[\"trial_data\"], \"model_name\") else \"shallow_conv_net\"\n",
    "#     }\n",
    "#     if \"weights\" in model.user_attrs[\"trial_data\"]:\n",
    "#         model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "#     elif \"model_weights\" in model.user_attrs[\"trial_data\"]:\n",
    "#         model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "    \n",
    "#     return model_info\n",
    "\n",
    "def create_and_save_baseline_model(model_info, train_test_data, results_folder):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    model_info[\"model\"].compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    baseline_model_test = model_info[\"model\"].evaluate(X_test, y_test, batch_size=model_info[\"batch_size\"])\n",
    "    rpprint(baseline_model_test)\n",
    "\n",
    "    baseline_test_acc = baseline_model_test[1]\n",
    "\n",
    "    _, keras_file = None, results_folder + \"baseline_model.h5\"\n",
    "    tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n",
    "    return {\n",
    "        \"keras_file\": keras_file,\n",
    "        \"baseline_test_acc\": baseline_test_acc,\n",
    "        \"baseline_model\": model_info[\"model\"],\n",
    "    }\n",
    "\n",
    "def weight_prune_dense_layer(k_weights, b_weights, k_sparsity):\n",
    "    # Copy the kernel weights and get ranked indeces of the abs\n",
    "    kernel_weights = np.copy(k_weights)\n",
    "    kernel_weight_idx_by_magnitude = np.argsort(np.abs(kernel_weights), axis=None) # rank the individual weights in weight matrix according to their magnitude (absolute value)\n",
    "\n",
    "    kernel_weights_sparse_idx = kernel_weight_idx_by_magnitude[0:int(len(kernel_weight_idx_by_magnitude)*k_sparsity)]\n",
    "    kernel_weights[np.unravel_index(kernel_weights_sparse_idx, kernel_weights.shape) if len(kernel_weights_sparse_idx) > 0 else kernel_weights_sparse_idx] = 0\n",
    "\n",
    "    if b_weights is None:\n",
    "        return kernel_weights, None\n",
    "    \n",
    "    bias_weights = np.copy(b_weights)\n",
    "    bias_weights_idx_by_magnitude = np.argsort(np.abs(bias_weights), axis=None) # rank the individual weights in weight matrix according to their magnitude (absolute value)\n",
    "\n",
    "    bias_weights_sparse_idx = bias_weights_idx_by_magnitude[0:int(len(bias_weights_idx_by_magnitude)*k_sparsity)]\n",
    "    bias_weights[np.unravel_index(bias_weights_sparse_idx, bias_weights.shape)] = 0\n",
    "\n",
    "    return kernel_weights, bias_weights\n",
    "\n",
    "def prune_model(model_info, train_test_data, target_sparsity, results_folder):\n",
    "\n",
    "    X_train, y_train = train_test_data[\"X_train\"], train_test_data[\"y_train\"]\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    # batch_size = model_info[\"batch_size\"]\n",
    "    # epochs = 2\n",
    "    # end_step = np.ceil(len(X_train) / batch_size).astype(np.int32) * epochs\n",
    "    # # Define model for pruning.\n",
    "    # pruning_params = {\n",
    "    #     # 'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=target_sparsity, begin_step=0, frequency=1),\n",
    "    #     'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.00,\n",
    "    #                                                             final_sparsity=target_sparsity,\n",
    "    #                                                             begin_step=0,\n",
    "    #                                                             end_step=end_step,\n",
    "    #                                                             frequency=1)\n",
    "    # }\n",
    "    # keras.utils.get_custom_objects().update({\n",
    "    #     **CUSTOM_OBJECTS\n",
    "    # })\n",
    "    # baseline_model_copy = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    # model_for_pruning = prune_low_magnitude(baseline_model_copy, **pruning_params)\n",
    "    # # `prune_low_magnitude` requires a recompile.\n",
    "    # model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    keras.utils.get_custom_objects().update(CUSTOM_OBJECTS)\n",
    "    sparse_model = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    sparse_model.set_weights(model_info[\"model\"].get_weights())\n",
    "    for layer in model_info[\"model\"].layers:\n",
    "        if \"input\" in layer.name or len(layer.trainable_weights) == 0:\n",
    "            continue\n",
    "        if \"batch_normalization\" in layer.name:\n",
    "            continue\n",
    "        W = layer.get_weights()[0]\n",
    "        b = None\n",
    "        if \"batch_normalization\" not in layer.name and layer.use_bias:\n",
    "            b = layer.get_weights()[1]\n",
    "\n",
    "        kernel_weights, bias_weights = weight_prune_dense_layer(W, b, target_sparsity)\n",
    "        # if pruning=='weight':\n",
    "            # rprint(layer.name, W.shape)\n",
    "        # elif pruning=='unit':\n",
    "        #     kernel_weights, bias_weights = unit_prune_dense_layer(W, b, k_sparsity)\n",
    "\n",
    "        sparse_model.get_layer(layer.name).set_weights([kernel_weights, bias_weights] if b is not None else [kernel_weights])\n",
    "\n",
    "    sparse_model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    model_for_pruning = sparse_model\n",
    "\n",
    "    # logdir = \"logs/pruning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # callbacks = [\n",
    "    #     tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    #     tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    # ]\n",
    "\n",
    "    # model_for_pruning.fit(X_train, y_train, batch_size=model_info[\"batch_size\"], epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "    _, model_for_pruning_accuracy = model_for_pruning.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    _, pruned_keras_file = None, results_folder + \"pruned_model.h5\"\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "\n",
    "    return {\n",
    "        \"pruned_model\": model_for_export,\n",
    "        \"pruned_model_test_acc\": model_for_pruning_accuracy,\n",
    "        \"pruned_keras_file\": pruned_keras_file\n",
    "    }\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    \n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def convert_pruned_model_to_tflite(pruned_model, sparsity, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # converter.target_spec.supported_types = [quantization]\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def convert_pruned_model_to_tflite_with_quantization(pruned_model, sparsity, quantization, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    if quantization == 'float16':\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    elif quantization == 'int8':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Quantization type {quantization} not implemented.\")\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity_{quantization}_quant.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_quant_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_quant_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def get_test_acc_non_tf_lite(model, train_test_data):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # Evaluate prediction accuracy of pruned model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=0)\n",
    "\n",
    "    # Evaluate Inference Time of pruned model\n",
    "    start_time = time.time()\n",
    "    prediction = model.predict(X_test)\n",
    "    exec_time = (time.time() - start_time)/X_test.shape[0]\n",
    "    return {\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"avg_exec_time\": exec_time\n",
    "    }\n",
    "\n",
    "def get_test_acc(model, train_test_data):\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "    def evaluate_model(interpreter):\n",
    "        input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        # signatures = interpreter.get_signature_list()\n",
    "        # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "        # Run predictions on every image in the \"test\" dataset.\n",
    "        predictions = []\n",
    "        exec_times = []\n",
    "        for i, v in enumerate(X_test):\n",
    "            v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "            # if i % 1000 == 0:\n",
    "            #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "            # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "            # # the model's input data format.\n",
    "            # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, v)\n",
    "\n",
    "            # Run inference.\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            exec_time = (time.time() - start_time)\n",
    "            exec_times.append(exec_time)\n",
    "\n",
    "            # Post-processing: remove batch dimension and find the digit with highest\n",
    "            # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "            predictions.append(class_prediction)\n",
    "\n",
    "        print('\\n')\n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        predictions = np.asarray(predictions)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "        avg_exec_time = np.mean(exec_times)\n",
    "        return accuracy, avg_exec_time\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    test_accuracy, avg_exec_time = evaluate_model(interpreter)\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"avg_exec_time\": avg_exec_time\n",
    "    }\n",
    "\n",
    "def get_model_weights_sparsity(model):\n",
    "    sparsity_levels = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "\n",
    "        for weight in weights:\n",
    "            # if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
    "            #     continue\n",
    "            weight_size = weight.numpy().size\n",
    "            zero_num = np.count_nonzero(weight == 0)\n",
    "            sparsity_levels.append((\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\",\n",
    "            ))\n",
    "    return sparsity_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Loading best trial model<span style=\"color: #808000; text-decoration-color: #808000\">...</span> .<span style=\"color: #800080; text-decoration-color: #800080\">/temp/FatigueMI/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/2e54fc7d125447c096b49ecb93fd4f9a/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">deep_conv_net_study.npy</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Loading best trial model\u001b[33m...\u001b[0m .\u001b[35m/temp/FatigueMI/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/2e54fc7d125447c096b49ecb93fd4f9a/model/\u001b[0m\u001b[95mdeep_conv_net_study.npy\u001b[0m \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'sfreq'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'channels_selected'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'P3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Fz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'P4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Cz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'T3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'T5'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'O2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'T6'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&lt;U3'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'channels_idx_selected'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;tf_keras.src.engine.functional.Functional object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f75655c7c10</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'deep_conv_net'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'subject'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'sfreq'\u001b[0m: \u001b[1;36m256\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'channels_selected'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'P3'\u001b[0m, \u001b[32m'Fz'\u001b[0m, \u001b[32m'P4'\u001b[0m, \u001b[32m'Cz'\u001b[0m, \u001b[32m'T3'\u001b[0m, \u001b[32m'T5'\u001b[0m, \u001b[32m'O2'\u001b[0m, \u001b[32m'T6'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mU3\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'channels_idx_selected'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m6\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m11\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m12\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m14\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'model'\u001b[0m\u001b[39m: <tf_keras.src.engine.functional.Functional object at \u001b[0m\u001b[1;36m0x7f75655c7c10\u001b[0m\u001b[1m>\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'deep_conv_net'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f76027b1080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f76027b0f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 727ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmnh342d4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmnh342d4/assets\n",
      "2024-04-19 22:52:49.537172: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:52:49.537248: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:52:49.537807: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpmnh342d4\n",
      "2024-04-19 22:52:49.541155: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:52:49.541220: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpmnh342d4\n",
      "2024-04-19 22:52:49.550669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-19 22:52:49.555874: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:52:49.610981: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpmnh342d4\n",
      "2024-04-19 22:52:49.641879: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 104083 microseconds.\n",
      "2024-04-19 22:52:49.684372: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model_0_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558932.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558932.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558928.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m558928.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">549773.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m549773.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmiv24nzv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmiv24nzv/assets\n",
      "2024-04-19 22:52:52.736549: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:52:52.736628: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:52:52.736815: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpmiv24nzv\n",
      "2024-04-19 22:52:52.739330: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:52:52.739363: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpmiv24nzv\n",
      "2024-04-19 22:52:52.746913: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:52:52.808047: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpmiv24nzv\n",
      "2024-04-19 22:52:52.838800: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 101985 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 44, % non-converted = 29.55 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f16: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 12)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model_0_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558932.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558932.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272537.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m272537.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181818181818</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.6818181818181818\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp_6z5lvo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp_6z5lvo/assets\n",
      "2024-04-19 22:53:00.354579: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:00.354659: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:00.355065: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpp_6z5lvo\n",
      "2024-04-19 22:53:00.358726: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:00.358776: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpp_6z5lvo\n",
      "2024-04-19 22:53:00.367758: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:00.425251: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpp_6z5lvo\n",
      "2024-04-19 22:53:00.452766: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 97710 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model_0_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558926.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558926.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558922.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m558922.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">549767.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m549767.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp32zfc9jl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp32zfc9jl/assets\n",
      "2024-04-19 22:53:03.430616: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:03.430673: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:03.430908: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp32zfc9jl\n",
      "2024-04-19 22:53:03.434093: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:03.434133: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp32zfc9jl\n",
      "2024-04-19 22:53:03.442595: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:03.493654: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp32zfc9jl\n",
      "2024-04-19 22:53:03.513493: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 82584 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 32, % non-converted = 25.00 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 7, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (uq_8: 5)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model_0_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558926.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558926.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151485.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m151485.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181818181818</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.6818181818181818\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.1/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.1/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 581ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.1/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpepdrodw_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpepdrodw_/assets\n",
      "2024-04-19 22:53:15.848707: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:15.848769: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:15.848965: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpepdrodw_\n",
      "2024-04-19 22:53:15.851437: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:15.851459: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpepdrodw_\n",
      "2024-04-19 22:53:15.858596: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:15.915018: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpepdrodw_\n",
      "2024-04-19 22:53:15.938661: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 89698 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model_0.1_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558936.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558936.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">520823.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m520823.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512072.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m512072.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpauw1of74/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpauw1of74/assets\n",
      "2024-04-19 22:53:19.533523: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:19.533638: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:19.533931: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpauw1of74\n",
      "2024-04-19 22:53:19.538941: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:19.539020: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpauw1of74\n",
      "2024-04-19 22:53:19.551318: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:19.623205: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpauw1of74\n",
      "2024-04-19 22:53:19.642582: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 108657 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 44, % non-converted = 29.55 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f16: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 12)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model_0.1_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558936.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558936.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">259821.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m259821.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181818181818</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.6818181818181818\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.1/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1zik6cg3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1zik6cg3/assets\n",
      "2024-04-19 22:53:27.048865: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:27.049020: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:27.049442: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp1zik6cg3\n",
      "2024-04-19 22:53:27.052262: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:27.052289: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp1zik6cg3\n",
      "2024-04-19 22:53:27.059847: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:27.107511: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp1zik6cg3\n",
      "2024-04-19 22:53:27.132710: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 83274 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model_0.1_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558930.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558930.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">520817.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m520817.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512066.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m512066.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplahqc26v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplahqc26v/assets\n",
      "2024-04-19 22:53:30.005240: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:30.005421: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:30.005949: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmplahqc26v\n",
      "2024-04-19 22:53:30.009337: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:30.009389: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmplahqc26v\n",
      "2024-04-19 22:53:30.015683: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:30.064818: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmplahqc26v\n",
      "2024-04-19 22:53:30.091524: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 85590 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 32, % non-converted = 25.00 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 7, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (uq_8: 5)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model_0.1_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558930.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558930.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">144510.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m144510.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181818181818</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.6818181818181818\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.6818181872367859\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.5/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.5/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5454545617103577\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 548ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.5/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5454545617103577\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvvt5abel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvvt5abel/assets\n",
      "2024-04-19 22:53:43.619711: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:43.619772: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:43.619931: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpvvt5abel\n",
      "2024-04-19 22:53:43.622878: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:43.622901: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpvvt5abel\n",
      "2024-04-19 22:53:43.629496: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:43.684476: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpvvt5abel\n",
      "2024-04-19 22:53:43.705542: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 85610 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model_0.5_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558936.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558936.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322376.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m322376.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315338.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m315338.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiw4rh8ct/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiw4rh8ct/assets\n",
      "2024-04-19 22:53:46.893845: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:46.893891: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:46.894064: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpiw4rh8ct\n",
      "2024-04-19 22:53:46.896847: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:46.896882: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpiw4rh8ct\n",
      "2024-04-19 22:53:46.905544: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:46.967626: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpiw4rh8ct\n",
      "2024-04-19 22:53:46.989901: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 95838 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 44, % non-converted = 29.55 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f16: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 12)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model_0.5_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558936.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558936.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">169890.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m169890.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545454545454</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5454545454545454\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.5/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5454545617103577\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0di2hiy0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0di2hiy0/assets\n",
      "2024-04-19 22:53:53.352581: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:53.352676: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:53.352930: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp0di2hiy0\n",
      "2024-04-19 22:53:53.356347: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:53.356509: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp0di2hiy0\n",
      "2024-04-19 22:53:53.365154: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:53.424462: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp0di2hiy0\n",
      "2024-04-19 22:53:53.450540: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 97614 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model_0.5_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558930.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558930.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322370.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m322370.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315332.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m315332.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl4sw28x1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl4sw28x1/assets\n",
      "2024-04-19 22:53:57.241443: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:53:57.241492: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:53:57.241650: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpl4sw28x1\n",
      "2024-04-19 22:53:57.244612: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:53:57.244791: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpl4sw28x1\n",
      "2024-04-19 22:53:57.257083: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:53:57.307848: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpl4sw28x1\n",
      "2024-04-19 22:53:57.336327: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 94678 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 32, % non-converted = 25.00 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 7, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (uq_8: 5)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model_0.5_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558930.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558930.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104031.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m104031.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545454545454</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5454545454545454\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.9/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.9/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 583ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.9/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjk3cjrsl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjk3cjrsl/assets\n",
      "2024-04-19 22:54:09.969383: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:54:09.969436: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:54:09.969580: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpjk3cjrsl\n",
      "2024-04-19 22:54:09.972281: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:54:09.972294: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpjk3cjrsl\n",
      "2024-04-19 22:54:09.978422: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:54:10.032431: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpjk3cjrsl\n",
      "2024-04-19 22:54:10.059050: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 89470 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model_0.9_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558936.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558936.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86540.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m86540.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79799.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m79799.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuse8onla/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuse8onla/assets\n",
      "2024-04-19 22:54:13.014321: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:54:13.014396: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:54:13.014589: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpuse8onla\n",
      "2024-04-19 22:54:13.017040: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:54:13.017072: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpuse8onla\n",
      "2024-04-19 22:54:13.023810: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:54:13.077278: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpuse8onla\n",
      "2024-04-19 22:54:13.100098: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 85510 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 44, % non-converted = 29.55 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f16: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 12)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model_0.9_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558936.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558936.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48884.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m48884.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Model: deep_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m11\u001b[0m, Model: deep_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6585825085639954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6585825085639954\u001b[0m, \u001b[1;36m0.6818181872367859\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:56: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/11/deep_conv_net/0.9/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/1856983060.py:148: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/11/deep_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq164zxsp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq164zxsp/assets\n",
      "2024-04-19 22:54:20.685196: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:54:20.685272: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:54:20.685479: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpq164zxsp\n",
      "2024-04-19 22:54:20.688474: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:54:20.688503: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpq164zxsp\n",
      "2024-04-19 22:54:20.695089: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:54:20.762479: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpq164zxsp\n",
      "2024-04-19 22:54:20.789031: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 103555 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 32, % non-converted = 40.62 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/11/deep_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model_0.9_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558930.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558930.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86534.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m86534.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79793.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m79793.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoir36j3k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoir36j3k/assets\n",
      "2024-04-19 22:54:23.721991: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 22:54:23.722263: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 22:54:23.722849: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpoir36j3k\n",
      "2024-04-19 22:54:23.727476: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 22:54:23.727537: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpoir36j3k\n",
      "2024-04-19 22:54:23.736061: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 22:54:23.786274: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpoir36j3k\n",
      "2024-04-19 22:54:23.814560: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 91717 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 32, % non-converted = 25.00 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 7, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (uq_8: 5)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/11/deep_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/11/deep_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model_0.9_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558930.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m558930.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34894.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m34894.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Folder structure for results: ./results/{subject}/{model}/{sparsity}/{quantization}/\n",
    "\n",
    "sparsity_levels = [0, 0.1, 0.5, 0.9]\n",
    "quantization_levels = [None, 'float16', 'int8']\n",
    "\n",
    "results_data = {\n",
    "    \"subject\": [],\n",
    "    \"model_name\": [],\n",
    "    \"sparsity\": [],\n",
    "    \"quantization\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"model_size\": [],\n",
    "    \"inf_time\": [],\n",
    "    \"weights_sparsity\": [],\n",
    "}\n",
    "\n",
    "for study_idx in range(len(subject_best_trials)):\n",
    "    if study_idx > 0: # Only test the first subject for now\n",
    "        break\n",
    "\n",
    "    rprint(\"\\n\\n\\nLoading best trial model...\", subject_best_trials[study_idx][0], subject_best_trials[study_idx][1])\n",
    "\n",
    "    model_info = load_best_trial_from_study(study_idx, subject_best_trials)\n",
    "    subject = model_info[\"subject\"]\n",
    "    model_name = model_info[\"model_name\"]\n",
    "\n",
    "    rpprint(model_info)\n",
    "\n",
    "    X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "    y_encoded = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "    train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "    for sparsity in sparsity_levels:\n",
    "        for quantization in quantization_levels:\n",
    "\n",
    "            rprint(f\"\\n\\n\\nSubject: {subject}, Model: {model_name}, Sparsity: {sparsity}, Quantization: {quantization}\\n\\n\")\n",
    "\n",
    "            results_folder = f\"./results/{subject}/{model_name}/{sparsity}/{quantization}/\"\n",
    "            os.makedirs(results_folder, exist_ok=True) if not os.path.exists(results_folder) else None # Make folder if doesn't exist\n",
    "\n",
    "            # region 1) ------------- Build & save baseline model ------------- \n",
    "            rprint(\"Building & saving baseline model...\")\n",
    "            baseline_model_info = create_and_save_baseline_model(**{\n",
    "                \"model_info\": model_info,\n",
    "                \"results_folder\": results_folder,\n",
    "                \"train_test_data\": train_test_data\n",
    "            })\n",
    "            keras_file, baseline_test_acc = baseline_model_info[\"keras_file\"], baseline_model_info[\"baseline_test_acc\"]\n",
    "            rprint('Saved baseline model to:', keras_file)\n",
    "            # endregion\n",
    "\n",
    "            # region 2) ------------- Pruning the baseline model -------------\n",
    "            rprint(\"Pruning the baseline model...\")\n",
    "            pruned_model_info = prune_model(**{\n",
    "                \"target_sparsity\": sparsity,\n",
    "                \"model_info\": model_info,\n",
    "                \"train_test_data\": train_test_data,\n",
    "                \"results_folder\": results_folder\n",
    "            })\n",
    "            \n",
    "            pruned_model = pruned_model_info[\"pruned_model\"]\n",
    "            pruned_model_test_acc, pruned_keras_file = pruned_model_info[\"pruned_model_test_acc\"], pruned_model_info[\"pruned_keras_file\"]\n",
    "            pruned_model_weights_sparsity = get_model_weights_sparsity(pruned_model)\n",
    "            model_weights_sparsity = pruned_model_weights_sparsity\n",
    "\n",
    "            rprint(f'Saved pruned Keras model with {sparsity*100}% sparsity to:', pruned_keras_file)\n",
    "            rpprint({\n",
    "                'Baseline test accuracy': baseline_test_acc,\n",
    "                'Pruned test accuracy': pruned_model_test_acc\n",
    "            })\n",
    "            # endregion\n",
    "\n",
    "            # region 3) ------------- Converting pruned model to TFLite -------------        \n",
    "            if quantization != None:\n",
    "                tflite_model_info = convert_pruned_model_to_tflite(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                pruned_tflite_model, pruned_tflite_file = tflite_model_info[\"pruned_tflite_model\"], tflite_model_info[\"pruned_tflite_file\"]\n",
    "                \n",
    "                rprint('Saved pruned TFLite model to:', pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "                rprint(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "            else:\n",
    "                pruned_tflite_model, pruned_tflite_file = None, None\n",
    "            # endregion\n",
    "\n",
    "            # region 4) ------------- Quantizing pruned TFLite model ------------- \n",
    "            if quantization != None:\n",
    "                tflite_quant_model_info = convert_pruned_model_to_tflite_with_quantization(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"quantization\": quantization,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                quantized_and_pruned_tflite_model = tflite_quant_model_info[\"pruned_quant_tflite_model\"]\n",
    "                quantized_and_pruned_tflite_file = tflite_quant_model_info[\"pruned_quant_tflite_file\"]\n",
    "\n",
    "                rprint('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "            else:\n",
    "                quantized_and_pruned_tflite_model, quantized_and_pruned_tflite_file = None, None\n",
    "            \n",
    "            # endregion\n",
    "\n",
    "            # region 5) ------------- Evaluation check -------------\n",
    "            if quantization != None:\n",
    "                tflite_quant_model_test_acc_results = get_test_acc(**{\n",
    "                    \"model\": quantized_and_pruned_tflite_model, \n",
    "                    \"train_test_data\": train_test_data\n",
    "                })\n",
    "                tflite_quant_model_test_acc = tflite_quant_model_test_acc_results[\"test_accuracy\"]\n",
    "\n",
    "                rprint('Pruned and quantized TFLite test_accuracy:', tflite_quant_model_test_acc)\n",
    "                rprint('Pruned TF test accuracy:', pruned_model_test_acc)\n",
    "            # endregion\n",
    "            \n",
    "            # region 6) ------------- Saving results -------------\n",
    "            if quantization != None:\n",
    "                model_objs = [{ \"model\": quantized_and_pruned_tflite_model, \"file\": quantized_and_pruned_tflite_file, \"tf_lite\": True, \"weights_sparsity\": model_weights_sparsity }]\n",
    "            else:\n",
    "                model_objs = [{ \"model\": pruned_model, \"file\": pruned_keras_file, \"tf_lite\": False, \"weights_sparsity\": model_weights_sparsity }]\n",
    "                \n",
    "            for model_obj in model_objs:\n",
    "                model_to_evaluate = model_obj[\"model\"]\n",
    "                model_file_to_evaluate = model_obj[\"file\"]\n",
    "                model_is_tf_lite = model_obj[\"tf_lite\"]\n",
    "                model_weights_sparsity = model_obj[\"weights_sparsity\"]\n",
    "\n",
    "                if model_to_evaluate == None or model_file_to_evaluate == None:\n",
    "                    continue\n",
    "\n",
    "                # 1) Test accuracy & inference time\n",
    "                if model_is_tf_lite:\n",
    "                    eval_res = get_test_acc(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                else:\n",
    "                    eval_res = get_test_acc_non_tf_lite(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                test_acc = eval_res[\"test_accuracy\"]\n",
    "                inf_time = eval_res[\"avg_exec_time\"]\n",
    "                # 2) Model size\n",
    "                model_size = get_gzipped_model_size(model_file_to_evaluate)\n",
    "\n",
    "                results_data[\"subject\"].append(subject)\n",
    "                results_data[\"model_name\"].append(model_name)\n",
    "                results_data[\"sparsity\"].append(sparsity)\n",
    "                results_data[\"quantization\"].append(quantization)\n",
    "                \n",
    "                results_data[\"test_acc\"].append(test_acc)\n",
    "                results_data[\"model_size\"].append(model_size)\n",
    "                results_data[\"inf_time\"].append(inf_time)\n",
    "\n",
    "                results_data[\"weights_sparsity\"].append(model_weights_sparsity)\n",
    "            # endregion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>quantization</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>model_size</th>\n",
       "      <th>inf_time</th>\n",
       "      <th>weights_sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>558922</td>\n",
       "      <td>0.039502</td>\n",
       "      <td>[(conv2d_90/kernel:0: 0.00% sparsity , (0/125)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>272537</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>[(conv2d_90/kernel:0: 0.00% sparsity , (0/125)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>151485</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>[(conv2d_90/kernel:0: 0.00% sparsity , (0/125)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>520817</td>\n",
       "      <td>0.038553</td>\n",
       "      <td>[(conv2d_90/kernel:0: 9.60% sparsity , (12/125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>259821</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>[(conv2d_90/kernel:0: 9.60% sparsity , (12/125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>144510</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>[(conv2d_90/kernel:0: 9.60% sparsity , (12/125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>322370</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>[(conv2d_90/kernel:0: 49.60% sparsity , (62/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>169890</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>[(conv2d_90/kernel:0: 49.60% sparsity , (62/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>104031</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>[(conv2d_90/kernel:0: 49.60% sparsity , (62/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>86534</td>\n",
       "      <td>0.033555</td>\n",
       "      <td>[(conv2d_90/kernel:0: 89.60% sparsity , (112/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>[(conv2d_90/kernel:0: 89.60% sparsity , (112/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>deep_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>34894</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>[(conv2d_90/kernel:0: 89.60% sparsity , (112/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject     model_name  sparsity quantization  test_acc  model_size  \\\n",
       "0        11  deep_conv_net       0.0         None  0.681818      558922   \n",
       "1        11  deep_conv_net       0.0      float16  0.681818      272537   \n",
       "2        11  deep_conv_net       0.0         int8  0.681818      151485   \n",
       "3        11  deep_conv_net       0.1         None  0.681818      520817   \n",
       "4        11  deep_conv_net       0.1      float16  0.681818      259821   \n",
       "5        11  deep_conv_net       0.1         int8  0.681818      144510   \n",
       "6        11  deep_conv_net       0.5         None  0.545455      322370   \n",
       "7        11  deep_conv_net       0.5      float16  0.545455      169890   \n",
       "8        11  deep_conv_net       0.5         int8  0.545455      104031   \n",
       "9        11  deep_conv_net       0.9         None  0.500000       86534   \n",
       "10       11  deep_conv_net       0.9      float16  0.500000       48884   \n",
       "11       11  deep_conv_net       0.9         int8  0.500000       34894   \n",
       "\n",
       "    inf_time                                   weights_sparsity  \n",
       "0   0.039502  [(conv2d_90/kernel:0: 0.00% sparsity , (0/125)...  \n",
       "1   0.000730  [(conv2d_90/kernel:0: 0.00% sparsity , (0/125)...  \n",
       "2   0.001193  [(conv2d_90/kernel:0: 0.00% sparsity , (0/125)...  \n",
       "3   0.038553  [(conv2d_90/kernel:0: 9.60% sparsity , (12/125...  \n",
       "4   0.000892  [(conv2d_90/kernel:0: 9.60% sparsity , (12/125...  \n",
       "5   0.001130  [(conv2d_90/kernel:0: 9.60% sparsity , (12/125...  \n",
       "6   0.035796  [(conv2d_90/kernel:0: 49.60% sparsity , (62/12...  \n",
       "7   0.000749  [(conv2d_90/kernel:0: 49.60% sparsity , (62/12...  \n",
       "8   0.001307  [(conv2d_90/kernel:0: 49.60% sparsity , (62/12...  \n",
       "9   0.033555  [(conv2d_90/kernel:0: 89.60% sparsity , (112/1...  \n",
       "10  0.000876  [(conv2d_90/kernel:0: 89.60% sparsity , (112/1...  \n",
       "11  0.001471  [(conv2d_90/kernel:0: 89.60% sparsity , (112/1...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data_df = pd.DataFrame(results_data)\n",
    "results_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296125/3253146802.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  results_data_df.groupby(\"sparsity\").mean().plot.bar(y=\"test_acc\", rot=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sparsity'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_data_df.groupby(\"sparsity\").mean().plot.bar(y=\"test_acc\", rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning [0, 0.1, 0.5, 0.9]\n",
    "# 1. Load the best model\n",
    "# 2. Loop through its layers\n",
    "# 3. At each layer, set a random % of weights to zero (% sparsity)\n",
    "# 4. Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
