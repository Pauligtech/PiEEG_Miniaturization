{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# region General Imports\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import copy\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from rich import print as rprint\n",
    "from rich.pretty import pprint as rpprint\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "# endregion General Imports\n",
    "\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "%load_ext tensorboard\n",
    "    \n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tf\"\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"0\"\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import keras\n",
    "    \n",
    "# region Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Permute, Dropout\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    ")\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "# endregion Keras\n",
    "\n",
    "from custom_datasets.fatigue_mi import FatigueMI\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_optim.utils import channels_to_channels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLRNG = 42\n",
    "# RNG = jax.random.PRNGKey(SKLRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Helper funcs\n",
    "def shallow_conv_net_square_layer(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "def shallow_conv_net_log_layer(x):\n",
    "    return tf.math.log(tf.clip_by_value(x, 1e-7, 10000))\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    \"shallow_conv_net_square_layer\": shallow_conv_net_square_layer, \n",
    "    \"shallow_conv_net_log_layer\": shallow_conv_net_log_layer \n",
    "}\n",
    "# endregion Helper funcs\n",
    "\n",
    "# region Models\n",
    "def shallow_conv_net(\n",
    "    nb_classes, channels, samples, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    From: https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
    "    \"\"\"\n",
    "\n",
    "    _POOL_SIZE_D2_ = kwargs.get(\"pool_size_d2\", 35)\n",
    "    _STRIDES_D2_ = kwargs.get(\"strides_d2\", 7)\n",
    "    _CONV_FILTERS_D2_ = kwargs.get(\"conv_filters_d2\", 13)\n",
    "\n",
    "    _POOL_SIZE_ = kwargs.get(\"pool_size\", (1, _POOL_SIZE_D2_))\n",
    "    _STRIDES_ = kwargs.get(\"strides\", (1, _STRIDES_D2_))\n",
    "    _CONV_FILTERS_ = kwargs.get(\"conv_filters\", (1, _CONV_FILTERS_D2_))\n",
    "\n",
    "    _CONV2D_1_UNITS_ = kwargs.get(\"conv2d_1_units\", 40)\n",
    "    _CONV2D_2_UNITS_ = kwargs.get(\"conv2d_2_units\", 40)\n",
    "    _L2_REG_1_ = kwargs.get(\"l2_reg_1\", 0.01)\n",
    "    _L2_REG_2_ = kwargs.get(\"l2_reg_2\", 0.01)\n",
    "    _L2_REG_3_ = kwargs.get(\"l2_reg_3\", 0.01)\n",
    "    _DROPOUT_RATE_ = kwargs.get(\"dropout_rate\", 0.5)\n",
    "\n",
    "    input_main = Input(shape=(channels, samples, 1))\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_1_UNITS_,\n",
    "        _CONV_FILTERS_,\n",
    "        input_shape=(channels, samples, 1),\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_1_),\n",
    "    )(input_main)\n",
    "    # block1       = Conv2D(40, (channels, 1), use_bias=False,\n",
    "    #                       kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1 = Conv2D(\n",
    "        _CONV2D_2_UNITS_,\n",
    "        (channels, 1),\n",
    "        use_bias=False,\n",
    "        kernel_constraint=max_norm(2.0, axis=(0, 1, 2)),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_2_),\n",
    "    )(block1)\n",
    "    block1 = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1 = Activation(shallow_conv_net_square_layer)(block1)\n",
    "    block1 = AveragePooling2D(pool_size=_POOL_SIZE_, strides=_STRIDES_)(block1)\n",
    "    block1 = Activation(shallow_conv_net_log_layer)(block1)\n",
    "    block1 = Dropout(_DROPOUT_RATE_)(block1)\n",
    "    flatten = Flatten()(block1)\n",
    "    # dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    dense = Dense(\n",
    "        nb_classes,\n",
    "        kernel_constraint=max_norm(0.5),\n",
    "        kernel_regularizer=keras.regularizers.L2(_L2_REG_3_),\n",
    "    )(flatten)\n",
    "    softmax = Activation(\"softmax\")(dense)\n",
    "\n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "# endregion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_best_trials = glob.glob('./temp_v2/**/model/study_best_trial.npy', recursive=True)\n",
    "# subject_best_trials = sorted(subject_best_trials, key=lambda x: os.path.getmtime(x))\n",
    "# subject_best_trials = sorted(subject_best_trials, key=lambda x: int(re.compile(r\"\\[.*\\]\").search(x).group(0).strip(\"[]\")))\n",
    "\n",
    "subject_best_trials = glob.glob('./temp/**/model/study_best_trial.npy', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, subjects = [1], channel_idx = [], filters = ([8, 32],), sfreq = 250):\n",
    "\n",
    "    find_events = lambda raw, event_id: mne.find_events(raw, shortest_event=0, verbose=False) if len(mne.utils._get_stim_channel(None, raw.info, raise_error=False)) > 0 else mne.events_from_annotations(raw, event_id=event_id, verbose=False)[0]\n",
    "    \n",
    "    data = dataset.get_data(subjects=subjects)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    metadata = []\n",
    "\n",
    "    for subject_id in data.keys():\n",
    "        for session_id in data[subject_id].keys():\n",
    "            for run_id in data[subject_id][session_id].keys():\n",
    "                raw = data[subject_id][session_id][run_id]\n",
    "                \n",
    "                for fmin, fmax in filters:\n",
    "                    raw = raw.filter(l_freq = fmin, h_freq = fmax, method = 'iir', picks = 'eeg', verbose = False)\n",
    "                \n",
    "                events = find_events(raw, dataset.event_id)\n",
    "\n",
    "                tmin = dataset.interval[0]\n",
    "                tmax = dataset.interval[1]\n",
    "\n",
    "                channels = np.asarray(raw.info['ch_names'])[channel_idx] if len(channel_idx) > 0 else np.asarray(raw.info['ch_names'])\n",
    "\n",
    "                # rpprint(channels)\n",
    "                \n",
    "                stim_channels = mne.utils._get_stim_channel(None, raw.info, raise_error=False)\n",
    "                picks = mne.pick_channels(raw.info[\"ch_names\"], include=channels, exclude=stim_channels, ordered=True)\n",
    "\n",
    "                x = mne.Epochs(\n",
    "                    raw,\n",
    "                    events,\n",
    "                    event_id=dataset.event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=False,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "                    verbose=False,\n",
    "                    picks=picks,\n",
    "                    event_repeated=\"drop\",\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "                x_events = x.events\n",
    "                inv_events = {k: v for v, k in dataset.event_id.items()}\n",
    "                labels = [inv_events[e] for e in x_events[:, -1]]\n",
    "\n",
    "                # rpprint({\n",
    "                #     \"X\": np.asarray(x.get_data(copy=False)).shape,\n",
    "                #     \"y\": np.asarray(labels).shape,\n",
    "                #     \"channels selected\": np.asarray(raw.info['ch_names'])[channel_idx]\n",
    "                # })\n",
    "\n",
    "                # x.plot(scalings=\"auto\")\n",
    "                # display(x.info)\n",
    "                \n",
    "                x_resampled = x.resample(sfreq) # Resampler_Epoch\n",
    "                x_resampled_data = x_resampled.get_data(copy=False) # Convert_Epoch_Array\n",
    "                x_resampled_data_standard_scaler = np.asarray([\n",
    "                    StandardScaler().fit_transform(x_resampled_data[i])\n",
    "                    for i in np.arange(x_resampled_data.shape[0])\n",
    "                ]) # Standard_Scaler_Epoch\n",
    "\n",
    "                # x_resampled.plot(scalings=\"auto\")\n",
    "                # display(x_resampled.info)\n",
    "\n",
    "                n = x_resampled_data_standard_scaler.shape[0]\n",
    "                # n = x.get_data(copy=False).shape[0]\n",
    "                met = pd.DataFrame(index=range(n))\n",
    "                met[\"subject\"] = subject_id\n",
    "                met[\"session\"] = session_id\n",
    "                met[\"run\"] = run_id\n",
    "                x.metadata = met.copy()\n",
    "                \n",
    "                # X.append(x_resampled_data_standard_scaler)\n",
    "                X.append(x)\n",
    "                y.append(labels)\n",
    "                metadata.append(met)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y), pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "fat_dataset = FatigueMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'./temp/[1]/8ca44c9b9c7c4410b37ac5781bd7da1f/model/study_best_trial.npy'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'./temp/\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m/8ca44c9b9c7c4410b37ac5781bd7da1f/model/study_best_trial.npy'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpprint(subject_best_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_trial(subject_best_trial):\n",
    "    model = np.load(subject_best_trials[0], allow_pickle=True).item()\n",
    "    model_info = {\n",
    "        \"subject\": model.user_attrs[\"trial_data\"][\"subject\"] if hasattr(model.user_attrs[\"trial_data\"], \"subject\") else int(re.compile(r\"\\[.*\\]\").search(model.user_attrs[\"trial_data\"][\"data_path\"]).group(0).strip(\"[]\")),\n",
    "        \"sfreq\": model.params[\"sfreq\"] if \"sfreq\" in model.params else 128,\n",
    "        \"batch_size\": model.params[\"batch_size\"] if \"batch_size\" in model.params else 128,\n",
    "        \"channels_selected\": model.user_attrs[\"trial_data\"][\"channels_selected\"],\n",
    "        \"channels_idx_selected\": channels_to_channels_idx(model.user_attrs[\"trial_data\"][\"channels_selected\"], fat_dataset.get_data(subjects=[1])[1]['0']['0'].info['ch_names'][:-1]),\n",
    "        \"model\": tf.keras.models.model_from_json(model.user_attrs[\"trial_data\"][\"model\"], custom_objects=CUSTOM_OBJECTS),\n",
    "        \"test_acc\": model.user_attrs[\"trial_data\"][\"test_accuracy\"],\n",
    "        \"model_name\": model.user_attrs[\"trial_data\"][\"model_name\"] if hasattr(model.user_attrs[\"trial_data\"], \"model_name\") else \"shallow_conv_net\"\n",
    "    }\n",
    "    if \"weights\" in model.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"weights\"])\n",
    "    elif \"model_weights\" in model.user_attrs[\"trial_data\"]:\n",
    "        model_info[\"model\"].set_weights(model.user_attrs[\"trial_data\"][\"model_weights\"])\n",
    "    \n",
    "    return model_info\n",
    "\n",
    "def create_and_save_baseline_model(model_info, train_test_data, results_folder):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    model_info[\"model\"].compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    baseline_model_test = model_info[\"model\"].evaluate(X_test, y_test, batch_size=model_info[\"batch_size\"])\n",
    "\n",
    "    baseline_test_acc = baseline_model_test[1]\n",
    "\n",
    "    _, keras_file = None, results_folder + \"baseline_model.h5\"\n",
    "    tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n",
    "    return {\n",
    "        \"keras_file\": keras_file,\n",
    "        \"baseline_test_acc\": baseline_test_acc,\n",
    "        \"baseline_model\": model_info[\"model\"],\n",
    "    }\n",
    "\n",
    "def prune_model(model_info, train_test_data, target_sparsity, results_folder):\n",
    "\n",
    "    X_train, y_train = train_test_data[\"X_train\"], train_test_data[\"y_train\"]\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    batch_size = model_info[\"batch_size\"]\n",
    "    epochs = 2\n",
    "    end_step = np.ceil(len(X_train) / batch_size).astype(np.int32) * epochs\n",
    "    # Define model for pruning.\n",
    "    pruning_params = {\n",
    "        # 'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=target_sparsity, begin_step=0, frequency=1),\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.00,\n",
    "                                                                final_sparsity=target_sparsity,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step,\n",
    "                                                                frequency=1)\n",
    "    }\n",
    "    keras.utils.get_custom_objects().update({\n",
    "        **CUSTOM_OBJECTS\n",
    "    })\n",
    "    baseline_model_copy = tf.keras.models.clone_model(model_info[\"model\"])\n",
    "    model_for_pruning = prune_low_magnitude(baseline_model_copy, **pruning_params)\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    logdir = \"logs/pruning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(X_train, y_train, batch_size=model_info[\"batch_size\"], epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "    _, model_for_pruning_accuracy = model_for_pruning.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    _, pruned_keras_file = None, results_folder + \"pruned_model.h5\"\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "\n",
    "    return {\n",
    "        \"pruned_model\": model_for_export,\n",
    "        \"pruned_model_test_acc\": model_for_pruning_accuracy,\n",
    "        \"pruned_keras_file\": pruned_keras_file\n",
    "    }\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    \n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def convert_pruned_model_to_tflite(pruned_model, sparsity, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # converter.target_spec.supported_types = [quantization]\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def convert_pruned_model_to_tflite_with_quantization(pruned_model, sparsity, quantization, results_folder):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    if quantization == 'float16':\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    elif quantization == 'int8':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Quantization type {quantization} not implemented.\")\n",
    "    pruned_tflite_model = converter.convert()\n",
    "\n",
    "    _, pruned_tflite_file = None, results_folder + f\"pruned_model_{sparsity}_sparsity_{quantization}_quant.tflite\"\n",
    "    with open(pruned_tflite_file, 'wb') as f:\n",
    "        f.write(pruned_tflite_model)\n",
    "    \n",
    "    return {\n",
    "        \"pruned_quant_tflite_model\": pruned_tflite_model,\n",
    "        \"pruned_quant_tflite_file\": pruned_tflite_file\n",
    "    }\n",
    "\n",
    "def get_test_acc_non_tf_lite(model, train_test_data):\n",
    "\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "\n",
    "    # Evaluate prediction accuracy of pruned model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=0)\n",
    "\n",
    "    # Evaluate Inference Time of pruned model\n",
    "    start_time = time.time()\n",
    "    prediction = model.predict(X_test)\n",
    "    exec_time = (time.time() - start_time)/X_test.shape[0]\n",
    "    return {\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"avg_exec_time\": exec_time\n",
    "    }\n",
    "\n",
    "def get_test_acc(model, train_test_data):\n",
    "    X_test, y_test = train_test_data[\"X_test\"], train_test_data[\"y_test\"]\n",
    "    def evaluate_model(interpreter):\n",
    "        input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        # signatures = interpreter.get_signature_list()\n",
    "        # rprint(interpreter.get_input_details(), interpreter.get_output_details(), signatures)\n",
    "\n",
    "        # Run predictions on every image in the \"test\" dataset.\n",
    "        predictions = []\n",
    "        exec_times = []\n",
    "        for i, v in enumerate(X_test):\n",
    "            v = v[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "            # if i % 1000 == 0:\n",
    "            #   rprint('Evaluated on {n} results so far.'.format(n=i))\n",
    "            # # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "            # # the model's input data format.\n",
    "            # v = np.expand_dims(v, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, v)\n",
    "\n",
    "            # Run inference.\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            exec_time = (time.time() - start_time)\n",
    "            exec_times.append(exec_time)\n",
    "\n",
    "            # Post-processing: remove batch dimension and find the digit with highest\n",
    "            # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            class_prediction = np.argmax(output()[0]) # 0 = left, 1 = right\n",
    "            predictions.append(class_prediction)\n",
    "\n",
    "        print('\\n')\n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        predictions = np.asarray(predictions)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "        avg_exec_time = np.mean(exec_times)\n",
    "        return accuracy, avg_exec_time\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    test_accuracy, avg_exec_time = evaluate_model(interpreter)\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"avg_exec_time\": avg_exec_time\n",
    "    }\n",
    "\n",
    "def get_model_weights_sparsity(model):\n",
    "    sparsity_levels = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "\n",
    "        for weight in weights:\n",
    "            # if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
    "            #     continue\n",
    "            weight_size = weight.numpy().size\n",
    "            zero_num = np.count_nonzero(weight == 0)\n",
    "            sparsity_levels.append((\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\",\n",
    "            ))\n",
    "    return sparsity_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Loading best trial model<span style=\"color: #808000; text-decoration-color: #808000\">...</span> .<span style=\"color: #800080; text-decoration-color: #800080\">/temp/</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080\">/8ca44c9b9c7c4410b37ac5781bd7da1f/model/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">study_best_trial.npy</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Loading best trial model\u001b[33m...\u001b[0m .\u001b[35m/temp/\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[35m/8ca44c9b9c7c4410b37ac5781bd7da1f/model/\u001b[0m\u001b[95mstudy_best_trial.npy\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 19:08:56.603869: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:56.631927: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:56.632001: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:56.634999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:56.635207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:56.635268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:58.391433: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:58.391575: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:58.391586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-01 19:08:58.391653: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-01 19:08:58.391696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6593 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 300.0, returning unmodified.\n",
      "Adding metadata with 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 19:09:13.827454: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-04-01 19:09:14.871569: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-01 19:09:15.212981: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 16s 16s/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 19:09:23.752934: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_10/prune_low_magnitude_dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-04-01 19:09:26.235502: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f9e2c231eb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-01 19:09:26.235558: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2024-04-01 19:09:26.243699: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712020166.319575  121836 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step - loss: 15.3946 - accuracy: 0.5000 - val_loss: 13.8357 - val_accuracy: 0.5556\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 13.7922 - accuracy: 0.4265 - val_loss: 13.4045 - val_accuracy: 0.5556\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090638160706</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5909090638160706\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 403ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 762ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.4555 - accuracy: 0.6029WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9edffd2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.4555 - accuracy: 0.6029 - val_loss: 13.5366 - val_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 13.3617 - accuracy: 0.6471 - val_loss: 13.1481 - val_accuracy: 0.4444\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.3636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpplslhb3s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpplslhb3s/assets\n",
      "2024-04-01 19:09:37.262097: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:09:37.262140: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:09:37.262395: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpplslhb3s\n",
      "2024-04-01 19:09:37.263629: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:09:37.263643: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpplslhb3s\n",
      "2024-04-01 19:09:37.266577: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-01 19:09:37.267762: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:09:37.292535: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpplslhb3s\n",
      "2024-04-01 19:09:37.301749: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 39355 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model_0_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86072.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86072.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85763.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m85763.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83840.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m83840.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgfztzktf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgfztzktf/assets\n",
      "2024-04-01 19:09:38.543879: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:09:38.543922: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:09:38.544068: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpgfztzktf\n",
      "2024-04-01 19:09:38.545243: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:09:38.545256: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpgfztzktf\n",
      "2024-04-01 19:09:38.555861: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:09:38.578023: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpgfztzktf\n",
      "2024-04-01 19:09:38.585685: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 41618 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0/float16/\u001b[0m\u001b[95mpruned_model_0_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86072.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86072.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42636.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m42636.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36363636363636365</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.36363636363636365\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.3636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9e1767f240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9e1767f240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 734ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.5885 - accuracy: 0.5000 - val_loss: 13.3894 - val_accuracy: 0.5556\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 13.5565 - accuracy: 0.4265 - val_loss: 13.0655 - val_accuracy: 0.7222\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3636363744735718</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.3636363744735718\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp65_6ris9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp65_6ris9/assets\n",
      "2024-04-01 19:09:46.628554: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:09:46.628633: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:09:46.628828: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp65_6ris9\n",
      "2024-04-01 19:09:46.631470: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:09:46.631506: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp65_6ris9\n",
      "2024-04-01 19:09:46.644673: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:09:46.666513: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp65_6ris9\n",
      "2024-04-01 19:09:46.683782: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 54950 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model_0_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86066.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86066.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85801.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m85801.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83835.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m83835.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoijoje_n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoijoje_n/assets\n",
      "2024-04-01 19:09:48.039219: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:09:48.039313: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:09:48.039698: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpoijoje_n\n",
      "2024-04-01 19:09:48.041382: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:09:48.041420: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpoijoje_n\n",
      "2024-04-01 19:09:48.045067: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:09:48.067597: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpoijoje_n\n",
      "2024-04-01 19:09:48.076430: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 36737 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0/int8/\u001b[0m\u001b[95mpruned_model_0_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86066.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86066.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24873.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m24873.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36363636363636365</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.36363636363636365\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3636363744735718</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.3636363744735718\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 811ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.1/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.9281 - accuracy: 0.4265 - val_loss: 13.8759 - val_accuracy: 0.1667\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 13.7576 - accuracy: 0.5294 - val_loss: 13.5942 - val_accuracy: 0.1667\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.1/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6363636255264282</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.6363636255264282\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 247ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9e175a23e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9e175a23e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 14.5191 - accuracy: 0.5294 - val_loss: 13.5569 - val_accuracy: 0.3889\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 13.5459 - accuracy: 0.5588 - val_loss: 13.2032 - val_accuracy: 0.4444\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.40909090638160706\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp68el81ob/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp68el81ob/assets\n",
      "2024-04-01 19:10:04.129739: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:04.129804: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:04.129965: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp68el81ob\n",
      "2024-04-01 19:10:04.131121: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:04.131139: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp68el81ob\n",
      "2024-04-01 19:10:04.134514: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:04.153089: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp68el81ob\n",
      "2024-04-01 19:10:04.162704: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 32739 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model_0.1_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86076.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86076.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80661.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m80661.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78828.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m78828.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwkx0dbbt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwkx0dbbt/assets\n",
      "2024-04-01 19:10:05.867847: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:05.867933: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:05.868139: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpwkx0dbbt\n",
      "2024-04-01 19:10:05.870740: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:05.870778: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpwkx0dbbt\n",
      "2024-04-01 19:10:05.877606: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:05.907166: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpwkx0dbbt\n",
      "2024-04-01 19:10:05.926015: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 57878 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.1/float16/\u001b[0m\u001b[95mpruned_model_0.1_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86076.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86076.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41054.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m41054.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4090909090909091</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.4090909090909091\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40909090638160706</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.40909090638160706\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.1\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 985ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9de3f6b240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9de3f6b240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 15.1287 - accuracy: 0.3824 - val_loss: 13.4552 - val_accuracy: 0.4444\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 13.4053 - accuracy: 0.5441 - val_loss: 13.1397 - val_accuracy: 0.5000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m10.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5454545617103577\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpshmgj1a4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpshmgj1a4/assets\n",
      "2024-04-01 19:10:14.210533: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:14.210615: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:14.210820: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpshmgj1a4\n",
      "2024-04-01 19:10:14.212279: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:14.212294: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpshmgj1a4\n",
      "2024-04-01 19:10:14.216941: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:14.242254: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpshmgj1a4\n",
      "2024-04-01 19:10:14.253254: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 42435 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model_0.1_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86070.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86070.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80695.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m80695.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78798.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m78798.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjwx2m5kt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjwx2m5kt/assets\n",
      "2024-04-01 19:10:15.761679: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:15.761784: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:15.761986: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpjwx2m5kt\n",
      "2024-04-01 19:10:15.763257: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:15.763289: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpjwx2m5kt\n",
      "2024-04-01 19:10:15.768432: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:15.791524: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpjwx2m5kt\n",
      "2024-04-01 19:10:15.802949: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 40962 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.1/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.1_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.1/int8/\u001b[0m\u001b[95mpruned_model_0.1_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86070.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86070.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23819.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m23819.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545454545454</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5454545454545454\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5454545617103577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 802ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.5/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.4719 - accuracy: 0.4265 - val_loss: 12.7312 - val_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 11.9920 - accuracy: 0.5735 - val_loss: 11.7704 - val_accuracy: 0.4444\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.5/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 808ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 19:10:28.898381: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_10/prune_low_magnitude_dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 13.6882 - accuracy: 0.5147 - val_loss: 12.6290 - val_accuracy: 0.5556\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 12.0352 - accuracy: 0.5735 - val_loss: 11.6996 - val_accuracy: 0.5000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3181818127632141</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.3181818127632141\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph9kahye0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph9kahye0/assets\n",
      "2024-04-01 19:10:31.858031: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:31.858081: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:31.858227: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmph9kahye0\n",
      "2024-04-01 19:10:31.859381: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:31.859393: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmph9kahye0\n",
      "2024-04-01 19:10:31.862104: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:31.882872: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmph9kahye0\n",
      "2024-04-01 19:10:31.893198: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 34971 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model_0.5_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86076.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86076.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53258.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m53258.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51414.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m51414.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4_3w_mf9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4_3w_mf9/assets\n",
      "2024-04-01 19:10:33.258262: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:33.258358: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:33.258588: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp4_3w_mf9\n",
      "2024-04-01 19:10:33.260274: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:33.260300: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp4_3w_mf9\n",
      "2024-04-01 19:10:33.262968: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:33.287297: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp4_3w_mf9\n",
      "2024-04-01 19:10:33.295215: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 36628 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.5/float16/\u001b[0m\u001b[95mpruned_model_0.5_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86076.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86076.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29079.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m29079.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3181818181818182</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.3181818181818182\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3181818127632141</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.3181818127632141\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.5\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 891ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.4434 - accuracy: 0.5147 - val_loss: 12.4159 - val_accuracy: 0.5556\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 11.8639 - accuracy: 0.5735 - val_loss: 11.5818 - val_accuracy: 0.5000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m50.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090638160706</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5909090638160706\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphg7tsxg9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphg7tsxg9/assets\n",
      "2024-04-01 19:10:41.538935: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:41.538984: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:41.539129: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphg7tsxg9\n",
      "2024-04-01 19:10:41.540275: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:41.540287: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphg7tsxg9\n",
      "2024-04-01 19:10:41.544299: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:41.565891: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphg7tsxg9\n",
      "2024-04-01 19:10:41.578007: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 38878 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model_0.5_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86070.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86070.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53287.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m53287.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51462.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m51462.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0al2_w6n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0al2_w6n/assets\n",
      "2024-04-01 19:10:43.015072: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:10:43.015191: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:10:43.015537: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp0al2_w6n\n",
      "2024-04-01 19:10:43.017966: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:10:43.018026: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp0al2_w6n\n",
      "2024-04-01 19:10:43.022822: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:10:43.050555: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp0al2_w6n\n",
      "2024-04-01 19:10:43.067260: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 51726 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.5/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.5_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.5/int8/\u001b[0m\u001b[95mpruned_model_0.5_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86070.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86070.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17574.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m17574.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090909090909</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5909090909090909\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5909090638160706</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5909090638160706\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: \u001b[3;35mNone\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 840ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.9/None/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.7703 - accuracy: 0.5441 - val_loss: 7.3322 - val_accuracy: 0.5556\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 4.2811 - accuracy: 0.5294 - val_loss: 4.1550 - val_accuracy: 0.5556\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/None/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.9/None/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5454545617103577</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5454545617103577\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: float16\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: float16\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 829ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 7.7675 - accuracy: 0.5294 - val_loss: 7.3226 - val_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 4.1359 - accuracy: 0.6176 - val_loss: 4.1884 - val_accuracy: 0.2222\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3atn_2y1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3atn_2y1/assets\n",
      "2024-04-01 19:11:00.030120: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:11:00.030189: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:11:00.030568: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp3atn_2y1\n",
      "2024-04-01 19:11:00.033046: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:11:00.033114: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp3atn_2y1\n",
      "2024-04-01 19:11:00.043276: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:11:00.075233: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp3atn_2y1\n",
      "2024-04-01 19:11:00.085517: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 54953 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model_0.9_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86076.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86076.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20543.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m20543.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18652.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m18652.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphkra4fhz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphkra4fhz/assets\n",
      "2024-04-01 19:11:01.709724: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:11:01.709795: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:11:01.710005: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphkra4fhz\n",
      "2024-04-01 19:11:01.712357: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:11:01.712454: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphkra4fhz\n",
      "2024-04-01 19:11:01.722150: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:11:01.753309: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphkra4fhz\n",
      "2024-04-01 19:11:01.769039: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 59036 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 30, % non-converted = 30.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f16: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/float16/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity_float16_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.9/float16/\u001b[0m\u001b[95mpruned_model_0.9_sparsity_float16_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86076.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86076.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12690.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m12690.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "Subject: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Model: shallow_conv_net, Sparsity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, Quantization: int8\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "Subject: \u001b[1;36m1\u001b[0m, Model: shallow_conv_net, Sparsity: \u001b[1;36m0.9\u001b[0m, Quantization: int8\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Building &amp; saving baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Building & saving baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 973ms/step - loss: 10.9936 - accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:30: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_info[\"model\"], keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved baseline model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">baseline_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved baseline model to: .\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mbaseline_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruning the baseline model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruning the baseline model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.0825 - accuracy: 0.4706 - val_loss: 7.3524 - val_accuracy: 0.6111\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.2644 - accuracy: 0.4559 - val_loss: 4.3009 - val_accuracy: 0.3889\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121500/1382588147.py:76: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned Keras model with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.0</span>% sparsity to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model.h5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned Keras model with \u001b[1;36m90.0\u001b[0m% sparsity to: .\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model.h5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Baseline test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6818181872367859</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pruned test accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'Baseline test accuracy'\u001b[0m: \u001b[1;36m0.6818181872367859\u001b[0m, \u001b[32m'Pruned test accuracy'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn88cmgfi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn88cmgfi/assets\n",
      "2024-04-01 19:11:09.868374: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:11:09.868439: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:11:09.868608: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpn88cmgfi\n",
      "2024-04-01 19:11:09.869874: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:11:09.869897: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpn88cmgfi\n",
      "2024-04-01 19:11:09.874289: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:11:09.903521: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpn88cmgfi\n",
      "2024-04-01 19:11:09.917451: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 48844 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 22, % non-converted = 40.91 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved pruned TFLite model to: .<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved pruned TFLite model to: .\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model_0.9_sparsity.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86070.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86070.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20530.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned Keras model: \u001b[1;36m20530.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18593.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned TFlite model: \u001b[1;36m18593.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvy7lbre2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvy7lbre2/assets\n",
      "2024-04-01 19:11:11.953146: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-01 19:11:11.953234: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-01 19:11:11.953483: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpvy7lbre2\n",
      "2024-04-01 19:11:11.956587: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-01 19:11:11.956650: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpvy7lbre2\n",
      "2024-04-01 19:11:11.967625: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-01 19:11:11.998845: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpvy7lbre2\n",
      "2024-04-01 19:11:12.019440: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 65959 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 22, % non-converted = 27.27 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saved quantized and pruned TFLite model to: \n",
       ".<span style=\"color: #800080; text-decoration-color: #800080\">/results/1/shallow_conv_net/0.9/int8/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pruned_model_0.9_sparsity_int8_quant.tflite</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saved quantized and pruned TFLite model to: \n",
       ".\u001b[35m/results/1/shallow_conv_net/0.9/int8/\u001b[0m\u001b[95mpruned_model_0.9_sparsity_int8_quant.tflite\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped baseline Keras model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86070.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped baseline Keras model: \u001b[1;36m86070.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of gzipped pruned and quantized TFlite model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6962.00</span> bytes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of gzipped pruned and quantized TFlite model: \u001b[1;36m6962.00\u001b[0m bytes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned and quantized TFLite test_accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned and quantized TFLite test_accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pruned TF test accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pruned TF test accuracy: \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Folder structure for results: ./results/{subject}/{model}/{sparsity}/{quantization}/\n",
    "\n",
    "sparsity_levels = [0, 0.1, 0.5, 0.9]\n",
    "quantization_levels = [None, 'float16', 'int8']\n",
    "\n",
    "results_data = {\n",
    "    \"subject\": [],\n",
    "    \"model_name\": [],\n",
    "    \"sparsity\": [],\n",
    "    \"quantization\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"model_size\": [],\n",
    "    \"inf_time\": [],\n",
    "    \"weights_sparsity\": [],\n",
    "}\n",
    "\n",
    "for subject_best_trial in subject_best_trials[0:1]:\n",
    "\n",
    "    rprint(\"\\n\\n\\nLoading best trial model...\", subject_best_trial)\n",
    "\n",
    "    model_info = load_best_trial(subject_best_trial)\n",
    "    subject = model_info[\"subject\"]\n",
    "    model_name = model_info[\"model_name\"]\n",
    "\n",
    "    X, y, _ = data_generator(fat_dataset, subjects=[model_info[\"subject\"]], channel_idx=model_info[\"channels_idx_selected\"], sfreq=model_info[\"sfreq\"])\n",
    "    y_encoded = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=SKLRNG, shuffle=True, stratify=y_encoded)\n",
    "    train_test_data = { \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test }\n",
    "\n",
    "    for sparsity in sparsity_levels:\n",
    "        for quantization in quantization_levels:\n",
    "\n",
    "            rprint(f\"\\n\\n\\nSubject: {subject}, Model: {model_name}, Sparsity: {sparsity}, Quantization: {quantization}\\n\\n\")\n",
    "\n",
    "            results_folder = f\"./results/{subject}/{model_name}/{sparsity}/{quantization}/\"\n",
    "            os.makedirs(results_folder, exist_ok=True) if not os.path.exists(results_folder) else None # Make folder if doesn't exist\n",
    "\n",
    "            # region 1) ------------- Build & save baseline model ------------- \n",
    "            rprint(\"Building & saving baseline model...\")\n",
    "            baseline_model_info = create_and_save_baseline_model(**{\n",
    "                \"model_info\": model_info,\n",
    "                \"results_folder\": results_folder,\n",
    "                \"train_test_data\": train_test_data\n",
    "            })\n",
    "            keras_file, baseline_test_acc = baseline_model_info[\"keras_file\"], baseline_model_info[\"baseline_test_acc\"]\n",
    "            rprint('Saved baseline model to:', keras_file)\n",
    "            # endregion\n",
    "\n",
    "            # region 2) ------------- Pruning the baseline model -------------\n",
    "            rprint(\"Pruning the baseline model...\")\n",
    "            pruned_model_info = prune_model(**{\n",
    "                \"target_sparsity\": sparsity,\n",
    "                \"model_info\": model_info,\n",
    "                \"train_test_data\": train_test_data,\n",
    "                \"results_folder\": results_folder\n",
    "            })\n",
    "            \n",
    "            pruned_model = pruned_model_info[\"pruned_model\"]\n",
    "            pruned_model_test_acc, pruned_keras_file = pruned_model_info[\"pruned_model_test_acc\"], pruned_model_info[\"pruned_keras_file\"]\n",
    "            pruned_model_weights_sparsity = get_model_weights_sparsity(pruned_model)\n",
    "            model_weights_sparsity = pruned_model_weights_sparsity\n",
    "\n",
    "            rprint(f'Saved pruned Keras model with {sparsity*100}% sparsity to:', pruned_keras_file)\n",
    "            rpprint({\n",
    "                'Baseline test accuracy': baseline_test_acc,\n",
    "                'Pruned test accuracy': pruned_model_test_acc\n",
    "            })\n",
    "            # endregion\n",
    "\n",
    "            # region 3) ------------- Converting pruned model to TFLite -------------        \n",
    "            if quantization != None:\n",
    "                tflite_model_info = convert_pruned_model_to_tflite(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                pruned_tflite_model, pruned_tflite_file = tflite_model_info[\"pruned_tflite_model\"], tflite_model_info[\"pruned_tflite_file\"]\n",
    "                \n",
    "                rprint('Saved pruned TFLite model to:', pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "                rprint(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "            else:\n",
    "                pruned_tflite_model, pruned_tflite_file = None, None\n",
    "            # endregion\n",
    "\n",
    "            # region 4) ------------- Quantizing pruned TFLite model ------------- \n",
    "            if quantization != None:\n",
    "                tflite_quant_model_info = convert_pruned_model_to_tflite_with_quantization(**{\n",
    "                    \"pruned_model\": pruned_model,\n",
    "                    \"sparsity\": sparsity,\n",
    "                    \"quantization\": quantization,\n",
    "                    \"results_folder\": results_folder\n",
    "                })\n",
    "                quantized_and_pruned_tflite_model = tflite_quant_model_info[\"pruned_quant_tflite_model\"]\n",
    "                quantized_and_pruned_tflite_file = tflite_quant_model_info[\"pruned_quant_tflite_file\"]\n",
    "\n",
    "                rprint('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "                rprint(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "                rprint(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "            else:\n",
    "                quantized_and_pruned_tflite_model, quantized_and_pruned_tflite_file = None, None\n",
    "            \n",
    "            # endregion\n",
    "\n",
    "            # region 5) ------------- Evaluation check -------------\n",
    "            if quantization != None:\n",
    "                tflite_quant_model_test_acc_results = get_test_acc(**{\n",
    "                    \"model\": quantized_and_pruned_tflite_model, \n",
    "                    \"train_test_data\": train_test_data\n",
    "                })\n",
    "                tflite_quant_model_test_acc = tflite_quant_model_test_acc_results[\"test_accuracy\"]\n",
    "\n",
    "                rprint('Pruned and quantized TFLite test_accuracy:', tflite_quant_model_test_acc)\n",
    "                rprint('Pruned TF test accuracy:', pruned_model_test_acc)\n",
    "            # endregion\n",
    "            \n",
    "            # region 6) ------------- Saving results -------------\n",
    "            if quantization != None:\n",
    "                model_objs = [{ \"model\": quantized_and_pruned_tflite_model, \"file\": quantized_and_pruned_tflite_file, \"tf_lite\": True, \"weights_sparsity\": model_weights_sparsity }]\n",
    "            else:\n",
    "                model_objs = [{ \"model\": pruned_model, \"file\": pruned_keras_file, \"tf_lite\": False, \"weights_sparsity\": model_weights_sparsity }]\n",
    "                \n",
    "            for model_obj in model_objs:\n",
    "                model_to_evaluate = model_obj[\"model\"]\n",
    "                model_file_to_evaluate = model_obj[\"file\"]\n",
    "                model_is_tf_lite = model_obj[\"tf_lite\"]\n",
    "                model_weights_sparsity = model_obj[\"weights_sparsity\"]\n",
    "\n",
    "                if model_to_evaluate == None or model_file_to_evaluate == None:\n",
    "                    continue\n",
    "\n",
    "                # 1) Test accuracy & inference time\n",
    "                if model_is_tf_lite:\n",
    "                    eval_res = get_test_acc(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                else:\n",
    "                    eval_res = get_test_acc_non_tf_lite(**{\n",
    "                        \"model\": model_to_evaluate, \n",
    "                        \"train_test_data\": train_test_data\n",
    "                    })\n",
    "                test_acc = eval_res[\"test_accuracy\"]\n",
    "                inf_time = eval_res[\"avg_exec_time\"]\n",
    "                # 2) Model size\n",
    "                model_size = get_gzipped_model_size(model_file_to_evaluate)\n",
    "\n",
    "                results_data[\"subject\"].append(subject)\n",
    "                results_data[\"model_name\"].append(model_name)\n",
    "                results_data[\"sparsity\"].append(sparsity)\n",
    "                results_data[\"quantization\"].append(quantization)\n",
    "                \n",
    "                results_data[\"test_acc\"].append(test_acc)\n",
    "                results_data[\"model_size\"].append(model_size)\n",
    "                results_data[\"inf_time\"].append(inf_time)\n",
    "\n",
    "                results_data[\"weights_sparsity\"].append(model_weights_sparsity)\n",
    "            # endregion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>quantization</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>model_size</th>\n",
       "      <th>inf_time</th>\n",
       "      <th>weights_sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>85759</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>[(conv2d_20/kernel:0: 0.00% sparsity , (0/1610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>42636</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>[(conv2d_20/kernel:0: 0.00% sparsity , (0/1610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>24873</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>[(conv2d_20/kernel:0: 0.00% sparsity , (0/1610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>80609</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>[(conv2d_20/kernel:0: 10.00% sparsity , (161/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>41054</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>[(conv2d_20/kernel:0: 10.00% sparsity , (161/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.1</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>23819</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>[(conv2d_20/kernel:0: 10.00% sparsity , (161/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>53333</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>[(conv2d_20/kernel:0: 50.00% sparsity , (805/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>29079</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>[(conv2d_20/kernel:0: 50.00% sparsity , (805/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.5</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>17574</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>[(conv2d_20/kernel:0: 50.00% sparsity , (805/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>20573</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>[(conv2d_20/kernel:0: 90.00% sparsity , (1449/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>float16</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12690</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>[(conv2d_20/kernel:0: 90.00% sparsity , (1449/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>shallow_conv_net</td>\n",
       "      <td>0.9</td>\n",
       "      <td>int8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6962</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>[(conv2d_20/kernel:0: 90.00% sparsity , (1449/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject        model_name  sparsity quantization  test_acc  model_size  \\\n",
       "0         1  shallow_conv_net       0.0         None  0.590909       85759   \n",
       "1         1  shallow_conv_net       0.0      float16  0.363636       42636   \n",
       "2         1  shallow_conv_net       0.0         int8  0.363636       24873   \n",
       "3         1  shallow_conv_net       0.1         None  0.636364       80609   \n",
       "4         1  shallow_conv_net       0.1      float16  0.409091       41054   \n",
       "5         1  shallow_conv_net       0.1         int8  0.545455       23819   \n",
       "6         1  shallow_conv_net       0.5         None  0.500000       53333   \n",
       "7         1  shallow_conv_net       0.5      float16  0.318182       29079   \n",
       "8         1  shallow_conv_net       0.5         int8  0.590909       17574   \n",
       "9         1  shallow_conv_net       0.9         None  0.545455       20573   \n",
       "10        1  shallow_conv_net       0.9      float16  0.500000       12690   \n",
       "11        1  shallow_conv_net       0.9         int8  0.500000        6962   \n",
       "\n",
       "    inf_time                                   weights_sparsity  \n",
       "0   0.020158  [(conv2d_20/kernel:0: 0.00% sparsity , (0/1610...  \n",
       "1   0.000948  [(conv2d_20/kernel:0: 0.00% sparsity , (0/1610...  \n",
       "2   0.002454  [(conv2d_20/kernel:0: 0.00% sparsity , (0/1610...  \n",
       "3   0.013621  [(conv2d_20/kernel:0: 10.00% sparsity , (161/1...  \n",
       "4   0.001223  [(conv2d_20/kernel:0: 10.00% sparsity , (161/1...  \n",
       "5   0.003124  [(conv2d_20/kernel:0: 10.00% sparsity , (161/1...  \n",
       "6   0.013633  [(conv2d_20/kernel:0: 50.00% sparsity , (805/1...  \n",
       "7   0.001356  [(conv2d_20/kernel:0: 50.00% sparsity , (805/1...  \n",
       "8   0.004283  [(conv2d_20/kernel:0: 50.00% sparsity , (805/1...  \n",
       "9   0.014336  [(conv2d_20/kernel:0: 90.00% sparsity , (1449/...  \n",
       "10  0.001039  [(conv2d_20/kernel:0: 90.00% sparsity , (1449/...  \n",
       "11  0.003213  [(conv2d_20/kernel:0: 90.00% sparsity , (1449/...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data_df = pd.DataFrame(results_data)\n",
    "results_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb_model_optimization_quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
